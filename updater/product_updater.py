"""
ìƒí’ˆ ì—…ë°ì´í„° ëª¨ë“ˆ - ë‹¨ìˆœí™”ëœ ë²„ì „ (ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©)

ì´ ëª¨ë“ˆì€ ì¿ íŒ¡ í¬ë¡¤ëŸ¬ì™€ iHerb ìŠ¤í¬ë˜í¼ë¥¼ ì—°ê³„í•˜ì—¬ ìƒí’ˆ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë§¤ì¹­í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
ê¸°ì¡´ ì½”ë“œì—ì„œ ë°œìƒí•˜ë˜ ëª‡ ê°€ì§€ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

* **í•„ìˆ˜ ì»¬ëŸ¼ ì„  ì •ì˜** â€“ í¬ë¡¤ë§ ë„ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí•˜ê±°ë‚˜ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í•´ë„ `required_columns`ê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šì•„
  `UnboundLocalError`ê°€ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ ëª©ë¡ì„ ì •ì˜í•˜ì—¬ í•­ìƒ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **Graceful ì¢…ë£Œ ì²˜ë¦¬** â€“ í¬ë¡¤ë§ ë˜ëŠ” ë§¤ì¹­ ê³¼ì •ì—ì„œ `KeyboardInterrupt`ê°€ ë°œìƒí•˜ë©´ í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„
  ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
* **ì§€ì† ê°€ëŠ¥í•œ ë§¤ì¹­ ê²°ê³¼ ì €ì¥** â€“ `match_iherb_products` í•¨ìˆ˜ì— `output_path` íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ì—¬,
  ë§¤ì¹­ ê²°ê³¼ë¥¼ ì§€ì •ëœ ê²½ë¡œì— ì €ì¥í•˜ê³ , ì¤‘ë‹¨ í›„ ì¬ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
"""

import pandas as pd
import sys
import os
import tempfile
from datetime import datetime

# ìƒìœ„ ë””ë ‰í† ë¦¬ì™€ coupang, iherbscraper ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
coupang_dir = os.path.join(parent_dir, 'coupang')
iherbscraper_dir = os.path.join(parent_dir, 'iherbscraper')

sys.path.insert(0, parent_dir)
sys.path.insert(0, coupang_dir)
sys.path.insert(0, iherbscraper_dir)

from config import PathConfig, APIConfig
from iherbscraper.iherb_config import IHerbConfig
from coupang.coupang_config import CoupangConfig
from coupang.crawler import CoupangCrawlerMacOS
from iherbscraper.main import EnglishIHerbScraper
from coupang.translator import GeminiCSVTranslator

class ProductUpdater:
    """ì¿ íŒ¡ í¬ë¡¤ë§ê³¼ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ì„ í†µí•©í•œ ìƒí’ˆ ì—…ë°ì´í„° - ë‹¨ìˆœí™”ëœ ë²„ì „"""

    def __init__(self, enable_images: bool = True):
        """
        ì´ˆê¸°í™”

        Args:
            enable_images: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í™œì„±í™” ì—¬ë¶€
        """
        self.enable_images = enable_images
        self.coupang_crawler = None
        self.iherb_scraper = None
        self.translator = None

        print(f"ğŸ“‹ ìƒí’ˆ ì—…ë°ì´í„° ì´ˆê¸°í™”")
        print(f"   ì´ë¯¸ì§€ ê¸°ëŠ¥: {'í™œì„±í™”' if enable_images else 'ë¹„í™œì„±í™”'}")
        if enable_images:
            print(f"   ì´ë¯¸ì§€ ì €ì¥: ê¸°ë³¸ ê²½ë¡œ (coupang/coupang_images)")

    def crawl_coupang_products(self, search_url: str) -> pd.DataFrame:
        # í•„ìˆ˜ ì»¬ëŸ¼ì„ í•¨ìˆ˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ ì •ì˜í•˜ì—¬ ì˜ˆì™¸ ìƒí™©ì—ì„œë„ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        required_columns = CoupangConfig.REQUIRED_COLUMNS[:5]  # ê¸°ë³¸ 5ê°œë§Œ
        try:
            print(f"   ğŸ”„ ì¿ íŒ¡ í¬ë¡¤ë§ ì‹œì‘")
            print(f"   ğŸ“ URL: {search_url[:80]}...")

            # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” - ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ìë™ ì‚¬ìš©
            self.coupang_crawler = CoupangCrawlerMacOS(
                headless=False,
                delay_range=(3, 6),
                download_images=self.enable_images,
                image_dir=None  # Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ ê²½ë¡œ(coupang/coupang_images) ìë™ ì‚¬ìš©
            )

            if self.enable_images:
                print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥ í™œì„±í™”: ìë™ ê²½ë¡œ ì‚¬ìš©")
            else:
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì „ìš© í¬ë¡¤ë§")

            # í¬ë¡¤ë§ ì‹¤í–‰
            products = self.coupang_crawler.crawl_all_pages(search_url, max_pages=None)

            # productsê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ ë•Œ ì²˜ë¦¬
            if not products:
                print(f"   âš ï¸ í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ")
                return pd.DataFrame(columns=required_columns)

            # DataFrame ë³€í™˜
            crawled_df = pd.DataFrame(products)

            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
            for col in required_columns:
                if col not in crawled_df.columns:
                    crawled_df[col] = ''

            print(f"   âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(crawled_df)}ê°œ ìƒí’ˆ")

            # ì´ë¯¸ì§€ í†µê³„ ì¶œë ¥
            if self.enable_images and getattr(self.coupang_crawler, 'image_downloader', None):
                stats = self.coupang_crawler.image_downloader.image_download_stats
                successful_images = stats.get('successful_downloads', 0)
                total_attempts = stats.get('total_attempts', 0)
                print(f"   ğŸ“¸ ì´ë¯¸ì§€ ìˆ˜ì§‘: {successful_images}/{total_attempts}ê°œ")

            return crawled_df

        except KeyboardInterrupt:
            # ì‚¬ìš©ì ì¤‘ë‹¨ ì‹œ ë¹ˆ DataFrame ë°˜í™˜
            print("   âš ï¸ ì‚¬ìš©ìê°€ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            return pd.DataFrame(columns=required_columns)
        except Exception as e:
            print(f"   âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return pd.DataFrame(columns=required_columns)

    def match_iherb_products(self, new_products_df: pd.DataFrame, output_path: str | None = None, brand_name: str = "unknown") -> pd.DataFrame:
        if len(new_products_df) == 0:
            print(f"   ğŸ“ ë§¤ì¹­í•  ì‹ ê·œ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()

        try:
            print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ì‹œì‘: {len(new_products_df)}ê°œ ìƒí’ˆ")

            # 1. outputs í´ë” ìƒì„±
            os.makedirs(PathConfig.UNIFIED_OUTPUTS_DIR, exist_ok=True)
            
            # 2. ì¶œë ¥ ê²½ë¡œ ì„¤ì •
            if output_path:
                matched_csv_path = output_path
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                matched_csv_path = os.path.join(PathConfig.UNIFIED_OUTPUTS_DIR, f"matched_{brand_name}_{timestamp}_partial.csv")

            # 3. ì¤‘ë‹¨ëœ ì‘ì—… í™•ì¸ ë° ì´ì–´ë°›ê¸°
            existing_results = None
            if os.path.exists(matched_csv_path):
                try:
                    existing_results = pd.read_csv(matched_csv_path, encoding='utf-8-sig')
                    completed_count = len(existing_results)
                    print(f"   ğŸ“‚ ê¸°ì¡´ ì§„í–‰ ìƒí™©: {completed_count}ê°œ ì™„ë£Œ")
                    
                    # ì´ë¯¸ ì²˜ë¦¬ëœ ìƒí’ˆ IDë“¤ í™•ì¸
                    if 'coupang_product_id' in existing_results.columns:
                        processed_ids = set(existing_results['coupang_product_id'].astype(str))
                        remaining_df = new_products_df[~new_products_df['product_id'].astype(str).isin(processed_ids)]
                        print(f"   â­ï¸ ë‚¨ì€ ì‘ì—…: {len(remaining_df)}ê°œ")
                        new_products_df = remaining_df
                except Exception as e:
                    print(f"   âš ï¸ ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                    existing_results = None

            # 4. ì…ë ¥ CSVë¥¼ outputs í´ë”ì— ì €ì¥ (ì•„ì´í—ˆë¸Œ ìŠ¤í¬ë˜í¼ ì…ë ¥ìš©)
            input_csv_path = matched_csv_path.replace('.csv', '_input.csv')
            new_products_df.to_csv(input_csv_path, index=False, encoding='utf-8-sig')

            # 5. ë²ˆì—­ (outputs í´ë”ì— ì €ì¥)
            print(f"   ğŸ“ ë²ˆì—­ ì‹œì‘")
            translated_csv_path = matched_csv_path.replace('.csv', '_translated.csv')
            
            self.translator = GeminiCSVTranslator()
            _ = self.translator.translate_csv(
                input_file=input_csv_path,
                output_file=translated_csv_path,
                column_name='product_name',
                batch_size=10
            )
            print(f"   âœ… ë²ˆì—­ ì™„ë£Œ")

            # 6. ì•„ì´í—ˆë¸Œ ë§¤ì¹­ (ì‹¤ì‹œê°„ ì €ì¥)
            print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ìˆ˜í–‰")
            print(f"   ğŸ’¾ ì‹¤ì‹œê°„ ì €ì¥: {matched_csv_path}")

            self.iherb_scraper = EnglishIHerbScraper(
                headless=False,
                delay_range=(2, 4),
                max_products_to_compare=4
            )

            # í•µì‹¬: ì‹¤ì‹œê°„ ì €ì¥ë˜ëŠ” ê²½ë¡œë¡œ ë§¤ì¹­ ìˆ˜í–‰
            # ì¤‘ë‹¨ë˜ì–´ë„ matched_csv_pathì— ì§€ê¸ˆê¹Œì§€ ê²°ê³¼ê°€ ì €ì¥ë¨
            matched_csv = self.iherb_scraper.process_products_complete(
                csv_file_path=translated_csv_path,
                output_file_path=matched_csv_path,  # ì‹¤ì‹œê°„ ì €ì¥ ê²½ë¡œ
                limit=None,
                start_from=None
            )

            # 7. ê²°ê³¼ ë¡œë“œ ë° ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•©
            if os.path.exists(matched_csv_path):
                matched_df = pd.read_csv(matched_csv_path, encoding='utf-8-sig')
                
                # ê¸°ì¡´ ê²°ê³¼ê°€ ìˆì—ˆë‹¤ë©´ ë³‘í•©
                if existing_results is not None:
                    # ìƒˆë¡œ ë§¤ì¹­ëœ ê²°ê³¼ì™€ ê¸°ì¡´ ê²°ê³¼ ë³‘í•©
                    final_matched_df = pd.concat([existing_results, matched_df], ignore_index=True)
                    # ì¤‘ë³µ ì œê±° (product_id ê¸°ì¤€)
                    if 'coupang_product_id' in final_matched_df.columns:
                        final_matched_df = final_matched_df.drop_duplicates(subset=['coupang_product_id'], keep='last')
                    
                    # ë³‘í•©ëœ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì €ì¥
                    final_matched_df.to_csv(matched_csv_path, index=False, encoding='utf-8-sig')
                    matched_df = final_matched_df
                    print(f"   ğŸ”— ê¸°ì¡´ ê²°ê³¼ì™€ ë³‘í•©: ì´ {len(matched_df)}ê°œ")
                
                # ì„±ê³µ í†µê³„
                if 'status' in matched_df.columns:
                    success_count = len(matched_df[matched_df['status'] == 'success'])
                    success_rate = success_count / len(matched_df) * 100 if len(matched_df) > 0 else 0
                    print(f"   âœ… ë§¤ì¹­ ì™„ë£Œ: {success_count}/{len(matched_df)}ê°œ ({success_rate:.1f}%)")
                    
                    if hasattr(self.iherb_scraper, 'product_matcher'):
                        api_stats = self.iherb_scraper.product_matcher.get_api_usage_stats()
                        total_calls = api_stats.get('total_calls', 0)
                        vision_calls = api_stats.get('vision_calls', 0)
                        print(f"   ğŸ¤– Gemini API: {total_calls}íšŒ (Vision: {vision_calls}íšŒ)")
                
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.unlink(input_csv_path)
                    os.unlink(translated_csv_path)
                except:
                    pass
                
                return matched_df
            else:
                print(f"   âŒ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                return pd.DataFrame()

        except KeyboardInterrupt:
            print(f"\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ - í˜„ì¬ê¹Œì§€ ê²°ê³¼ê°€ {matched_csv_path}ì— ì €ì¥ë¨")
            # ì¤‘ë‹¨ë˜ì–´ë„ ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜
            if os.path.exists(matched_csv_path):
                try:
                    return pd.read_csv(matched_csv_path, encoding='utf-8-sig')
                except Exception:
                    pass
            return pd.DataFrame()
            
        except Exception as e:
            print(f"   âŒ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.coupang_crawler:
                self.coupang_crawler.close()
                print(f"   ğŸ”„ ì¿ íŒ¡ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")

            if self.iherb_scraper:
                self.iherb_scraper.close()
                print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ìŠ¤í¬ë˜í¼ ì¢…ë£Œ")

            print(f"   âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            print(f"   âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ (ë…ë¦½ ì‹¤í–‰ ì‹œì—ë§Œ)
if __name__ == "__main__":
    print("ğŸ§ª Product Updater í…ŒìŠ¤íŠ¸ ì‹¤í–‰")

    updater = ProductUpdater(enable_images=True)

    try:
        # í…ŒìŠ¤íŠ¸ìš© ì¿ íŒ¡ URL
        test_url = "https://www.coupang.com/np/search?listSize=36&filterType=coupang_global&rating=0&isPriceRange=false&minPrice=&maxPrice=&component=&sorter=scoreDesc&brand=14420&offerCondition=&filter=194176%23attr_7652%2431823%40DEFAULT&fromComponent=N&channel=user&selectedPlpKeepFilter=&q=thorne"

        print("\n1ï¸âƒ£ ì¿ íŒ¡ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸")
        crawled_df = updater.crawl_coupang_products(test_url)
        print(f"í¬ë¡¤ë§ ê²°ê³¼: {len(crawled_df)}ê°œ")

        if len(crawled_df) > 0:
            print("\n2ï¸âƒ£ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 3ê°œë§Œ)")
            test_df = crawled_df.head(3)
            # ë§¤ì¹­ ê²°ê³¼ë¥¼ ì„ì‹œ ê²½ë¡œê°€ ì•„ë‹Œ ê³ ì •ëœ ê²½ë¡œë¡œ ì €ì¥í•´ ì´ì–´ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ í…ŒìŠ¤íŠ¸
            matched_df = updater.match_iherb_products(test_df, output_path="test_matched_results.csv", brand_name="thorne")
            print(f"ë§¤ì¹­ ê²°ê³¼: {len(matched_df)}ê°œ")

        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        updater.close()