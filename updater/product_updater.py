"""
ìƒí’ˆ ì—…ë°ì´í„° ëª¨ë“ˆ - í†µí•© ì´ë¯¸ì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ
"""

import pandas as pd
import sys
import os
import tempfile

# ìƒìœ„ ë””ë ‰í† ë¦¬ì™€ coupang, iherbscraper ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
coupang_dir = os.path.join(parent_dir, 'coupang')
iherbscraper_dir = os.path.join(parent_dir, 'iherbscraper')

sys.path.insert(0, parent_dir)
sys.path.insert(0, coupang_dir)
sys.path.insert(0, iherbscraper_dir)

from coupang.crawler import CoupangCrawlerMacOS
from iherbscraper.main import EnglishIHerbScraper
from coupang.translator import GeminiCSVTranslator
from iherbscraper.config import Config


class ProductUpdater:
    """ì¿ íŒ¡ í¬ë¡¤ë§ê³¼ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ì„ í†µí•©í•œ ìƒí’ˆ ì—…ë°ì´í„° - ë‹¨ìˆœí™”ëœ ë²„ì „"""
    
    def __init__(self, enable_images: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            enable_images: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í™œì„±í™” (ì•„ì´í—ˆë¸Œ ë§¤ì¹­ìš©)
        """
        self.enable_images = enable_images
        self.coupang_crawler = None
        self.iherb_scraper = None
        self.translator = None
    
    def crawl_coupang_products(self, search_url: str) -> pd.DataFrame:
        """
        ì¿ íŒ¡ ìƒí’ˆ í¬ë¡¤ë§ - ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©
        
        Args:
            search_url: ì¿ íŒ¡ ê²€ìƒ‰ ê²°ê³¼ URL
            
        Returns:
            í¬ë¡¤ë§ëœ ìƒí’ˆ DataFrame
        """
        try:
            print(f"   í¬ë¡¤ë§ ì‹œì‘: {search_url}")
            print(f"   ì´ë¯¸ì§€ ì €ì¥: coupang/coupang_images (ê¸°ë³¸ ê²½ë¡œ)")
            
            # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” - ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©
            self.coupang_crawler = CoupangCrawlerMacOS(
                headless=False,
                delay_range=(3, 6),
                download_images=self.enable_images,
                image_dir=None  # ğŸ†• ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (coupang/coupang_images)
            )
            
            # í¬ë¡¤ë§ ì‹¤í–‰
            products = self.coupang_crawler.crawl_all_pages(search_url, max_pages=None)
            
            if products:
                # DataFrame ë³€í™˜
                crawled_df = pd.DataFrame(products)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
                required_columns = ['product_id', 'product_name', 'current_price', 'original_price', 'discount_rate']
                for col in required_columns:
                    if col not in crawled_df.columns:
                        crawled_df[col] = ''
                
                print(f"   í¬ë¡¤ë§ ì™„ë£Œ: {len(crawled_df)}ê°œ ìƒí’ˆ")
                return crawled_df
            else:
                print(f"   í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ")
                empty_df = pd.DataFrame(columns=['product_id', 'product_name', 'current_price', 'original_price', 'discount_rate'])
                return empty_df
                
        except Exception as e:
            print(f"   í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            empty_df = pd.DataFrame(columns=['product_id', 'product_name', 'current_price', 'original_price', 'discount_rate'])
            return empty_df
    
    def match_iherb_products(self, new_products_df: pd.DataFrame) -> pd.DataFrame:
        """
        ì‹ ê·œ ìƒí’ˆë“¤ì„ ì•„ì´í—ˆë¸Œì™€ ë§¤ì¹­ - ë‹¨ìˆœí™”ëœ ë²„ì „
        
        Args:
            new_products_df: ì‹ ê·œ ì¿ íŒ¡ ìƒí’ˆ DataFrame
            
        Returns:
            ë§¤ì¹­ ê²°ê³¼ DataFrame
        """
        if len(new_products_df) == 0:
            return pd.DataFrame()
        
        try:
            # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_file:
                temp_csv_path = temp_file.name
                new_products_df.to_csv(temp_csv_path, index=False, encoding='utf-8-sig')
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_translated_file:
                translated_csv_path = temp_translated_file.name
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_matched_file:
                matched_csv_path = temp_matched_file.name
            
            # 1. ë²ˆì—­ ìˆ˜í–‰
            print(f"   ë²ˆì—­ ì‹œì‘: {len(new_products_df)}ê°œ ìƒí’ˆ")
            self.translator = GeminiCSVTranslator(Config.GEMINI_API_KEY)
            
            translated_df = self.translator.translate_csv(
                input_file=temp_csv_path,
                output_file=translated_csv_path,
                column_name='product_name',
                batch_size=10
            )
            print(f"   ë²ˆì—­ ì™„ë£Œ")
            
            # 2. ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ìˆ˜í–‰ (ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©)
            print(f"   ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ì‹œì‘")
            
            self.iherb_scraper = EnglishIHerbScraper(
                headless=False,
                delay_range=(2, 4),
                max_products_to_compare=4
            )
            
            # ë§¤ì¹­ ì‹¤í–‰
            matched_csv = self.iherb_scraper.process_products_complete(
                csv_file_path=translated_csv_path,
                output_file_path=matched_csv_path,
                limit=None,
                start_from=None
            )
            
            # ë§¤ì¹­ ê²°ê³¼ ë¡œë“œ
            matched_df = pd.read_csv(matched_csv, encoding='utf-8-sig')
            
            # ì„±ê³µ í†µê³„
            success_count = len(matched_df[matched_df['status'] == 'success'])
            success_rate = success_count / len(matched_df) * 100 if len(matched_df) > 0 else 0
            
            print(f"   ë§¤ì¹­ ì„±ê³µ: {success_count}ê°œ ({success_rate:.1f}%)")
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_path in [temp_csv_path, translated_csv_path, matched_csv_path]:
                try:
                    os.unlink(temp_path)
                except:
                    pass
            
            return matched_df
            
        except Exception as e:
            print(f"   ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.coupang_crawler:
            self.coupang_crawler.close()
            print(f"   ì¿ íŒ¡ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")
        
        if self.iherb_scraper:
            self.iherb_scraper.close()
            print(f"   ì•„ì´í—ˆë¸Œ ìŠ¤í¬ë˜í¼ ì¢…ë£Œ")