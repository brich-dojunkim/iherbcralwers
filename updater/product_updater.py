"""
ìƒí’ˆ ì—…ë°ì´í„° ëª¨ë“ˆ - ë‹¨ìˆœí™”ëœ ë²„ì „ (ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©)
"""

import pandas as pd
import sys
import os
import tempfile

# ìƒìœ„ ë””ë ‰í† ë¦¬ì™€ coupang, iherbscraper ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
coupang_dir = os.path.join(parent_dir, 'coupang')
iherbscraper_dir = os.path.join(parent_dir, 'iherbscraper')

sys.path.insert(0, parent_dir)
sys.path.insert(0, coupang_dir)
sys.path.insert(0, iherbscraper_dir)

from coupang.crawler import CoupangCrawlerMacOS
from iherbscraper.main import EnglishIHerbScraper
from coupang.translator import GeminiCSVTranslator
from iherbscraper.config import Config


class ProductUpdater:
    """ì¿ íŒ¡ í¬ë¡¤ë§ê³¼ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ì„ í†µí•©í•œ ìƒí’ˆ ì—…ë°ì´í„° - ë‹¨ìˆœí™”ëœ ë²„ì „"""
    
    def __init__(self, enable_images: bool = True):
        """
        ì´ˆê¸°í™”
        
        Args:
            enable_images: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í™œì„±í™” ì—¬ë¶€
        """
        self.enable_images = enable_images
        self.coupang_crawler = None
        self.iherb_scraper = None
        self.translator = None
        
        print(f"ğŸ“‹ ìƒí’ˆ ì—…ë°ì´í„° ì´ˆê¸°í™”")
        print(f"   ì´ë¯¸ì§€ ê¸°ëŠ¥: {'í™œì„±í™”' if enable_images else 'ë¹„í™œì„±í™”'}")
        if enable_images:
            print(f"   ì´ë¯¸ì§€ ì €ì¥: ê¸°ë³¸ ê²½ë¡œ (coupang/coupang_images)")
    
    def crawl_coupang_products(self, search_url: str) -> pd.DataFrame:
        """
        ì¿ íŒ¡ ìƒí’ˆ í¬ë¡¤ë§ - ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš©
        
        Args:
            search_url: ì¿ íŒ¡ ê²€ìƒ‰ ê²°ê³¼ URL
            
        Returns:
            í¬ë¡¤ë§ëœ ìƒí’ˆ DataFrame
        """
        try:
            print(f"   ğŸ”„ ì¿ íŒ¡ í¬ë¡¤ë§ ì‹œì‘")
            print(f"   ğŸ“ URL: {search_url[:80]}...")
            
            # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” - ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ìë™ ì‚¬ìš©
            self.coupang_crawler = CoupangCrawlerMacOS(
                headless=False,
                delay_range=(3, 6),
                download_images=self.enable_images,
                image_dir=None  # ğŸ”¥ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê¸°ë³¸ ê²½ë¡œ(coupang/coupang_images) ìë™ ì‚¬ìš©
            )
            
            if self.enable_images:
                print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€ ì €ì¥ í™œì„±í™”: ìë™ ê²½ë¡œ ì‚¬ìš©")
            else:
                print(f"   ğŸ“ í…ìŠ¤íŠ¸ ì „ìš© í¬ë¡¤ë§")
            
            # í¬ë¡¤ë§ ì‹¤í–‰
            products = self.coupang_crawler.crawl_all_pages(search_url, max_pages=None)
            
            if products:
                # DataFrame ë³€í™˜
                crawled_df = pd.DataFrame(products)
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ìƒì„±
                required_columns = [
                    'product_id', 'product_name', 'current_price', 
                    'original_price', 'discount_rate'
                ]
                for col in required_columns:
                    if col not in crawled_df.columns:
                        crawled_df[col] = ''
                
                print(f"   âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(crawled_df)}ê°œ ìƒí’ˆ")
                
                # ì´ë¯¸ì§€ í†µê³„ ì¶œë ¥
                if self.enable_images and self.coupang_crawler.image_downloader:
                    stats = self.coupang_crawler.image_downloader.image_download_stats
                    successful_images = stats.get('successful_downloads', 0)
                    total_attempts = stats.get('total_attempts', 0)
                    print(f"   ğŸ“¸ ì´ë¯¸ì§€ ìˆ˜ì§‘: {successful_images}/{total_attempts}ê°œ")
                
                return crawled_df
            else:
                print(f"   âš ï¸ í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ")
                empty_df = pd.DataFrame(columns=required_columns)
                return empty_df
                
        except Exception as e:
            print(f"   âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            empty_columns = ['product_id', 'product_name', 'current_price', 'original_price', 'discount_rate']
            empty_df = pd.DataFrame(columns=empty_columns)
            return empty_df
    
    def match_iherb_products(self, new_products_df: pd.DataFrame) -> pd.DataFrame:
        """
        ì‹ ê·œ ìƒí’ˆë“¤ì„ ì•„ì´í—ˆë¸Œì™€ ë§¤ì¹­ - ë‹¨ìˆœí™”ëœ ë²„ì „
        
        Args:
            new_products_df: ì‹ ê·œ ì¿ íŒ¡ ìƒí’ˆ DataFrame
            
        Returns:
            ë§¤ì¹­ ê²°ê³¼ DataFrame
        """
        if len(new_products_df) == 0:
            print(f"   ğŸ“ ë§¤ì¹­í•  ì‹ ê·œ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
        
        try:
            print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ì‹œì‘: {len(new_products_df)}ê°œ ìƒí’ˆ")
            
            # 1. ì„ì‹œ íŒŒì¼ ìƒì„± (ìë™ ì •ë¦¬)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_file:
                temp_csv_path = temp_file.name
                new_products_df.to_csv(temp_csv_path, index=False, encoding='utf-8-sig')
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_translated_file:
                translated_csv_path = temp_translated_file.name
            
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8-sig') as temp_matched_file:
                matched_csv_path = temp_matched_file.name
            
            # 2. í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­
            print(f"   ğŸ“ ë²ˆì—­ ì‹œì‘: {len(new_products_df)}ê°œ ìƒí’ˆëª…")
            self.translator = GeminiCSVTranslator(Config.GEMINI_API_KEY)
            
            translated_df = self.translator.translate_csv(
                input_file=temp_csv_path,
                output_file=translated_csv_path,
                column_name='product_name',
                batch_size=10
            )
            print(f"   âœ… ë²ˆì—­ ì™„ë£Œ")
            
            # 3. ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ìˆ˜í–‰ (ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ìë™ ì‚¬ìš©)
            print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ìˆ˜í–‰")
            print(f"   ğŸ’¡ ê¸°ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ìë™ ì‚¬ìš© (ë‹¨ìˆœí™”)")
            
            self.iherb_scraper = EnglishIHerbScraper(
                headless=False,
                delay_range=(2, 4),
                max_products_to_compare=4
            )
            
            # ë§¤ì¹­ ì‹¤í–‰
            matched_csv = self.iherb_scraper.process_products_complete(
                csv_file_path=translated_csv_path,
                output_file_path=matched_csv_path,
                limit=None,
                start_from=None
            )
            
            # 4. ë§¤ì¹­ ê²°ê³¼ ë¡œë“œ
            matched_df = pd.read_csv(matched_csv, encoding='utf-8-sig')
            
            # 5. ì„±ê³µ í†µê³„ ì¶œë ¥
            if 'status' in matched_df.columns:
                success_count = len(matched_df[matched_df['status'] == 'success'])
                success_rate = success_count / len(matched_df) * 100 if len(matched_df) > 0 else 0
                
                print(f"   âœ… ë§¤ì¹­ ì™„ë£Œ: {success_count}/{len(matched_df)}ê°œ ({success_rate:.1f}%)")
                
                # Gemini API í†µê³„ (ìˆìœ¼ë©´ í‘œì‹œ)
                if hasattr(self.iherb_scraper, 'product_matcher'):
                    api_stats = self.iherb_scraper.product_matcher.get_api_usage_stats()
                    total_calls = api_stats.get('total_calls', 0)
                    vision_calls = api_stats.get('vision_calls', 0)
                    print(f"   ğŸ¤– Gemini API: {total_calls}íšŒ (Vision: {vision_calls}íšŒ)")
            else:
                print(f"   âš ï¸ ìƒíƒœ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ ì„±ê³µë¥  ê³„ì‚° ë¶ˆê°€")
            
            # 6. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for temp_path in [temp_csv_path, translated_csv_path, matched_csv_path]:
                try:
                    os.unlink(temp_path)
                except:
                    pass
            
            return matched_df
            
        except Exception as e:
            print(f"   âŒ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.coupang_crawler:
                self.coupang_crawler.close()
                print(f"   ğŸ”„ ì¿ íŒ¡ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")
            
            if self.iherb_scraper:
                self.iherb_scraper.close()
                print(f"   ğŸ”„ ì•„ì´í—ˆë¸Œ ìŠ¤í¬ë˜í¼ ì¢…ë£Œ")
            
            print(f"   âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âš ï¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ (ë…ë¦½ ì‹¤í–‰ ì‹œì—ë§Œ)
if __name__ == "__main__":
    print("ğŸ§ª Product Updater í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    
    updater = ProductUpdater(enable_images=True)
    
    try:
        # í…ŒìŠ¤íŠ¸ìš© ì¿ íŒ¡ URL
        test_url = "https://www.coupang.com/np/search?listSize=36&filterType=coupang_global&rating=0&isPriceRange=false&minPrice=&maxPrice=&component=&sorter=scoreDesc&brand=14420&offerCondition=&filter=194176%23attr_7652%2431823%40DEFAULT&fromComponent=N&channel=user&selectedPlpKeepFilter=&q=thorne"
        
        print("\n1ï¸âƒ£ ì¿ íŒ¡ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸")
        crawled_df = updater.crawl_coupang_products(test_url)
        print(f"í¬ë¡¤ë§ ê²°ê³¼: {len(crawled_df)}ê°œ")
        
        if len(crawled_df) > 0:
            print("\n2ï¸âƒ£ ì•„ì´í—ˆë¸Œ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 3ê°œë§Œ)")
            test_df = crawled_df.head(3)
            matched_df = updater.match_iherb_products(test_df)
            print(f"ë§¤ì¹­ ê²°ê³¼: {len(matched_df)}ê°œ")
        
        print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        updater.close()