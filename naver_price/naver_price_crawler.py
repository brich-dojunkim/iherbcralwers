"""
ë„¤ì´ë²„ ì‡¼í•‘ ê°€ê²© í¬ë¡¤ë§ ë° êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ë™
- undetected_chromedriver ì‚¬ìš©
- ë„¤ì´ë²„ ë¡œê·¸ì¸
- ìµœì €ê°€ ì¡°ì‚¬
- ì•„ì´í—ˆë¸Œ íŒë§¤ì²˜ í™•ì¸
- ë´‡ ìº¡ì°¨ ìë™ ê°ì§€ ë° ëŒ€ê¸°
"""

import time
import re
from datetime import datetime
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import gspread
from google.oauth2.service_account import Credentials
from bs4 import BeautifulSoup


class NaverPriceCrawler:
    def __init__(self, spreadsheet_id, credentials_file='credentials.json'):
        """
        ì´ˆê¸°í™”
        
        Args:
            spreadsheet_id: êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID
            credentials_file: Google API ì¸ì¦ íŒŒì¼ ê²½ë¡œ
        """
        self.spreadsheet_id = spreadsheet_id
        self.driver = None
        self.wait = None
        
        # êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²°
        self.sheet = self._connect_google_sheets(credentials_file)
    
    def _connect_google_sheets(self, credentials_file):
        """êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²°"""
        try:
            scope = [
                'https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive'
            ]
            creds = Credentials.from_service_account_file(
                credentials_file, 
                scopes=scope
            )
            client = gspread.authorize(creds)
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            spreadsheet = client.open_by_key(self.spreadsheet_id)
            
            # "0" ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸°
            sheet = spreadsheet.worksheet("0")
            print(f"âœ“ êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²° ì„±ê³µ: {spreadsheet.title}")
            return sheet
            
        except Exception as e:
            print(f"âœ— ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def setup_driver(self):
        """undetected_chromedriver ì„¤ì •"""
        options = uc.ChromeOptions()
        
        # ì˜µì…˜ ì„¤ì •
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--no-sandbox')
        
        # headless ëª¨ë“œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # options.add_argument('--headless=new')
        
        self.driver = uc.Chrome(options=options)
        self.wait = WebDriverWait(self.driver, 10)
        
        print("âœ“ í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ")
    
    def naver_login(self, user_id, user_pw):
        """
        ë„¤ì´ë²„ ë¡œê·¸ì¸
        
        Args:
            user_id: ë„¤ì´ë²„ ì•„ì´ë””
            user_pw: ë„¤ì´ë²„ ë¹„ë°€ë²ˆí˜¸
        """
        try:
            print("ë„¤ì´ë²„ ë¡œê·¸ì¸ ì‹œì‘...")
            self.driver.get('https://nid.naver.com/nidlogin.login')
            time.sleep(2)
            
            # ì•„ì´ë”” ì…ë ¥
            id_input = self.wait.until(
                EC.presence_of_element_located((By.ID, 'id'))
            )
            id_input.clear()
            id_input.send_keys(user_id)
            time.sleep(0.5)
            
            # ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
            pw_input = self.driver.find_element(By.ID, 'pw')
            pw_input.clear()
            pw_input.send_keys(user_pw)
            time.sleep(0.5)
            
            # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
            login_btn = self.driver.find_element(By.ID, 'log.login')
            login_btn.click()
            
            time.sleep(3)
            
            # ë¡œê·¸ì¸ ì‹œ ìº¡ì°¨ í™•ì¸
            self._wait_for_captcha()
            
            # ë¡œê·¸ì¸ í™•ì¸
            if 'nid.naver.com' not in self.driver.current_url:
                print("âœ“ ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ")
                return True
            else:
                print("âœ— ë„¤ì´ë²„ ë¡œê·¸ì¸ ì‹¤íŒ¨ - ìº¡ì±  ë˜ëŠ” ì¸ì¦ í•„ìš”í•  ìˆ˜ ìˆìŒ")
                input("ë¡œê·¸ì¸ì„ ìˆ˜ë™ìœ¼ë¡œ ì™„ë£Œí•œ í›„ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                return True
                
        except Exception as e:
            print(f"âœ— ë¡œê·¸ì¸ ì˜¤ë¥˜: {e}")
            return False
    
    def scroll_to_element(self, element):
        """ìš”ì†Œê¹Œì§€ ìŠ¤í¬ë¡¤"""
        self.driver.execute_script(
            "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", 
            element
        )
        time.sleep(0.5)
    
    def _wait_for_captcha(self):
        """ë´‡ ìº¡ì°¨ê°€ ë‚˜íƒ€ë‚˜ë©´ ì‚¬ìš©ìê°€ í•´ê²°í•  ë•Œê¹Œì§€ ëŒ€ê¸°"""
        try:
            # ìº¡ì°¨ ê´€ë ¨ ìš”ì†Œë“¤
            captcha_selectors = [
                '#captcha_wrap',
                '#rcpt_form',
                '.captcha_wrap',
                '[data-component="rcpt_wrap"]',
                '[data-component="vcpt_wrap"]',
                '.captcha_img'
            ]
            
            captcha_detected = False
            for selector in captcha_selectors:
                try:
                    captcha = self.driver.find_element(By.CSS_SELECTOR, selector)
                    if captcha.is_displayed():
                        captcha_detected = True
                        break
                except:
                    continue
            
            if captcha_detected:
                print("\n" + "="*60)
                print("âš ï¸  ë´‡ ìº¡ì°¨ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!")
                print("   ë¸Œë¼ìš°ì €ì—ì„œ ìº¡ì°¨ë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”.")
                print("   (ì´ë¯¸ì§€ì—ì„œ ì •ë‹µì„ ì…ë ¥í•˜ê³  í™•ì¸ ë²„íŠ¼ í´ë¦­)")
                print("="*60)
                
                # ìº¡ì°¨ê°€ ì‚¬ë¼ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°
                while True:
                    captcha_exists = False
                    for selector in captcha_selectors:
                        try:
                            captcha = self.driver.find_element(By.CSS_SELECTOR, selector)
                            if captcha.is_displayed():
                                captcha_exists = True
                                break
                        except:
                            continue
                    
                    if not captcha_exists:
                        break
                    
                    time.sleep(1)
                
                print("âœ“ ìº¡ì°¨ í•´ê²° ì™„ë£Œ")
                time.sleep(2)
                    
        except Exception as e:
            # ìº¡ì°¨ê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì§„í–‰
            pass
    
    def get_lowest_price(self, url):
        """
        ìµœì €ê°€ ì¡°íšŒ
        
        Args:
            url: ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆ URL
            
        Returns:
            dict: {'price': ìµœì €ê°€, 'shipping': ë°°ì†¡ë¹„, 'mall': íŒë§¤ì²˜}
        """
        try:
            print(f"\nìƒí’ˆ URL ì ‘ì†: {url}")
            self.driver.get(url)
            time.sleep(2)
            
            # ë´‡ ìº¡ì°¨ í™•ì¸
            self._wait_for_captcha()
            
            # í˜ì´ì§€ ìŠ¤í¬ë¡¤ (íŒë§¤ì²˜ ì„ íƒë³´ê¸° ìš”ì†Œê°€ ë³´ì´ë„ë¡)
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            time.sleep(1)
            
            # HTML íŒŒì‹±
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # ìµœì €ê°€ ì¶”ì¶œ
            lowest_price = None
            price_elem = soup.select_one('.lowestPrice_num__adgCI')
            if price_elem:
                price_text = price_elem.get_text(strip=True).replace(',', '')
                lowest_price = int(price_text)
            
            # ë°°ì†¡ë¹„ ì¶”ì¶œ
            shipping_text = "í™•ì¸í•„ìš”"
            shipping_elem = soup.select_one('.lowestPrice_delivery_fee__COSVN')
            if shipping_elem:
                shipping_text = shipping_elem.get_text(strip=True)
            
            # íŒë§¤ì²˜ ì¶”ì¶œ
            mall_name = "í™•ì¸í•„ìš”"
            mall_elem = soup.select_one('.lowestPrice_cell__1_Cz0:nth-child(2)')
            if mall_elem:
                mall_name = mall_elem.get_text(strip=True)
            
            print(f"  ìµœì €ê°€: {lowest_price}ì›")
            print(f"  ë°°ì†¡ë¹„: {shipping_text}")
            print(f"  íŒë§¤ì²˜: {mall_name}")
            
            return {
                'price': lowest_price,
                'shipping': shipping_text,
                'mall': mall_name
            }
            
        except Exception as e:
            print(f"âœ— ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'price': None,
                'shipping': "ì˜¤ë¥˜",
                'mall': "ì˜¤ë¥˜"
            }
    
    def check_iherb_available(self, url):
        """
        ì•„ì´í—ˆë¸Œ íŒë§¤ ì—¬ë¶€ í™•ì¸
        
        Args:
            url: ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆ URL
            
        Returns:
            bool: ì•„ì´í—ˆë¸Œ íŒë§¤ ì—¬ë¶€
        """
        try:
            print("ì•„ì´í—ˆë¸Œ íŒë§¤ì²˜ í™•ì¸ ì¤‘...")
            
            # ì´ë¯¸ í•´ë‹¹ í˜ì´ì§€ì— ìˆë‹¤ê³  ê°€ì •
            if self.driver.current_url != url:
                self.driver.get(url)
                time.sleep(2)
                
                # ë´‡ ìº¡ì°¨ í™•ì¸
                self._wait_for_captcha()
            
            # í˜ì´ì§€ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤ (í—¤ë” í”¼í•˜ê¸°)
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            time.sleep(1)
            
            # íŒë§¤ì²˜ ì„ íƒë³´ê¸° ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­
            try:
                # ì˜¬ë°”ë¥¸ ì„ íƒì ì‚¬ìš©
                select_mall_btn = self.wait.until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, '.filter_check_mall__IK03K')
                    )
                )
                
                # ìš”ì†Œê°€ ë³´ì´ë„ë¡ ì¶”ê°€ ìŠ¤í¬ë¡¤
                self.driver.execute_script(
                    "arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", 
                    select_mall_btn
                )
                time.sleep(1)
                
                # JavaScriptë¡œ í´ë¦­ (í—¤ë” ê°„ì„­ ë°©ì§€)
                self.driver.execute_script("arguments[0].click();", select_mall_btn)
                print("  íŒë§¤ì²˜ ì„ íƒ ë ˆì´ì–´ ì—´ë¦¼")
                time.sleep(2)
                
                # ë ˆì´ì–´ ì˜¤í”ˆ í›„ ìº¡ì°¨ í™•ì¸
                self._wait_for_captcha()
                
                # íŒë§¤ì²˜ ëª©ë¡ì—ì„œ ì•„ì´í—ˆë¸Œ ê²€ìƒ‰
                soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                
                # ì•„ì´í—ˆë¸Œ í‚¤ì›Œë“œ
                iherb_keywords = ['ì•„ì´í—ˆë¸Œ', 'iherb', 'iHerb', 'ì•„ì´í—ˆë¸Œ ê³µì‹']
                
                # íŒë§¤ì²˜ ëª©ë¡ ê²€ìƒ‰
                mall_labels = soup.select('.filter_text__yBa_v')
                
                for mall in mall_labels:
                    mall_text = mall.get_text(strip=True)
                    for keyword in iherb_keywords:
                        if keyword.lower() in mall_text.lower():
                            print(f"  âœ“ ì•„ì´í—ˆë¸Œ íŒë§¤ì²˜ ë°œê²¬: {mall_text}")
                            
                            # ë ˆì´ì–´ ë‹«ê¸° (ì·¨ì†Œ ë²„íŠ¼ í´ë¦­)
                            try:
                                cancel_btn = self.driver.find_element(
                                    By.CSS_SELECTOR, 
                                    '.filter_btn_cancel__wIx02'
                                )
                                self.driver.execute_script("arguments[0].click();", cancel_btn)
                                time.sleep(0.5)
                            except:
                                # ESC í‚¤ë¡œ ë‹«ê¸° ì‹œë„
                                from selenium.webdriver.common.action_chains import ActionChains
                                ActionChains(self.driver).send_keys(Keys.ESCAPE).perform()
                                time.sleep(0.5)
                            
                            return True
                
                print("  âœ— ì•„ì´í—ˆë¸Œ íŒë§¤ì²˜ ì—†ìŒ")
                
                # ë ˆì´ì–´ ë‹«ê¸°
                try:
                    cancel_btn = self.driver.find_element(
                        By.CSS_SELECTOR, 
                        '.filter_btn_cancel__wIx02'
                    )
                    self.driver.execute_script("arguments[0].click();", cancel_btn)
                    time.sleep(0.5)
                except:
                    from selenium.webdriver.common.action_chains import ActionChains
                    ActionChains(self.driver).send_keys(Keys.ESCAPE).perform()
                    time.sleep(0.5)
                
                return False
                
            except TimeoutException:
                print("  ! íŒë§¤ì²˜ ì„ íƒë³´ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                
                # í˜ì´ì§€ ì „ì²´ì—ì„œ ì•„ì´í—ˆë¸Œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ëŒ€ì•ˆ)
                soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                page_text = soup.get_text().lower()
                
                if 'ì•„ì´í—ˆë¸Œ' in page_text or 'iherb' in page_text:
                    print("  âœ“ í˜ì´ì§€ ë‚´ ì•„ì´í—ˆë¸Œ í‚¤ì›Œë“œ ë°œê²¬")
                    return True
                
                return False
                
        except Exception as e:
            print(f"âœ— ì•„ì´í—ˆë¸Œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            print("\në¸Œë¼ìš°ì € ì¢…ë£Œ")
        
    def process_urls(self):
        """
        URL ì¼ê´„ ì²˜ë¦¬ (ë‚ ì§œë³„ ëˆ„ì  + ë‚ ì§œ í–‰ ë³‘í•©)
        """
        try:
            # ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            all_data = self.sheet.get_all_values()
            
            if not all_data or len(all_data) < 2:
                print("ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # 1í–‰: ë‚ ì§œ (ë³‘í•©ìš©)
            # 2í–‰: í•­ëª©ëª… (ì•„ì´í—ˆë¸Œ, ìµœì €ê°€)
            date_row = all_data[0] if len(all_data) > 0 else []
            headers = all_data[1] if len(all_data) > 1 else []
            
            print(f"í˜„ì¬ í—¤ë” ê°œìˆ˜: {len(headers)}ê°œ")
            
            # URL ì»¬ëŸ¼ ì°¾ê¸° (D ì»¬ëŸ¼)
            url_col_idx = None
            for idx, header in enumerate(headers):
                if header and ('url' in header.lower() or header == 'URL'):
                    url_col_idx = idx
                    break
            
            if url_col_idx is None:
                print("URL ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"URL ì»¬ëŸ¼ ìœ„ì¹˜: {chr(65+url_col_idx)} (ì¸ë±ìŠ¤ {url_col_idx})")
            
            # ì˜¤ëŠ˜ ë‚ ì§œ
            today = datetime.now().strftime('%Y-%m-%d')
            print(f"\nğŸ“… ì²˜ë¦¬ ë‚ ì§œ: {today}")
            
            # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì»¬ëŸ¼ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (1í–‰ì˜ ë‚ ì§œ í™•ì¸)
            today_start_col = None
            for idx in range(len(date_row)):
                if date_row[idx] and today in date_row[idx]:
                    today_start_col = idx
                    print(f"âš ï¸  ê°™ì€ ë‚ ì§œ ì»¬ëŸ¼ ë°œê²¬ â†’ ë®ì–´ì“°ê¸° ëª¨ë“œ")
                    break
            
            # ì˜¤ëŠ˜ ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
            if today_start_col is None:
                # ë§ˆì§€ë§‰ ì»¬ëŸ¼ ë‹¤ìŒì— ì¶”ê°€
                today_start_col = len(headers)
                
                # 1í–‰ì— ë‚ ì§œ ì¶”ê°€ (ë³‘í•©ìš©)
                new_date_row = date_row.copy()
                while len(new_date_row) < today_start_col:
                    new_date_row.append('')
                new_date_row.append(today)  # Eì—´ì— ë‚ ì§œ
                new_date_row.append('')      # Fì—´ì€ ë¹„ì›€ (ë³‘í•©ë  ë¶€ë¶„)
                
                # 2í–‰ì— í•­ëª©ëª… ì¶”ê°€
                new_headers = headers.copy()
                while len(new_headers) < today_start_col:
                    new_headers.append('')
                new_headers.append('ì•„ì´í—ˆë¸Œ')
                new_headers.append('ìµœì €ê°€')
                
                # 1í–‰ê³¼ 2í–‰ ì—…ë°ì´íŠ¸
                update_range = f'A1:{chr(65+len(new_date_row)-1)}2'
                self.sheet.update([new_date_row, new_headers], update_range)
                
                # ì…€ ë³‘í•© (E1:F1 ë³‘í•©)
                merge_range = f'{chr(65+today_start_col)}1:{chr(65+today_start_col+1)}1'
                self.sheet.merge_cells(merge_range, merge_type='MERGE_ALL')
                
                print(f"âœ“ ìƒˆë¡œìš´ ë‚ ì§œ ì»¬ëŸ¼ ì¶”ê°€: {chr(65+today_start_col)}~{chr(65+today_start_col+1)}ì—´")
                print(f"âœ“ ë‚ ì§œ ë³‘í•©: {merge_range}")
                
                date_row = new_date_row
                headers = new_headers
            else:
                print(f"âœ“ ê¸°ì¡´ ì»¬ëŸ¼ ì‚¬ìš©: {chr(65+today_start_col)}ì—´ë¶€í„°")
            
            # ì»¬ëŸ¼ ìœ„ì¹˜
            iherb_col = today_start_col
            price_col = today_start_col + 1
            
            print(f"  ğŸ“ ì•„ì´í—ˆë¸Œ: {chr(65+iherb_col)}ì—´")
            print(f"  ğŸ“ ìµœì €ê°€: {chr(65+price_col)}ì—´")
            
            # ì‹¤ì œ URLì´ ìˆëŠ” í–‰ ì°¾ê¸° (3í–‰ë¶€í„° - 1í–‰ ë‚ ì§œ, 2í–‰ í—¤ë”)
            url_rows = []
            for row_idx in range(2, len(all_data)):
                row_data = all_data[row_idx]
                
                if len(row_data) > url_col_idx:
                    url = row_data[url_col_idx]
                    if url and url.strip() and url.startswith('http'):
                        url_rows.append(row_idx)
            
            if not url_rows:
                print("\nì²˜ë¦¬í•  URLì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"\nğŸ“Š ì´ {len(url_rows)}ê°œì˜ URL ë°œê²¬")
            print(f"   ì‹œì‘ í–‰: {url_rows[0] + 1}")
            print(f"   ì¢…ë£Œ í–‰: {url_rows[-1] + 1}")
            
            # URL ì²˜ë¦¬
            for idx, row_idx in enumerate(url_rows):
                row_data = all_data[row_idx]
                url = row_data[url_col_idx]
                
                print(f"\n{'='*60}")
                print(f"[{idx + 1}/{len(url_rows)}] í–‰ {row_idx + 1} ì²˜ë¦¬ ì‹œì‘")
                print(f"{'='*60}")
                
                # ìµœì €ê°€ ì¡°íšŒ
                price_info = self.get_lowest_price(url)
                
                # ì•„ì´í—ˆë¸Œ íŒë§¤ í™•ì¸
                has_iherb = self.check_iherb_available(url)
                
                # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—…ë°ì´íŠ¸
                result_row = row_idx + 1
                
                # ë°°ì¹˜ ì—…ë°ì´íŠ¸ (2ê°œ ì…€ë§Œ)
                update_range = f'{chr(65+iherb_col)}{result_row}:{chr(65+price_col)}{result_row}'
                update_values = [[
                    'O' if has_iherb else 'X',
                    price_info['price']
                ]]
                
                self.sheet.update(update_values, update_range)
                
                print(f"\nâœ… í–‰ {result_row} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                print(f"   ì•„ì´í—ˆë¸Œ: {'O' if has_iherb else 'X'}")
                print(f"   ìµœì €ê°€: {price_info['price']}ì›")
                
                # ìš”ì²­ ê°„ ë”œë ˆì´
                time.sleep(2)
            
            print(f"\n{'='*60}")
            print(f"âœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"   ì²˜ë¦¬ëœ URL: {len(url_rows)}ê°œ")
            print(f"   ì €ì¥ ìœ„ì¹˜: {chr(65+iherb_col)}~{chr(65+price_col)}ì—´")
            print(f"{'='*60}")
            
        except Exception as e:
            print(f"âœ— URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            raise

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # ì„¤ì •
    SPREADSHEET_ID = '1o2xj4R02Wr4QDhfR3VdQSYbtoaueZzEZend15DqObR8'
    CREDENTIALS_FILE = 'credentials.json'  # Google API ì¸ì¦ íŒŒì¼
    
    # ë„¤ì´ë²„ ê³„ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì•ˆì „í•œ ë°©ë²•ìœ¼ë¡œ ê´€ë¦¬ ê¶Œì¥)
    NAVER_ID = input("ë„¤ì´ë²„ ID: ")
    NAVER_PW = input("ë„¤ì´ë²„ PW: ")
    
    crawler = None
    
    try:
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        crawler = NaverPriceCrawler(SPREADSHEET_ID, CREDENTIALS_FILE)
        
        # ë“œë¼ì´ë²„ ì„¤ì •
        crawler.setup_driver()
        
        # ë„¤ì´ë²„ ë¡œê·¸ì¸
        if not crawler.naver_login(NAVER_ID, NAVER_PW):
            print("ë¡œê·¸ì¸ ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        # URL ì²˜ë¦¬ (ìë™ìœ¼ë¡œ ëª¨ë“  URL ì²˜ë¦¬)
        crawler.process_urls()
        
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        
    finally:
        if crawler:
            crawler.close()


if __name__ == "__main__":
    main()