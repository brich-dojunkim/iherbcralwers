#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìˆœìˆ˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° ë³€í™” ê°ì§€
ì¿ íŒ¡ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìˆ˜ì§‘í•˜ì—¬ ë³€í™” ì¶”ì 
"""

import sys
import os
import time
import re
import sqlite3
import random
from datetime import datetime
from bs4 import BeautifulSoup

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
sys.path.insert(0, os.path.join(parent_dir, 'coupang'))

from coupang.coupang_manager import BrowserManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


class CategoryMonitoringDatabase:
    """ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë‹ˆí„°ë§ ì „ìš© ë°ì´í„°ë² ì´ìŠ¤"""
    
    def __init__(self, db_path="page_monitoring.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì´ˆê¸°í™” - ìˆœìˆ˜ ëª¨ë‹ˆí„°ë§ìš©"""
        conn = sqlite3.connect(self.db_path)
        
        # 1. ì¹´í…Œê³ ë¦¬ í…Œì´ë¸”
        conn.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT UNIQUE NOT NULL,
                url TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 2. ë§¤ì¹­ ì°¸ì¡° í…Œì´ë¸” (CSVì—ì„œ ë¡œë“œ)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS matching_reference (
                coupang_product_id TEXT PRIMARY KEY,
                coupang_product_name TEXT,
                coupang_product_url TEXT,
                original_category TEXT,
                iherb_upc TEXT,
                iherb_part_number TEXT,
                created_from_csv BOOLEAN DEFAULT TRUE,
                created_time DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # 3. í˜ì´ì§€ ìŠ¤ëƒ…ìƒ· í…Œì´ë¸” (ì¹´í…Œê³ ë¦¬ë³„)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS page_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category_id INTEGER NOT NULL,
                category_name TEXT NOT NULL,
                page_url TEXT NOT NULL,
                snapshot_time DATETIME DEFAULT CURRENT_TIMESTAMP,
                total_products INTEGER,
                crawl_duration_seconds REAL,
                status TEXT DEFAULT 'completed',
                FOREIGN KEY (category_id) REFERENCES categories (id)
            )
        """)
        
        # 4. ìƒí’ˆ ìƒíƒœ í…Œì´ë¸” (ì¹´í…Œê³ ë¦¬ë³„ ìˆœìœ„)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS product_states (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                snapshot_id INTEGER NOT NULL,
                coupang_product_id TEXT NOT NULL,
                category_rank INTEGER NOT NULL,
                
                -- ì¿ íŒ¡ ì‹¤ì‹œê°„ ì •ë³´
                product_name TEXT,
                product_url TEXT,
                current_price INTEGER,
                original_price INTEGER,
                discount_rate INTEGER,
                review_count INTEGER,
                rating_score REAL,
                is_rocket_delivery BOOLEAN,
                is_free_shipping BOOLEAN,
                cashback_amount INTEGER,
                delivery_info TEXT,
                
                -- ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ì •ë³´
                iherb_upc TEXT,
                iherb_part_number TEXT,
                matching_status TEXT DEFAULT 'unknown',
                
                FOREIGN KEY (snapshot_id) REFERENCES page_snapshots (id)
            )
        """)
        
        # 5. ë³€í™” ì´ë²¤íŠ¸ ë¡œê·¸ í…Œì´ë¸” (ì¹´í…Œê³ ë¦¬ ì •ë³´ í¬í•¨)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS change_events (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                coupang_product_id TEXT NOT NULL,
                category_name TEXT NOT NULL,
                event_type TEXT NOT NULL,
                old_value TEXT,
                new_value TEXT,
                description TEXT,
                event_time DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ì¸ë±ìŠ¤ ìƒì„±
        conn.execute("CREATE INDEX IF NOT EXISTS idx_product_states_snapshot ON product_states(snapshot_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_product_states_product ON product_states(coupang_product_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_product_states_category_rank ON product_states(snapshot_id, category_rank)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_change_events_product ON change_events(coupang_product_id)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_change_events_category ON change_events(category_name)")
        
        conn.commit()
        conn.close()
    
    def register_category(self, name, url):
        """ì¹´í…Œê³ ë¦¬ ë“±ë¡"""
        conn = sqlite3.connect(self.db_path)
        try:
            conn.execute("""
                INSERT OR REPLACE INTO categories (name, url)
                VALUES (?, ?)
            """, (name, url))
            conn.commit()
            
            category_id = conn.execute("""
                SELECT id FROM categories WHERE name = ?
            """, (name,)).fetchone()[0]
            
            return category_id
        finally:
            conn.close()
    
    def load_csv_baseline(self, csv_path):
        """CSV ë² ì´ìŠ¤ë¼ì¸ ë¡œë“œ (ë§¤ì¹­ ì°¸ì¡°ìš©)"""
        import pandas as pd
        
        try:
            df = pd.read_csv(csv_path, encoding='utf-8-sig')
            
            conn = sqlite3.connect(self.db_path)
            
            for _, row in df.iterrows():
                product_id = str(row.get('coupang_product_id', ''))
                if not product_id:
                    continue
                
                conn.execute("""
                    INSERT OR REPLACE INTO matching_reference 
                    (coupang_product_id, coupang_product_name, coupang_product_url,
                     original_category, iherb_upc, iherb_part_number)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    product_id,
                    str(row.get('coupang_product_name', '')),
                    str(row.get('coupang_product_url', '')),
                    str(row.get('category', '')),
                    str(row.get('iherb_upc', '')),
                    str(row.get('iherb_part_number', ''))
                ))
            
            conn.commit()
            conn.close()
            
            print(f"CSV ë² ì´ìŠ¤ë¼ì¸ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒí’ˆ")
            
        except Exception as e:
            print(f"CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_snapshot(self, category_name, page_url, products, crawl_duration):
        """ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        conn = sqlite3.connect(self.db_path)
        
        # ì¹´í…Œê³ ë¦¬ ID ì¡°íšŒ
        category_id = conn.execute("""
            SELECT id FROM categories WHERE name = ?
        """, (category_name,)).fetchone()[0]
        
        # ìŠ¤ëƒ…ìƒ· ìƒì„±
        cursor = conn.execute("""
            INSERT INTO page_snapshots 
            (category_id, category_name, page_url, total_products, crawl_duration_seconds)
            VALUES (?, ?, ?, ?, ?)
        """, (category_id, category_name, page_url, len(products), crawl_duration))
        
        snapshot_id = cursor.lastrowid
        
        # ìƒí’ˆ ìƒíƒœ ì €ì¥
        for product in products:
            # ë§¤ì¹­ ì •ë³´ ì¡°íšŒ
            matching_info = conn.execute("""
                SELECT iherb_upc, iherb_part_number 
                FROM matching_reference 
                WHERE coupang_product_id = ?
            """, (product['product_id'],)).fetchone()
            
            iherb_upc = matching_info[0] if matching_info else None
            iherb_part_number = matching_info[1] if matching_info else None
            matching_status = 'matched' if iherb_upc else 'unmatched'
            
            conn.execute("""
                INSERT INTO product_states 
                (snapshot_id, coupang_product_id, category_rank,
                 product_name, product_url, current_price, original_price,
                 discount_rate, review_count, rating_score,
                 is_rocket_delivery, is_free_shipping, cashback_amount, delivery_info,
                 iherb_upc, iherb_part_number, matching_status)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                snapshot_id, product['product_id'], product['rank'],
                product['product_name'], product['product_url'],
                product.get('current_price', 0), product.get('original_price', 0),
                product.get('discount_rate', 0), product.get('review_count', 0),
                product.get('rating_score', 0.0),
                product.get('is_rocket_delivery', False),
                product.get('is_free_shipping', False),
                product.get('cashback_amount', 0),
                product.get('delivery_info', ''),
                iherb_upc, iherb_part_number, matching_status
            ))
        
        conn.commit()
        conn.close()
        
        return snapshot_id
    
    def get_latest_snapshot_data(self, category_name):
        """ìµœì‹  ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì¡°íšŒ"""
        conn = sqlite3.connect(self.db_path)
        
        query = """
        SELECT 
            ps.coupang_product_id as product_id,
            ps.category_rank as rank,
            ps.product_name,
            ps.product_url,
            ps.current_price,
            ps.original_price,
            ps.discount_rate,
            ps.review_count
        FROM product_states ps
        JOIN page_snapshots snap ON ps.snapshot_id = snap.id
        WHERE snap.category_name = ?
        AND snap.id = (
            SELECT MAX(id) FROM page_snapshots WHERE category_name = ?
        )
        ORDER BY ps.category_rank
        """
        
        cursor = conn.execute(query, (category_name, category_name))
        products = []
        
        for row in cursor:
            products.append({
                'product_id': row[0],
                'rank': row[1],
                'product_name': row[2],
                'product_url': row[3],
                'current_price': row[4],
                'original_price': row[5],
                'discount_rate': row[6],
                'review_count': row[7]
            })
        
        conn.close()
        return products
    
    def log_change_event(self, product_id, category_name, event_type, old_value, new_value, description):
        """ë³€í™” ì´ë²¤íŠ¸ ë¡œê¹…"""
        conn = sqlite3.connect(self.db_path)
        conn.execute("""
            INSERT INTO change_events 
            (coupang_product_id, category_name, event_type, old_value, new_value, description)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (product_id, category_name, event_type, str(old_value), str(new_value), description))
        conn.commit()
        conn.close()


class InfiniteScrollExtractor:
    """ë¬´í•œ ìŠ¤í¬ë¡¤ ìƒí’ˆ ì¶”ì¶œê¸°"""
    
    def __init__(self, browser_manager):
        self.browser = browser_manager
    
    @property
    def driver(self):
        """ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì ‘ê·¼"""
        return self.browser.driver if self.browser else None
    
    def extract_all_products_with_scroll(self, page_url):
        """ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ìƒí’ˆ ì¶”ì¶œ"""
        if not self.driver:
            print("âŒ ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []
        
        try:
            print(f"ë¬´í•œ ìŠ¤í¬ë¡¤ í¬ë¡¤ë§ ì‹œì‘: {page_url}")
            self.driver.get(page_url)
            time.sleep(random.uniform(3, 5))
            
            # íŒë§¤ëŸ‰ìˆœ í•„í„° ì ìš©
            self._click_sales_filter()
            
            all_products = []
            seen_product_ids = set()
            scroll_count = 0
            max_scrolls = 200
            no_new_products_count = 0
            max_no_new_attempts = 15
            consecutive_no_height_change = 0
            
            print("ğŸ“œ ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  ìƒí’ˆ ìˆ˜ì§‘ ì¤‘...")
            
            while scroll_count < max_scrolls:
                scroll_count += 1
                
                # í˜„ì¬ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ì¶”ì¶œ
                new_products = self._extract_products_from_current_page(seen_product_ids)
                
                if new_products:
                    all_products.extend(new_products)
                    no_new_products_count = 0
                    consecutive_no_height_change = 0
                    print(f"  [ìŠ¤í¬ë¡¤ {scroll_count}] ì‹ ê·œ: {len(new_products)}ê°œ, ì´: {len(all_products)}ê°œ")
                else:
                    no_new_products_count += 1
                
                # ìŠ¤í¬ë¡¤
                height_changed = self._scroll_to_bottom()
                
                if not height_changed:
                    consecutive_no_height_change += 1
                    
                    # 5íšŒ ì—°ì† ë†’ì´ ë³€í™” ì—†ìœ¼ë©´ì„œ ì‹ ê·œë„ ì—†ìœ¼ë©´ ì¢…ë£Œ
                    if consecutive_no_height_change >= 5 and no_new_products_count >= 5:
                        print(f"ğŸ ë” ì´ìƒ ì‹ ê·œ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
                        break
                else:
                    consecutive_no_height_change = 0
                
                # ì˜¤ë˜ ì‹ ê·œ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if no_new_products_count >= max_no_new_attempts:
                    print(f"ğŸ {max_no_new_attempts}íšŒ ì—°ì† ì‹ ê·œ ì—†ìŒ, í¬ë¡¤ë§ ì¢…ë£Œ")
                    break
                
                time.sleep(random.uniform(1, 2))
            
            print(f"âœ… ë¬´í•œ ìŠ¤í¬ë¡¤ ì™„ë£Œ: ì´ {len(all_products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘")
            return all_products
            
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _click_sales_filter(self):
        """íŒë§¤ëŸ‰ìˆœ í•„í„° í´ë¦­"""
        try:
            print("ğŸ” íŒë§¤ëŸ‰ìˆœ í•„í„° ì ìš© ì¤‘...")
            time.sleep(2)
            
            filter_buttons = self.driver.find_elements(By.CSS_SELECTOR, 'li.sortkey')
            
            for button in filter_buttons:
                try:
                    if 'íŒë§¤ëŸ‰ìˆœ' in button.text:
                        button.click()
                        print("âœ… íŒë§¤ëŸ‰ìˆœ í•„í„° ì ìš© ì™„ë£Œ")
                        time.sleep(3)
                        return
                except:
                    continue
            
            print("âš ï¸ íŒë§¤ëŸ‰ìˆœ í•„í„° ì—†ìŒ (ê¸°ë³¸ ì •ë ¬ ì‚¬ìš©)")
        except Exception as e:
            print(f"âš ï¸ í•„í„° ì ìš© ì˜¤ë¥˜: {e}")
    
    def _extract_products_from_current_page(self, seen_product_ids):
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ì‹ ê·œ ìƒí’ˆë§Œ ì¶”ì¶œ"""
        try:
            new_products = []
            
            product_elements = self.driver.find_elements(By.CSS_SELECTOR, 'li.product-wrap')
            
            for element in product_elements:
                try:
                    link_elem = element.find_element(By.CSS_SELECTOR, 'a.product-wrapper')
                    product_url = link_elem.get_attribute('href')
                    
                    if not product_url:
                        continue
                    
                    match = re.search(r'itemId=(\d+)', product_url)
                    if not match:
                        continue
                    
                    product_id = match.group(1)
                    
                    if product_id in seen_product_ids:
                        continue
                    
                    seen_product_ids.add(product_id)
                    
                    # ìƒí’ˆ ë°ì´í„° íŒŒì‹±
                    product_data = self._parse_product_data(element, product_id, product_url)
                    if product_data and product_data.get('product_name'):
                        new_products.append(product_data)
                
                except:
                    continue
            
            return new_products
            
        except:
            return []
    
    def _parse_product_data(self, element, product_id, product_url):
        """ìƒí’ˆ ë°ì´í„° íŒŒì‹±"""
        try:
            html = element.get_attribute('outerHTML')
            soup = BeautifulSoup(html, 'html.parser')
            
            # ìƒí’ˆëª… (í•„ìˆ˜)
            name_elem = soup.select_one('div.name, div.product-name, div[class*="name"]')
            if not name_elem:
                return None
            
            product_name = name_elem.get_text(strip=True)
            if not product_name:
                return None
            
            # ê°€ê²©
            current_price = 0
            price_selectors = ['strong.price-value', 'span.price-value', 'em.sale', 'span[class*="price"]']
            
            for selector in price_selectors:
                price_elem = soup.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    price_text = re.sub(r'[^\d]', '', price_text)
                    if price_text:
                        current_price = int(price_text)
                        break
            
            # í• ì¸ìœ¨
            discount_rate = 0
            discount_selectors = ['span.discount-percentage', 'em.discount-rate', 'span[class*="discount"]']
            
            for selector in discount_selectors:
                discount_elem = soup.select_one(selector)
                if discount_elem:
                    discount_text = discount_elem.get_text(strip=True)
                    discount_text = re.sub(r'[^\d]', '', discount_text)
                    if discount_text:
                        discount_rate = int(discount_text)
                        break
            
            # ë¦¬ë·° ìˆ˜
            review_count = 0
            review_selectors = ['span.rating-total-count', 'span[class*="review"]', 'em.rating-count']
            
            for selector in review_selectors:
                review_elem = soup.select_one(selector)
                if review_elem:
                    review_text = review_elem.get_text(strip=True)
                    review_text = re.sub(r'[^\d]', '', review_text)
                    if review_text:
                        review_count = int(review_text)
                        break
            
            # í‰ì 
            rating_score = 0.0
            rating_elem = soup.select_one('em.rating, span[class*="rating"]')
            if rating_elem:
                try:
                    rating_text = rating_elem.get_text(strip=True)
                    rating_score = float(re.sub(r'[^\d.]', '', rating_text))
                except:
                    pass
            
            return {
                'product_id': product_id,
                'product_name': product_name,
                'product_url': product_url,
                'current_price': current_price,
                'discount_rate': discount_rate,
                'review_count': review_count,
                'rating_score': rating_score,
                'rank': 0
            }
            
        except:
            return None
    
    def _scroll_to_bottom(self):
        """ìŠ¤í¬ë¡¤ & ìƒˆ ì½˜í…ì¸  í™•ì¸"""
        try:
            last_height = self.driver.execute_script("return document.body.scrollHeight")
            
            # ì²œì²œíˆ ë‹¨ê³„ì ìœ¼ë¡œ ìŠ¤í¬ë¡¤
            scroll_steps = random.randint(3, 5)
            for i in range(scroll_steps):
                scroll_amount = (last_height / scroll_steps) * (i + 1)
                self.driver.execute_script(f"window.scrollTo(0, {scroll_amount});")
                time.sleep(0.3)
            
            # ì™„ì „íˆ ëê¹Œì§€
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # ìƒˆ ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
            for _ in range(5):
                time.sleep(1)
                new_height = self.driver.execute_script("return document.body.scrollHeight")
                if new_height > last_height:
                    return True
            
            return False
            
        except:
            return False


class CategoryChangeDetector:
    """ì¹´í…Œê³ ë¦¬ ë³€í™” ê°ì§€ê¸°"""
    
    def detect_changes(self, previous_products, current_products):
        """ì´ì „ ë°ì´í„°ì™€ í˜„ì¬ ë°ì´í„° ë¹„êµ"""
        changes = {
            'new_products': [],
            'removed_products': [],
            'rank_changes': [],
            'price_changes': []
        }
        
        # ìˆœìœ„ í• ë‹¹
        for idx, product in enumerate(current_products, 1):
            product['rank'] = idx
        
        # ì´ì „ ìƒí’ˆ ID ì„¸íŠ¸
        prev_ids = {p['product_id']: p for p in previous_products}
        curr_ids = {p['product_id']: p for p in current_products}
        
        # ì‹ ê·œ ìƒí’ˆ
        for pid in curr_ids:
            if pid not in prev_ids:
                changes['new_products'].append(curr_ids[pid])
        
        # ì œê±°ëœ ìƒí’ˆ
        for pid in prev_ids:
            if pid not in curr_ids:
                changes['removed_products'].append(prev_ids[pid])
        
        # ìˆœìœ„ ë° ê°€ê²© ë³€í™”
        for pid in set(prev_ids.keys()) & set(curr_ids.keys()):
            old_product = prev_ids[pid]
            new_product = curr_ids[pid]
            
            # ìˆœìœ„ ë³€í™”
            if old_product['rank'] != new_product['rank']:
                changes['rank_changes'].append({
                    'product_id': pid,
                    'product_name': new_product['product_name'],
                    'old_rank': old_product['rank'],
                    'new_rank': new_product['rank'],
                    'rank_change': old_product['rank'] - new_product['rank']
                })
            
            # ê°€ê²© ë³€í™”
            if old_product['current_price'] != new_product['current_price']:
                changes['price_changes'].append({
                    'product_id': pid,
                    'product_name': new_product['product_name'],
                    'old_price': old_product['current_price'],
                    'new_price': new_product['current_price'],
                    'price_change': new_product['current_price'] - old_product['current_price']
                })
        
        return changes


class CategoryPageMonitor:
    """ì¹´í…Œê³ ë¦¬ë³„ í˜ì´ì§€ ëª¨ë‹ˆí„°ë§ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, category_config, csv_baseline_path=None, db_path="page_monitoring.db", headless=True):
        self.category_config = category_config
        self.db = CategoryMonitoringDatabase(db_path)
        self.browser = BrowserManager(headless=headless)
        self.extractor = None
        self.change_detector = CategoryChangeDetector()
        
        # ì¹´í…Œê³ ë¦¬ ë“±ë¡
        self.category_id = self.db.register_category(
            category_config['name'], 
            category_config['url']
        )
        
        # CSV ë² ì´ìŠ¤ë¼ì¸ ë¡œë“œ (ì´ˆê¸° 1íšŒë§Œ)
        if csv_baseline_path:
            self.db.load_csv_baseline(csv_baseline_path)
        
        print(f"ì¹´í…Œê³ ë¦¬ '{category_config['name']}' ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_driver(self):
        """ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì‹œì‘"""
        print("Chrome ë“œë¼ì´ë²„ ì‹œì‘ ì¤‘...")
        if self.browser.start_driver():
            print("Chrome ë“œë¼ì´ë²„ ì‹œì‘ ì™„ë£Œ")
            self.extractor = InfiniteScrollExtractor(self.browser)
            return True
        print("âŒ Chrome ë“œë¼ì´ë²„ ì‹œì‘ ì‹¤íŒ¨")
        return False
    
    def run_monitoring_cycle(self):
        """ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì‹¤í–‰"""
        category_name = self.category_config['name']
        page_url = self.category_config['url']
        
        print(f"\n{'='*60}")
        print(f"[{category_name}] ëª¨ë‹ˆí„°ë§ ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*60}")
        
        start_time = time.time()
        
        try:
            if not self.extractor:
                print(f"âŒ Extractor ì´ˆê¸°í™” ì•ˆë¨")
                return None
            
            # 1. í˜ì´ì§€ í¬ë¡¤ë§
            current_products = self.extractor.extract_all_products_with_scroll(page_url)
            
            if not current_products:
                print(f"âŒ ìƒí’ˆ ìˆ˜ì§‘ ì‹¤íŒ¨: ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            print(f"âœ… {len(current_products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # 2. ì´ì „ ë°ì´í„°ì™€ ë¹„êµ
            previous_products = self.db.get_latest_snapshot_data(category_name)
            changes = self.change_detector.detect_changes(previous_products, current_products)
            
            # 3. ë³€í™” ë³´ê³ 
            self.report_changes(category_name, changes)
            
            # 4. ë³€í™” ì´ë²¤íŠ¸ ë¡œê¹…
            self.log_changes(category_name, changes)
            
            # 5. ìŠ¤ëƒ…ìƒ· ì €ì¥
            crawl_duration = time.time() - start_time
            snapshot_id = self.db.save_snapshot(category_name, page_url, current_products, crawl_duration)
            
            print(f"ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ: ID {snapshot_id}, {len(current_products)}ê°œ ìƒí’ˆ")
            return changes
            
        except Exception as e:
            print(f"âŒ [{category_name}] ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def report_changes(self, category_name, changes):
        """ì¹´í…Œê³ ë¦¬ë³„ ë³€í™” ë³´ê³ """
        print(f"\n[{category_name}] ë³€í™” ê°ì§€:")
        print(f"  ì‹ ê·œ: {len(changes['new_products'])}ê°œ")
        print(f"  ì œê±°: {len(changes['removed_products'])}ê°œ")
        print(f"  ìˆœìœ„ ë³€í™”: {len(changes['rank_changes'])}ê°œ")
        print(f"  ê°€ê²© ë³€í™”: {len(changes['price_changes'])}ê°œ")
        
        # ì£¼ìš” ìˆœìœ„ ë³€í™”
        if changes['rank_changes']:
            print(f"\nì£¼ìš” ìˆœìœ„ ë³€í™”:")
            for change in changes['rank_changes'][:5]:
                direction = "â†‘" if change['rank_change'] > 0 else "â†“"
                print(f"  {change['product_name'][:30]}: {change['old_rank']}ìœ„ â†’ {change['new_rank']}ìœ„ {direction}")
        
        # ì£¼ìš” ê°€ê²© ë³€í™”
        if changes['price_changes']:
            print(f"\nì£¼ìš” ê°€ê²© ë³€í™”:")
            for change in changes['price_changes'][:5]:
                direction = "â†‘" if change['price_change'] > 0 else "â†“"
                print(f"  {change['product_name'][:30]}: {change['old_price']:,}ì› â†’ {change['new_price']:,}ì› {direction}")
    
    def log_changes(self, category_name, changes):
        """ì¹´í…Œê³ ë¦¬ë³„ ë³€í™” ì´ë²¤íŠ¸ ë¡œê¹…"""
        # ìˆœìœ„ ë³€í™” ë¡œê¹…
        for change in changes['rank_changes']:
            self.db.log_change_event(
                change['product_id'], category_name, 'rank_change',
                change['old_rank'], change['new_rank'],
                f"ìˆœìœ„ {abs(change['rank_change'])}ë‹¨ê³„ {'ìƒìŠ¹' if change['rank_change'] > 0 else 'í•˜ë½'}"
            )
        
        # ê°€ê²© ë³€í™” ë¡œê¹…
        for change in changes['price_changes']:
            self.db.log_change_event(
                change['product_id'], category_name, 'price_change',
                change['old_price'], change['new_price'],
                f"ê°€ê²© {abs(change['price_change']):,}ì› {'ì¸ìƒ' if change['price_change'] > 0 else 'ì¸í•˜'}"
            )
        
        # ì‹ ê·œ ìƒí’ˆ ë¡œê¹…
        for product in changes['new_products']:
            self.db.log_change_event(
                product['product_id'], category_name, 'new_product',
                None, product['product_name'],
                f"ì‹ ê·œ ìƒí’ˆ"
            )
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.browser:
            self.browser.close()


class MultiCategoryMonitoringSystem:
    """ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def __init__(self, categories_config, csv_baseline_path=None, db_path="page_monitoring.db", headless=True):
        self.categories_config = categories_config
        self.csv_baseline_path = csv_baseline_path
        self.db_path = db_path
        self.headless = headless
        
        print(f"ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"ëŒ€ìƒ ì¹´í…Œê³ ë¦¬: {len(categories_config)}ê°œ")
    
    def run_full_monitoring_cycle(self, cycles=1):
        """ì „ì²´ ì¹´í…Œê³ ë¦¬ ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì‹¤í–‰"""
        print(f"\nğŸ¯ ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ({cycles}íšŒ ë°˜ë³µ)")
        print("="*80)
        
        for cycle in range(cycles):
            if cycles > 1:
                print(f"\n[ì‚¬ì´í´ {cycle + 1}/{cycles}]")
            
            # ê° ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë‹ˆí„°ë§
            for i, category_config in enumerate(self.categories_config, 1):
                print(f"\n[{i}/{len(self.categories_config)}] ğŸ“‚ {category_config['name']} ëª¨ë‹ˆí„°ë§")
                
                monitor = CategoryPageMonitor(
                    category_config=category_config,
                    csv_baseline_path=self.csv_baseline_path,
                    db_path=self.db_path,
                    headless=self.headless
                )
                
                try:
                    if not monitor.start_driver():
                        print(f"âŒ {category_config['name']} ë¸Œë¼ìš°ì € ì‹œì‘ ì‹¤íŒ¨")
                        continue
                    
                    changes = monitor.run_monitoring_cycle()
                    
                    if changes:
                        print(f"âœ… {category_config['name']} ëª¨ë‹ˆí„°ë§ ì™„ë£Œ!")
                    else:
                        print(f"âŒ {category_config['name']} ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨")
                
                except KeyboardInterrupt:
                    print(f"\nâš ï¸ {category_config['name']} ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨")
                    monitor.close()
                    return
                except Exception as e:
                    print(f"âŒ {category_config['name']} ì˜¤ë¥˜ ë°œìƒ: {e}")
                finally:
                    monitor.close()
                
                # ì¹´í…Œê³ ë¦¬ ê°„ ëŒ€ê¸° (ë´‡ íƒì§€ ë°©ì§€)
                if i < len(self.categories_config):
                    wait_time = 30 if cycle == 0 else 60
                    print(f"ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ê¹Œì§€ {wait_time}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)
            
            # ì‚¬ì´í´ ê°„ ëŒ€ê¸°
            if cycle < cycles - 1:
                print(f"\në‹¤ìŒ ì‚¬ì´í´ê¹Œì§€ 10ë¶„ ëŒ€ê¸°...")
                time.sleep(600)
        
        print(f"\nğŸ‰ ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì™„ë£Œ!")


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ë‹¤ì¤‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‹ˆí„°ë§"""
    
    categories = [
        {
            'name': 'í—¬ìŠ¤/ê±´ê°•ì‹í’ˆ',
            'url': 'https://shop.coupang.com/coupangus/74511?category=305433&platform=p&brandId=0'
        },
        {
            'name': 'ì¶œì‚°ìœ ì•„ë™',
            'url': 'https://shop.coupang.com/coupangus/74511?category=219079&platform=p&brandId=0'
        },
        {
            'name': 'ìŠ¤í¬ì¸ ë ˆì €',
            'url': 'https://shop.coupang.com/coupangus/74511?category=317675&platform=p&brandId=0'
        }
    ]
    
    csv_baseline = "coupang_iherb_products.csv"
    
    monitoring_system = MultiCategoryMonitoringSystem(
        categories_config=categories,
        csv_baseline_path=csv_baseline,
        headless=False
    )
    
    try:
        monitoring_system.run_full_monitoring_cycle(cycles=2)
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()