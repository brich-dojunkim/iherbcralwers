#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Data Migrator - ê¸°ì¡´ monitoring.db â†’ í†µí•© DB
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¡œì¼“ì§êµ¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‚ ì§œë³„ snapshotìœ¼ë¡œ ë³€í™˜
"""

import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Dict, List


class DataMigrator:
    """ê¸°ì¡´ DB â†’ í†µí•© DB ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    def __init__(self, legacy_db_path: str, integrated_db):
        """
        Args:
            legacy_db_path: ê¸°ì¡´ monitoring.db ê²½ë¡œ
            integrated_db: IntegratedDatabase ì¸ìŠ¤í„´ìŠ¤
        """
        self.legacy_db_path = legacy_db_path
        self.integrated_db = integrated_db
    
    def migrate_all(self):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        
        print(f"\n{'='*80}")
        print(f"ğŸ”„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        print(f"{'='*80}")
        print(f"Legacy DB: {self.legacy_db_path}")
        print(f"Integrated DB: {self.integrated_db.db_path}")
        print(f"{'='*80}\n")
        
        # 1. ë‚ ì§œë³„ snapshot ëª©ë¡ ì¡°íšŒ
        snapshot_dates = self._get_snapshot_dates()
        
        if not snapshot_dates:
            print("âš ï¸  ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“… ë°œê²¬ëœ ë‚ ì§œ: {len(snapshot_dates)}ê°œ")
        for date_info in snapshot_dates[:5]:
            print(f"   â€¢ {date_info['date']}: {date_info['count']}ê°œ ìŠ¤ëƒ…ìƒ·")
        if len(snapshot_dates) > 5:
            print(f"   ... ì™¸ {len(snapshot_dates) - 5}ê°œ")
        print()
        
        # 2. ë‚ ì§œë³„ ë§ˆì´ê·¸ë ˆì´ì…˜
        total_products = 0
        total_snapshots = 0
        
        for date_info in snapshot_dates:
            date_str = date_info['date']
            print(f"\nğŸ“† {date_str} ì²˜ë¦¬ ì¤‘...")
            
            # í•´ë‹¹ ë‚ ì§œì˜ ì¹´í…Œê³ ë¦¬ë³„ ìµœì‹  snapshot ì¡°íšŒ
            snapshots = self._get_snapshots_by_date(date_str)
            
            if not snapshots:
                continue
            
            # í†µí•© DBì— snapshot ìƒì„±
            snapshot_id = self._create_integrated_snapshot(date_str, snapshots)
            
            # ê° ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            for snap in snapshots:
                products = self._get_products_from_snapshot(snap['id'])
                
                if products:
                    self._migrate_products(snapshot_id, products, snap['category'])
                    total_products += len(products)
                    print(f"   âœ“ {snap['category']}: {len(products)}ê°œ ìƒí’ˆ")
            
            total_snapshots += 1
        
        print(f"\n{'='*80}")
        print(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        print(f"{'='*80}")
        print(f"ì´ Snapshot: {total_snapshots}ê°œ")
        print(f"ì´ ìƒí’ˆ ë ˆì½”ë“œ: {total_products:,}ê°œ")
        print(f"{'='*80}\n")
    
    def _get_snapshot_dates(self) -> List[Dict]:
        """ë‚ ì§œë³„ snapshot ëª©ë¡ ì¡°íšŒ"""
        conn = sqlite3.connect(self.legacy_db_path)
        
        query = """
            SELECT DATE(snapshot_time) as date, COUNT(*) as count
            FROM snapshots
            WHERE source_id = (SELECT id FROM sources WHERE source_type = 'rocket_direct')
            GROUP BY DATE(snapshot_time)
            ORDER BY date DESC
        """
        
        cursor = conn.execute(query)
        results = [{'date': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        conn.close()
        return results
    
    def _get_snapshots_by_date(self, target_date: str) -> List[Dict]:
        """íŠ¹ì • ë‚ ì§œì˜ ì¹´í…Œê³ ë¦¬ë³„ ìµœì‹  snapshot ì¡°íšŒ"""
        conn = sqlite3.connect(self.legacy_db_path)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìµœì‹  snapshot
        query = """
            SELECT s.id, s.page_url, s.snapshot_time, c.name as category, c.coupang_category_id
            FROM snapshots s
            JOIN categories c ON s.category_id = c.id
            WHERE DATE(s.snapshot_time) = ?
            AND s.source_id = (SELECT id FROM sources WHERE source_type = 'rocket_direct')
            AND s.id IN (
                SELECT MAX(id)
                FROM snapshots
                WHERE DATE(snapshot_time) = ?
                AND source_id = (SELECT id FROM sources WHERE source_type = 'rocket_direct')
                GROUP BY category_id
            )
            ORDER BY c.id
        """
        
        cursor = conn.execute(query, (target_date, target_date))
        
        snapshots = []
        for row in cursor.fetchall():
            snapshots.append({
                'id': row[0],
                'page_url': row[1],
                'snapshot_time': row[2],
                'category': row[3],
                'category_id': row[4]
            })
        
        conn.close()
        return snapshots
    
    def _create_integrated_snapshot(self, date_str: str, snapshots: List[Dict]) -> int:
        """í†µí•© DBì— snapshot ìƒì„±"""
        
        # URLì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë§¤í•‘
        rocket_urls = {}
        
        for snap in snapshots:
            cat_id = snap['category_id']
            page_url = snap['page_url']
            
            # category_idë¡œ url_column ê²°ì •
            if cat_id == '305433':  # í—¬ìŠ¤/ê±´ê°•ì‹í’ˆ
                rocket_urls['url_1'] = page_url
            elif cat_id == '219079':  # ì¶œì‚°ìœ ì•„ë™
                rocket_urls['url_2'] = page_url
            elif cat_id == '317675':  # ìŠ¤í¬ì¸ ë ˆì €
                rocket_urls['url_3'] = page_url
        
        snapshot_id = self.integrated_db.create_snapshot(
            snapshot_date=date_str,
            rocket_urls=rocket_urls,
            file_names=None  # ì—‘ì…€ì€ ë‚˜ì¤‘ì— ì¶”ê°€
        )
        
        return snapshot_id
    
    def _get_products_from_snapshot(self, snapshot_id: int) -> List[Dict]:
        """íŠ¹ì • snapshotì˜ ìƒí’ˆ ë°ì´í„° ì¡°íšŒ"""
        conn = sqlite3.connect(self.legacy_db_path)
        
        query = """
            SELECT 
                vendor_item_id,
                category_rank,
                product_name,
                product_url,
                current_price,
                original_price,
                discount_rate,
                rating_score,
                review_count
            FROM product_states
            WHERE snapshot_id = ?
            ORDER BY category_rank
        """
        
        cursor = conn.execute(query, (snapshot_id,))
        
        products = []
        for row in cursor.fetchall():
            products.append({
                'vendor_item_id': row[0],
                'rank': row[1],
                'name': row[2],
                'url': row[3],
                'current_price': row[4],
                'original_price': row[5],
                'discount_rate': row[6],
                'rating': row[7],
                'reviews': row[8]
            })
        
        conn.close()
        return products
    
    def _migrate_products(self, snapshot_id: int, products: List[Dict], category: str):
        """ìƒí’ˆ ë°ì´í„°ë¥¼ í†µí•© DBë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
        
        # URLì—ì„œ product_id, item_id ì¶”ì¶œ
        import re
        
        products_data = []
        prices_data = []
        features_data = []
        
        for p in products:
            vendor_id = p['vendor_item_id']
            url = p['url']
            
            # product_id, item_id ì¶”ì¶œ
            product_id = None
            item_id = None
            
            if url:
                m_product = re.search(r'/products/(\d+)', url)
                if m_product:
                    product_id = m_product.group(1)
                
                m_item = re.search(r'itemId=(\d+)', url)
                if m_item:
                    item_id = m_item.group(1)
            
            # products í…Œì´ë¸”
            products_data.append({
                'vendor_item_id': vendor_id,
                'product_id': product_id,
                'item_id': item_id,
                'part_number': None,
                'upc': None,
                'name': p['name']
            })
            
            # product_price í…Œì´ë¸”
            prices_data.append({
                'vendor_item_id': vendor_id,
                'rocket_price': p['current_price'],
                'rocket_original_price': p['original_price'],
                'iherb_price': None,
                'iherb_original_price': None,
                'iherb_recommended_price': None
            })
            
            # product_features í…Œì´ë¸”
            features_data.append({
                'vendor_item_id': vendor_id,
                'rocket_rank': p['rank'],
                'rocket_rating': p['rating'],
                'rocket_reviews': p['reviews'],
                'iherb_stock': None,
                'iherb_stock_status': None,
                'iherb_revenue': None,
                'iherb_sales_quantity': None,
                'iherb_item_winner_ratio': None
            })
        
        # ì¼ê´„ ì €ì¥
        if products_data:
            self.integrated_db.batch_upsert_products(products_data)
        
        if prices_data:
            self.integrated_db.batch_save_product_prices(snapshot_id, prices_data)
        
        if features_data:
            self.integrated_db.batch_save_product_features(snapshot_id, features_data)


def main():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
    from database import IntegratedDatabase
    
    # ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    legacy_db_path = "/Users/brich/Desktop/iherb_price/coupang2/data/rocket/monitoring.db"
    integrated_db_path = "/Users/brich/Desktop/iherb_price/coupang2/data/integrated/rocket_iherb.db"
    
    # í†µí•© DB ì´ˆê¸°í™”
    integrated_db = IntegratedDatabase(integrated_db_path)
    integrated_db.init_database()
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrator = DataMigrator(legacy_db_path, integrated_db)
    
    print("\nâš ï¸  ê²½ê³ : ê¸°ì¡´ í†µí•© DBì˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¤‘ë³µë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ").strip().lower()
    
    if confirm == 'yes':
        migrator.migrate_all()
    else:
        print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()