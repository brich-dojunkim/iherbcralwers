#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìµœì¢… Price Agent Excel (2-Sheet)

Sheet 1: ì „ì²´ ë°ì´í„° ì‹œê³„ì—´ (í”„ë ˆì  í…Œì´ì…˜ìš©) - date_excel ìŠ¤íƒ€ì¼
Sheet 2: ì¤‘ë³µ UPC ìƒì„¸ íƒìƒ‰ (ê·¸ë£¹í™”) - 379ê°œ UPCë§Œ
"""

import sqlite3
import pandas as pd
import numpy as np
import os
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.utils.dataframe import dataframe_to_rows
from difflib import SequenceMatcher

DB_PATH = "/Users/brich/Desktop/iherb_price/coupang2/monitoring.db"
OUTPUT_DIR = "/Users/brich/Desktop/iherb_price/coupang2/outputs"


def calculate_name_similarity(name1, name2):
    """ë‘ ìƒí’ˆëª…ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
    if pd.isna(name1) or pd.isna(name2):
        return 0.0
    return SequenceMatcher(None, str(name1), str(name2)).ratio()


def select_representative_product(group_df):
    """
    UPC ê·¸ë£¹ì—ì„œ ëŒ€í‘œ ìƒí’ˆ ì„ ì •
    
    ìš°ì„ ìˆœìœ„:
    1. ì†ŒìŠ¤ = ë¡œì¼“ì§êµ¬
    2. ì´ë¦„ ìœ ì‚¬ë„ ìµœëŒ€ (í‰ê· )
    3. ë¦¬ë·°ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ
    4. í‰ì  ë‚´ë¦¼ì°¨ìˆœ
    5. ê°€ê²© ì˜¤ë¦„ì°¨ìˆœ
    """
    
    # ë¡œì¼“ì§êµ¬ í•„í„°ë§
    rocket_products = group_df[group_df['source_type'] == 'rocket_direct'].copy()
    
    candidates = rocket_products if len(rocket_products) > 0 else group_df.copy()
    
    # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
    for idx in candidates.index:
        product_name = candidates.loc[idx, 'product_name']
        similarities = []
        
        for other_idx in group_df.index:
            if idx != other_idx:
                other_name = group_df.loc[other_idx, 'product_name']
                sim = calculate_name_similarity(product_name, other_name)
                similarities.append(sim)
        
        candidates.loc[idx, 'avg_similarity'] = np.mean(similarities) if similarities else 0.0
    
    # ì •ë ¬
    candidates = candidates.sort_values(
        by=['avg_similarity', 'review_count', 'rating_score', 'current_price'],
        ascending=[False, False, False, True]
    )
    
    return candidates.index[0]


def generate_sheet1_all_products():
    """Sheet 1: ì „ì²´ ë°ì´í„° ì‹œê³„ì—´ (date_excel ìŠ¤íƒ€ì¼)"""
    
    conn = sqlite3.connect(DB_PATH)
    
    print("\n" + "="*80)
    print("ğŸ“Š Sheet 1: ì „ì²´ ë°ì´í„° ì‹œê³„ì—´ ìƒì„± ì¤‘...")
    print("="*80)
    
    # ë°ì´í„° ë¡œë“œ
    query = """
    WITH daily_latest_snapshots AS (
        SELECT 
            c.name as category_name,
            s.source_type,
            DATE(snap.snapshot_time) as snapshot_date,
            MAX(snap.id) as latest_snapshot_id
        FROM snapshots snap
        JOIN sources s ON snap.source_id = s.id
        JOIN categories c ON snap.category_id = c.id
        GROUP BY c.name, s.source_type, DATE(snap.snapshot_time)
    )
    SELECT 
        dls.category_name,
        dls.source_type,
        dls.snapshot_date,
        mr.iherb_upc,
        mr.iherb_part_number,
        ps.vendor_item_id,
        ps.product_name,
        ps.category_rank,
        ps.current_price,
        ps.discount_rate,
        ps.review_count,
        ps.rating_score
    FROM daily_latest_snapshots dls
    JOIN product_states ps ON dls.latest_snapshot_id = ps.snapshot_id
    LEFT JOIN matching_reference mr ON ps.vendor_item_id = mr.vendor_item_id
    ORDER BY COALESCE(mr.iherb_upc, ps.vendor_item_id), 
             dls.category_name, dls.source_type, dls.snapshot_date
    """
    
    df_long = pd.read_sql_query(query, conn)
    conn.close()
    
    if df_long.empty:
        print("   âš ï¸ ë°ì´í„° ì—†ìŒ")
        return pd.DataFrame(), []
    
    dates = sorted(df_long['snapshot_date'].unique())
    print(f"   âœ“ {len(df_long):,}ê°œ ë ˆì½”ë“œ, {len(dates)}ì¼")
    
    # ì†ŒìŠ¤ ë¼ë²¨
    df_long['ì†ŒìŠ¤'] = df_long['source_type'].map({
        'rocket_direct': 'ë¡œì¼“ì§êµ¬',
        'iherb_official': 'ì•„ì´í—ˆë¸Œ'
    })
    
    # ê¸°ë³¸ ì •ë³´
    base = df_long.groupby(['category_name', 'source_type', 'iherb_upc', 'vendor_item_id']).agg({
        'product_name': 'first',
        'iherb_part_number': 'first',
        'review_count': 'last',
        'rating_score': 'last',
        'ì†ŒìŠ¤': 'first'
    }).reset_index()
    
    # ë‚ ì§œë³„ ë°ì´í„° ì¶”ê°€
    for date in dates:
        date_str = date[5:].replace('-', '/')
        date_data = df_long[df_long['snapshot_date'] == date][
            ['category_name', 'source_type', 'iherb_upc', 'vendor_item_id',
             'category_rank', 'current_price', 'discount_rate', 'review_count']
        ].copy()
        
        date_data.columns = [
            'category_name', 'source_type', 'iherb_upc', 'vendor_item_id',
            f'{date_str}_ìˆœìœ„', f'{date_str}_ê°€ê²©', f'{date_str}_í• ì¸ìœ¨', f'{date_str}_ë¦¬ë·°ìˆ˜'
        ]
        
        base = base.merge(
            date_data,
            on=['category_name', 'source_type', 'iherb_upc', 'vendor_item_id'],
            how='left'
        )
    
    # ë³€í™”ëŸ‰ ê³„ì‚°
    for i in range(1, len(dates)):
        prev = dates[i-1][5:].replace('-', '/')
        curr = dates[i][5:].replace('-', '/')
        
        # ìˆœìœ„ ë³€í™” = ì´ì „ - í˜„ì¬
        base[f'{curr}_ìˆœìœ„ë³€í™”'] = base[f'{prev}_ìˆœìœ„'] - base[f'{curr}_ìˆœìœ„']
        
        # ê°€ê²© ë³€í™” = í˜„ì¬ - ì´ì „
        base[f'{curr}_ê°€ê²©ë³€í™”'] = base[f'{curr}_ê°€ê²©'] - base[f'{prev}_ê°€ê²©']
        
        # í• ì¸ìœ¨ ë³€í™” = í˜„ì¬ - ì´ì „
        base[f'{curr}_í• ì¸ìœ¨ë³€í™”'] = base[f'{curr}_í• ì¸ìœ¨'] - base[f'{prev}_í• ì¸ìœ¨']
    
    # ì»¬ëŸ¼ ì •ë¦¬
    base = base.rename(columns={
        'category_name': 'ì¹´í…Œê³ ë¦¬',
        'iherb_upc': 'UPC',
        'iherb_part_number': 'í’ˆë²ˆ',
        'vendor_item_id': 'VendorItemID',
        'product_name': 'ìƒí’ˆëª…',
        'review_count': 'ìµœì¢…ë¦¬ë·°ìˆ˜',
        'rating_score': 'ìµœì¢…í‰ì '
    })
    
    # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (ê¸°ë³¸ì •ë³´ + ë‚ ì§œë³„ ì¸¡ì •ê°’ + ë‚ ì§œë³„ ë³€í™”ëŸ‰)
    base_cols = ['ì¹´í…Œê³ ë¦¬', 'ì†ŒìŠ¤', 'UPC', 'í’ˆë²ˆ', 'VendorItemID', 'ìƒí’ˆëª…', 'ìµœì¢…ë¦¬ë·°ìˆ˜', 'ìµœì¢…í‰ì ']
    
    ordered_cols = base_cols.copy()
    
    # ë‚ ì§œë³„ ì¸¡ì •ê°’
    for date in dates:
        d = date[5:].replace('-', '/')
        ordered_cols.extend([f'{d}_ìˆœìœ„', f'{d}_ê°€ê²©', f'{d}_í• ì¸ìœ¨', f'{d}_ë¦¬ë·°ìˆ˜'])
    
    # ë‚ ì§œë³„ ë³€í™”ëŸ‰
    for i in range(1, len(dates)):
        d = dates[i][5:].replace('-', '/')
        ordered_cols.extend([f'{d}_ìˆœìœ„ë³€í™”', f'{d}_ê°€ê²©ë³€í™”', f'{d}_í• ì¸ìœ¨ë³€í™”'])
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    ordered_cols = [c for c in ordered_cols if c in base.columns]
    base = base[ordered_cols]
    
    print(f"   âœ… Wide Format ìƒì„± ì™„ë£Œ: {len(base):,}ê°œ í–‰")
    
    return base, dates


def generate_sheet2_overlap_upc():
    """Sheet 2: ì¤‘ë³µ UPCë§Œ (379ê°œ ê·¸ë£¹í™”)"""
    
    conn = sqlite3.connect(DB_PATH)
    
    print("\n" + "="*80)
    print("ğŸ“Š Sheet 2: ì¤‘ë³µ UPC ìƒì„¸ íƒìƒ‰ ìƒì„± ì¤‘...")
    print("="*80)
    
    # ì¤‘ë³µ UPCë§Œ í•„í„°ë§
    query = """
    WITH daily_latest_snapshots AS (
        SELECT 
            c.name as category_name,
            s.source_type,
            DATE(snap.snapshot_time) as snapshot_date,
            MAX(snap.id) as latest_snapshot_id
        FROM snapshots snap
        JOIN sources s ON snap.source_id = s.id
        JOIN categories c ON snap.category_id = c.id
        GROUP BY c.name, s.source_type, DATE(snap.snapshot_time)
    ),
    overlap_upc AS (
        SELECT 
            mr.iherb_upc
        FROM product_states ps
        JOIN snapshots snap ON ps.snapshot_id = snap.id
        JOIN sources s ON snap.source_id = s.id
        INNER JOIN matching_reference mr ON ps.vendor_item_id = mr.vendor_item_id
        WHERE mr.iherb_upc IS NOT NULL
        GROUP BY mr.iherb_upc
        HAVING COUNT(DISTINCT s.source_type) = 2
    )
    SELECT 
        dls.category_name,
        dls.source_type,
        dls.snapshot_date,
        mr.iherb_upc,
        mr.iherb_part_number,
        ps.vendor_item_id,
        ps.product_name,
        ps.category_rank,
        ps.current_price,
        ps.discount_rate,
        ps.review_count,
        ps.rating_score
    FROM overlap_upc ou
    JOIN matching_reference mr ON ou.iherb_upc = mr.iherb_upc
    JOIN product_states ps ON mr.vendor_item_id = ps.vendor_item_id
    JOIN daily_latest_snapshots dls ON ps.snapshot_id = dls.latest_snapshot_id
    ORDER BY mr.iherb_upc, dls.category_name, dls.source_type, dls.snapshot_date
    """
    
    df_long = pd.read_sql_query(query, conn)
    conn.close()
    
    if df_long.empty:
        print("   âš ï¸ ì¤‘ë³µ UPC ì—†ìŒ")
        return pd.DataFrame(), []
    
    dates = sorted(df_long['snapshot_date'].unique())
    print(f"   âœ“ {len(df_long):,}ê°œ ë ˆì½”ë“œ, {len(dates)}ì¼")
    print(f"   âœ“ ì¤‘ë³µ UPC: {df_long['iherb_upc'].nunique():,}ê°œ")
    
    # ì†ŒìŠ¤ ë¼ë²¨
    df_long['ì†ŒìŠ¤'] = df_long['source_type'].map({
        'rocket_direct': 'ë¡œì¼“ì§êµ¬',
        'iherb_official': 'ì•„ì´í—ˆë¸Œ'
    })
    
    # ìµœì‹  ìŠ¤ëƒ…ìƒ·ìœ¼ë¡œ ëŒ€í‘œ ì„ ì •
    latest_date = dates[-1]
    df_latest = df_long[df_long['snapshot_date'] == latest_date].copy()
    
    print(f"   ğŸ” ëŒ€í‘œ ìƒí’ˆ ì„ ì • ì¤‘... (ê¸°ì¤€: {latest_date})")
    
    # UPCë³„ ëŒ€í‘œ ì„ ì •
    representative_mapping = {}
    
    for upc in df_latest['iherb_upc'].unique():
        if pd.notna(upc):
            group_df = df_latest[df_latest['iherb_upc'] == upc].copy()
            
            if len(group_df) > 0:
                rep_idx = select_representative_product(group_df)
                representative_mapping[upc] = group_df.loc[rep_idx, 'vendor_item_id']
    
    print(f"   âœ“ {len(representative_mapping):,}ê°œ ê·¸ë£¹ì˜ ëŒ€í‘œ ì„ ì • ì™„ë£Œ")
    
    # Wide Format ìƒì„±
    base = df_long.groupby(['category_name', 'source_type', 'iherb_upc', 'vendor_item_id']).agg({
        'product_name': 'first',
        'iherb_part_number': 'first',
        'review_count': 'last',
        'rating_score': 'last',
        'ì†ŒìŠ¤': 'first'
    }).reset_index()
    
    # ë‚ ì§œë³„ ë°ì´í„°
    for date in dates:
        date_str = date[5:].replace('-', '/')
        date_data = df_long[df_long['snapshot_date'] == date][
            ['category_name', 'source_type', 'iherb_upc', 'vendor_item_id',
             'category_rank', 'current_price', 'discount_rate', 'review_count']
        ].copy()
        
        date_data.columns = [
            'category_name', 'source_type', 'iherb_upc', 'vendor_item_id',
            f'{date_str}_ìˆœìœ„', f'{date_str}_ê°€ê²©', f'{date_str}_í• ì¸ìœ¨', f'{date_str}_ë¦¬ë·°ìˆ˜'
        ]
        
        base = base.merge(
            date_data,
            on=['category_name', 'source_type', 'iherb_upc', 'vendor_item_id'],
            how='left'
        )
    
    # ë³€í™”ëŸ‰ ê³„ì‚°
    for i in range(1, len(dates)):
        prev = dates[i-1][5:].replace('-', '/')
        curr = dates[i][5:].replace('-', '/')
        
        base[f'{curr}_ìˆœìœ„ë³€í™”'] = base[f'{prev}_ìˆœìœ„'] - base[f'{curr}_ìˆœìœ„']
        base[f'{curr}_ê°€ê²©ë³€í™”'] = base[f'{curr}_ê°€ê²©'] - base[f'{prev}_ê°€ê²©']
        base[f'{curr}_í• ì¸ìœ¨ë³€í™”'] = base[f'{curr}_í• ì¸ìœ¨'] - base[f'{prev}_í• ì¸ìœ¨']
    
    # ê·¸ë£¹í™” ì¤€ë¹„
    base['_upc_sort'] = base['iherb_upc']
    base['_group_order'] = 999
    base['_is_representative'] = False
    
    # ëŒ€í‘œ ìƒí’ˆ í‘œì‹œ
    for upc, rep_vendor_id in representative_mapping.items():
        mask = (base['iherb_upc'] == upc) & (base['vendor_item_id'] == rep_vendor_id)
        base.loc[mask, '_group_order'] = 0
        base.loc[mask, '_is_representative'] = True
    
    # ë‚˜ë¨¸ì§€ ìƒí’ˆ ìˆœì„œ
    for upc in representative_mapping.keys():
        group_mask = base['iherb_upc'] == upc
        other_indices = base[group_mask & (base['_group_order'] != 0)].index
        
        if len(other_indices) > 0:
            group_subset = base.loc[other_indices].sort_values(
                ['source_type', 'product_name'],
                ascending=[False, True]
            )
            
            for i, idx in enumerate(group_subset.index, start=1):
                base.loc[idx, '_group_order'] = i
    
    # ì •ë ¬
    base = base.sort_values(['category_name', '_upc_sort', '_group_order'])
    
    # ì»¬ëŸ¼ ì •ë¦¬
    base = base.rename(columns={
        'category_name': 'ì¹´í…Œê³ ë¦¬',
        'iherb_upc': 'UPC',
        'iherb_part_number': 'í’ˆë²ˆ',
        'vendor_item_id': 'VendorItemID',
        'product_name': 'ìƒí’ˆëª…',
        'review_count': 'ìµœì¢…ë¦¬ë·°ìˆ˜',
        'rating_score': 'ìµœì¢…í‰ì '
    })
    
    # ì»¬ëŸ¼ ìˆœì„œ
    hidden_cols = ['_upc_sort', '_group_order', '_is_representative']
    base_cols = ['ì¹´í…Œê³ ë¦¬', 'ì†ŒìŠ¤', 'UPC', 'í’ˆë²ˆ', 'VendorItemID', 'ìƒí’ˆëª…', 'ìµœì¢…ë¦¬ë·°ìˆ˜', 'ìµœì¢…í‰ì ']
    
    ordered_cols = hidden_cols + base_cols.copy()
    
    # ë‚ ì§œë³„ ì¸¡ì •ê°’ + ë³€í™”ëŸ‰
    for date in dates:
        d = date[5:].replace('-', '/')
        ordered_cols.extend([f'{d}_ìˆœìœ„', f'{d}_ê°€ê²©', f'{d}_í• ì¸ìœ¨', f'{d}_ë¦¬ë·°ìˆ˜'])
    
    for i in range(1, len(dates)):
        d = dates[i][5:].replace('-', '/')
        ordered_cols.extend([f'{d}_ìˆœìœ„ë³€í™”', f'{d}_ê°€ê²©ë³€í™”', f'{d}_í• ì¸ìœ¨ë³€í™”'])
    
    ordered_cols = [c for c in ordered_cols if c in base.columns]
    base = base[ordered_cols]
    
    print(f"   âœ… ê·¸ë£¹í™” ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(base):,}ê°œ í–‰")
    
    return base, dates


def save_to_excel_date_style(df_sheet1, dates1, df_sheet2, dates2, output_path):
    """date_excel ìŠ¤íƒ€ì¼ë¡œ Excel ì €ì¥"""
    
    print("\n" + "="*80)
    print("ğŸ’¾ Excel íŒŒì¼ ì €ì¥ ì¤‘ (date_excel ìŠ¤íƒ€ì¼)...")
    print("="*80)
    
    wb = Workbook()
    wb.remove(wb.active)
    
    # ìŠ¤íƒ€ì¼
    header_font = Font(bold=True, size=11)
    subheader_font = Font(bold=True, size=10)
    header_fill = PatternFill(start_color='F0F0F0', end_color='F0F0F0', fill_type='solid')
    rep_fill = PatternFill(start_color='E7F3FF', end_color='E7F3FF', fill_type='solid')
    rep_font = Font(bold=True, size=10)
    
    # ===== Sheet 1: ì „ì²´ ë°ì´í„° =====
    print("\nğŸ“„ Sheet 1: ì „ì²´ ë°ì´í„°...")
    ws1 = wb.create_sheet("ì „ì²´ë°ì´í„°_ì‹œê³„ì—´")
    
    # ë©€í‹°ë ˆë²¨ í—¤ë” êµ¬ì„±
    base_cols_count = 8  # ê¸°ë³¸ì •ë³´ ì»¬ëŸ¼ ìˆ˜
    
    # 1í–‰: ìƒìœ„ í—¤ë”
    ws1.cell(1, 1, "ê¸°ë³¸ì •ë³´")
    
    col_idx = base_cols_count + 1
    for date in dates1:
        date_str = date[5:].replace('-', '/')
        ws1.cell(1, col_idx, date_str)
        col_idx += 4  # ìˆœìœ„, ê°€ê²©, í• ì¸ìœ¨, ë¦¬ë·°ìˆ˜
    
    for i in range(1, len(dates1)):
        date_str = dates1[i][5:].replace('-', '/')
        ws1.cell(1, col_idx, f"{date_str}_ë³€í™”")
        col_idx += 3  # ìˆœìœ„ë³€í™”, ê°€ê²©ë³€í™”, í• ì¸ìœ¨ë³€í™”
    
    # 2í–‰: í•˜ìœ„ í—¤ë”
    for c_idx, col_name in enumerate(df_sheet1.columns, 1):
        if col_name in ['ì¹´í…Œê³ ë¦¬', 'ì†ŒìŠ¤', 'UPC', 'í’ˆë²ˆ', 'VendorItemID', 'ìƒí’ˆëª…', 'ìµœì¢…ë¦¬ë·°ìˆ˜', 'ìµœì¢…í‰ì ']:
            ws1.cell(2, c_idx, col_name)
        elif '_' in col_name:
            parts = col_name.rsplit('_', 1)
            ws1.cell(2, c_idx, parts[1])
    
    # í—¤ë” ìŠ¤íƒ€ì¼
    for row in [1, 2]:
        for col in range(1, len(df_sheet1.columns) + 1):
            cell = ws1.cell(row, col)
            cell.font = header_font if row == 1 else subheader_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal='center', vertical='center')
    
    # ìƒìœ„ í—¤ë” ë³‘í•©
    merge_start = 1
    prev_header = ws1.cell(1, 1).value
    
    for col in range(2, len(df_sheet1.columns) + 2):
        current_header = ws1.cell(1, col).value if col <= len(df_sheet1.columns) else None
        
        if current_header != prev_header or col == len(df_sheet1.columns) + 1:
            if merge_start < col - 1:
                ws1.merge_cells(start_row=1, start_column=merge_start, end_row=1, end_column=col - 1)
            merge_start = col
            prev_header = current_header
    
    # 3í–‰ë¶€í„°: ë°ì´í„°
    for r_idx, row_data in enumerate(df_sheet1.values, start=3):
        for c_idx, value in enumerate(row_data, start=1):
            cell = ws1.cell(row=r_idx, column=c_idx, value=value)
            
            col_name = df_sheet1.columns[c_idx - 1]
            
            # ë³€í™”ëŸ‰ ìƒ‰ìƒ
            if 'ë³€í™”' in col_name and pd.notna(value) and isinstance(value, (int, float)):
                if value < 0:
                    cell.font = Font(color='0000FF')
                elif value > 0:
                    cell.font = Font(color='FF0000')
    
    ws1.auto_filter.ref = ws1.dimensions
    ws1.freeze_panes = 'I3'
    
    print(f"   âœ“ {len(df_sheet1):,}ê°œ í–‰ ì‘ì„±")
    
    # ===== Sheet 2: ì¤‘ë³µ UPC ê·¸ë£¹í™” =====
    print("\nğŸ“„ Sheet 2: ì¤‘ë³µ UPC ê·¸ë£¹í™”...")
    ws2 = wb.create_sheet("ì¤‘ë³µUPC_ê·¸ë£¹í™”")
    
    # ë©€í‹°ë ˆë²¨ í—¤ë” (Sheet 1ê³¼ ë™ì¼)
    ws2.cell(1, 4, "ê¸°ë³¸ì •ë³´")  # ìˆ¨ê¹€ ì»¬ëŸ¼ 3ê°œ ì œì™¸
    
    col_idx = 11  # ìˆ¨ê¹€ 3ê°œ + ê¸°ë³¸ì •ë³´ 8ê°œ
    for date in dates2:
        date_str = date[5:].replace('-', '/')
        ws2.cell(1, col_idx, date_str)
        col_idx += 4
    
    for i in range(1, len(dates2)):
        date_str = dates2[i][5:].replace('-', '/')
        ws2.cell(1, col_idx, f"{date_str}_ë³€í™”")
        col_idx += 3
    
    # 2í–‰: í•˜ìœ„ í—¤ë”
    for c_idx, col_name in enumerate(df_sheet2.columns, 1):
        if col_name.startswith('_'):
            ws2.cell(2, c_idx, col_name)
        elif col_name in ['ì¹´í…Œê³ ë¦¬', 'ì†ŒìŠ¤', 'UPC', 'í’ˆë²ˆ', 'VendorItemID', 'ìƒí’ˆëª…', 'ìµœì¢…ë¦¬ë·°ìˆ˜', 'ìµœì¢…í‰ì ']:
            ws2.cell(2, c_idx, col_name)
        elif '_' in col_name:
            parts = col_name.rsplit('_', 1)
            ws2.cell(2, c_idx, parts[1])
    
    # í—¤ë” ìŠ¤íƒ€ì¼
    for row in [1, 2]:
        for col in range(4, len(df_sheet2.columns) + 1):  # ìˆ¨ê¹€ ì œì™¸
            cell = ws2.cell(row, col)
            cell.font = header_font if row == 1 else subheader_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal='center', vertical='center')
    
    # ìƒìœ„ í—¤ë” ë³‘í•©
    merge_start = 4
    prev_header = ws2.cell(1, 4).value
    
    for col in range(5, len(df_sheet2.columns) + 2):
        current_header = ws2.cell(1, col).value if col <= len(df_sheet2.columns) else None
        
        if current_header != prev_header or col == len(df_sheet2.columns) + 1:
            if merge_start < col - 1:
                ws2.merge_cells(start_row=1, start_column=merge_start, end_row=1, end_column=col - 1)
            merge_start = col
            prev_header = current_header
    
    # ë°ì´í„° & ê·¸ë£¹í™”
    for r_idx, row_data in enumerate(df_sheet2.values, start=3):
        for c_idx, value in enumerate(row_data, start=1):
            cell = ws2.cell(row=r_idx, column=c_idx, value=value)
            
            is_rep = df_sheet2.iloc[r_idx - 3]['_is_representative']
            col_name = df_sheet2.columns[c_idx - 1]
            
            # ëŒ€í‘œ ìƒí’ˆ ìŠ¤íƒ€ì¼
            if is_rep and c_idx > 3:
                cell.fill = rep_fill
                cell.font = rep_font
            
            # ë³€í™”ëŸ‰ ìƒ‰ìƒ
            if 'ë³€í™”' in col_name and pd.notna(value) and isinstance(value, (int, float)):
                if value < 0:
                    cell.font = Font(color='0000FF', bold=is_rep)
                elif value > 0:
                    cell.font = Font(color='FF0000', bold=is_rep)
    
    # ìˆ¨ê¹€ ì»¬ëŸ¼
    ws2.column_dimensions['A'].hidden = True
    ws2.column_dimensions['B'].hidden = True
    ws2.column_dimensions['C'].hidden = True
    
    # ê·¸ë£¹í™”
    print("   ğŸ”§ ê·¸ë£¹í™” ì ìš© ì¤‘...")
    prev_upc = None
    group_start = 3
    group_count = 0
    
    for idx in range(len(df_sheet2)):
        excel_row = idx + 3
        current_upc = df_sheet2.iloc[idx]['_upc_sort']
        
        if prev_upc != current_upc:
            if prev_upc is not None and group_start < excel_row - 1:
                ws2.row_dimensions.group(
                    group_start + 1,
                    excel_row - 1,
                    outline_level=1,
                    hidden=False
                )
                group_count += 1
            
            group_start = excel_row
            prev_upc = current_upc
    
    # ë§ˆì§€ë§‰ ê·¸ë£¹
    if group_start < len(df_sheet2) + 2:
        ws2.row_dimensions.group(
            group_start + 1,
            len(df_sheet2) + 2,
            outline_level=1,
            hidden=False
        )
        group_count += 1
    
    ws2.auto_filter.ref = ws2.dimensions
    ws2.freeze_panes = 'K3'
    
    print(f"   âœ“ {len(df_sheet2):,}ê°œ í–‰, {group_count:,}ê°œ ê·¸ë£¹")
    
    # ì €ì¥
    wb.save(output_path)
    print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {output_path}")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("\n" + "="*80)
    print("ğŸ¯ ìµœì¢… Price Agent Excel (2-Sheet)")
    print("="*80)
    print("\nêµ¬ì¡°:")
    print("  ğŸ“Š Sheet 1: ì „ì²´ ë°ì´í„° ì‹œê³„ì—´ (í”„ë ˆì  í…Œì´ì…˜)")
    print("  ğŸ“Š Sheet 2: ì¤‘ë³µ UPC ê·¸ë£¹í™” (379ê°œ)")
    print("\nìŠ¤íƒ€ì¼:")
    print("  âœ“ date_excel í˜•íƒœ (ìƒìœ„ í—¤ë”)")
    print("  âœ“ ë³€í™”ëŸ‰ ìƒ‰ìƒ (ìŒìˆ˜=íŒŒë‘, ì–‘ìˆ˜=ë¹¨ê°•)")
    print("  âœ“ ë°ì´í„° ìˆëŠ” ê·¸ëŒ€ë¡œ (Round ì—†ìŒ)")
    print("="*80)
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Sheet ìƒì„±
    df_sheet1, dates1 = generate_sheet1_all_products()
    df_sheet2, dates2 = generate_sheet2_overlap_upc()
    
    if df_sheet1.empty or df_sheet2.empty:
        print("\nâŒ ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
        return
    
    # Excel ì €ì¥
    output_path = os.path.join(OUTPUT_DIR, "price_agent_final.xlsx")
    save_to_excel_date_style(df_sheet1, dates1, df_sheet2, dates2, output_path)
    
    # í†µê³„
    print("\n" + "="*80)
    print("ğŸ“Š ìµœì¢… í†µê³„")
    print("="*80)
    print(f"\nâœ… Sheet 1 (ì „ì²´ ë°ì´í„°)")
    print(f"   - ì´ í–‰: {len(df_sheet1):,}ê°œ")
    print(f"   - ë‚ ì§œ: {len(dates1)}ì¼")
    
    print(f"\nâœ… Sheet 2 (ì¤‘ë³µ UPC)")
    print(f"   - ì´ í–‰: {len(df_sheet2):,}ê°œ")
    print(f"   - ì¤‘ë³µ UPC: {df_sheet2['UPC'].nunique():,}ê°œ")
    print(f"   - ëŒ€í‘œ ìƒí’ˆ: {df_sheet2['_is_representative'].sum():,}ê°œ")
    
    print("\n" + "="*80)
    print("âœ… ì™„ë£Œ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()