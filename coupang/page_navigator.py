import time
import random
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from bs4 import BeautifulSoup

class PageNavigator:
    def __init__(self, browser_manager, scraper, image_downloader):
        self.browser = browser_manager
        self.scraper = scraper
        self.image_downloader = image_downloader
        self.products = []
    
    def wait_for_page_load(self, timeout=20):
        """í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°"""
        try:
            wait = WebDriverWait(self.browser.driver, timeout)
            
            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€ ëŒ€ê¸°
            wait.until(lambda driver: 
                driver.find_elements(By.ID, "product-list") or 
                driver.find_elements(By.CLASS_NAME, "search-no-result") or
                "ì°¨ë‹¨" in driver.title.lower()
            )
            
            # DOM ë¡œë”© ì™„ë£Œ ëŒ€ê¸°
            self.browser.driver.execute_script("return document.readyState === 'complete'")
            
            # ì¶”ê°€ ë¡œë”© ì‹œê°„
            time.sleep(random.uniform(2, 4))
            
            # ì°¨ë‹¨ í˜ì´ì§€ í™•ì¸
            if "ì°¨ë‹¨" in self.browser.driver.title.lower() or "blocked" in self.browser.driver.title.lower():
                print("âš ï¸ ì°¨ë‹¨ í˜ì´ì§€ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ ëŒ€ê¸°í•´ì£¼ì„¸ìš”.")
                time.sleep(10)
                return False
            
            return True
            
        except TimeoutException:
            print("í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼")
            return False
    
    def human_like_scroll(self):
        """ì¸ê°„ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ë§"""
        try:
            # í˜ì´ì§€ ë†’ì´ ê°€ì ¸ì˜¤ê¸°
            total_height = self.browser.driver.execute_script("return document.body.scrollHeight")
            viewport_height = self.browser.driver.execute_script("return window.innerHeight")
            
            current_position = 0
            scroll_step = random.randint(200, 400)
            
            # í˜ì´ì§€ë¥¼ ì²œì²œíˆ ìŠ¤í¬ë¡¤ ë‹¤ìš´
            while current_position < total_height - viewport_height:
                scroll_distance = random.randint(scroll_step - 50, scroll_step + 50)
                current_position += scroll_distance
                
                self.browser.driver.execute_script(f"window.scrollTo(0, {current_position});")
                time.sleep(random.uniform(0.3, 0.8))
            
            # ì ì‹œ ëŒ€ê¸° í›„ ìƒë‹¨ìœ¼ë¡œ
            time.sleep(random.uniform(1, 2))
            self.browser.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(random.uniform(0.5, 1))
            
        except Exception as e:
            print(f"ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def extract_products_from_current_page(self):
        """í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ìƒí’ˆ ì¶”ì¶œ - ìƒˆë¡œìš´ HTML êµ¬ì¡° ëŒ€ì‘"""
        try:
            # ì°¨ë‹¨ í™•ì¸
            if "ì°¨ë‹¨" in self.browser.driver.title.lower():
                print("âš ï¸ ì°¨ë‹¨ëœ í˜ì´ì§€ì…ë‹ˆë‹¤. í¬ë¡¤ë§ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return []
            
            # ìŠ¤í¬ë¡¤ë§
            self.human_like_scroll()
            
            # HTML íŒŒì‹±
            html_content = self.browser.driver.page_source
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
            product_list = soup.find('ul', id='product-list')
            if not product_list:
                product_list = soup.select_one('ul[id="product-list"], [id*="product"], ul[class*="product"]')
                
            if not product_list:
                print("ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                no_result = soup.find('div', class_='search-no-result')
                if no_result:
                    print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ìƒí’ˆ ì¶”ì¶œ
            product_items = product_list.select('li.ProductUnit_productUnit__Qd6sv, li[class*="ProductUnit"], li[data-id]')
            page_products = []
            
            print(f"    í˜ì´ì§€ì—ì„œ {len(product_items)}ê°œ ìƒí’ˆ ë°œê²¬")
            
            for idx, item in enumerate(product_items):
                try:
                    product = self.scraper.extract_product_info(item)
                    if product and product.get('product_name'):
                        # ì´ë¯¸ì§€ ì²˜ë¦¬
                        product_id = product.get('product_id')
                        
                        if self.image_downloader and product_id:
                            # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                            image_url = self.image_downloader.extract_image_url_from_element(item)
                            product['image_url'] = image_url if image_url else ''
                            
                            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                            if image_url:
                                download_result = self.image_downloader.download_image(image_url, product_id)
                                product['image_download_result'] = download_result
                                product['image_local_path'] = download_result.get('filepath', '') if download_result.get('success') else ''
                                product['image_filename'] = download_result.get('filename', '') if download_result.get('success') else ''
                            else:
                                product['image_download_result'] = {'success': False, 'reason': 'no_url'}
                                product['image_local_path'] = ''
                                product['image_filename'] = ''
                        else:
                            product['image_url'] = ''
                            product['image_download_result'] = {'success': False, 'reason': 'not_attempted'}
                            product['image_local_path'] = ''
                            product['image_filename'] = ''
                        
                        page_products.append(product)
                        
                        # ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
                        if idx < 3:
                            product_name = product.get('product_name', 'N/A')[:50]
                            current_price = product.get('current_price', 'N/A')
                            discount_rate = product.get('discount_rate', 'N/A')
                            print(f"      ìƒí’ˆ {idx+1}: {product_name}... ({current_price}, í• ì¸: {discount_rate})")
                    
                except Exception as e:
                    print(f"      ìƒí’ˆ {idx+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    
                # ì²˜ë¦¬ ê°„ê²© ì¡°ì ˆ
                if idx % 10 == 0:
                    time.sleep(random.uniform(0.1, 0.3))
            
            print(f"    ì‹¤ì œ ì¶”ì¶œëœ ìƒí’ˆ ìˆ˜: {len(page_products)}ê°œ")
            if self.image_downloader:
                print(f"    ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í†µê³„: ì‹œë„ {self.image_downloader.image_download_stats['total_attempts']}ê°œ, ì„±ê³µ {self.image_downloader.image_download_stats['successful_downloads']}ê°œ")
            
            return page_products
            
        except Exception as e:
            print(f"í˜ì´ì§€ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return []
    
    def has_next_page(self):
        """ë‹¤ìŒ í˜ì´ì§€ í™•ì¸"""
        try:
            next_button = self.browser.driver.find_element(By.CSS_SELECTOR, 'a.Pagination_nextBtn__TUY5t')
            button_classes = next_button.get_attribute('class')
            return 'disabled' not in button_classes
        except:
            return False
    
    def go_to_next_page(self):
        """ë‹¤ìŒ í˜ì´ì§€ ì´ë™"""
        try:
            next_button = self.browser.driver.find_element(By.CSS_SELECTOR, 'a.Pagination_nextBtn__TUY5t')
            
            if 'disabled' in next_button.get_attribute('class'):
                return False
            
            # ë²„íŠ¼ ìœ„ì¹˜ë¡œ ìŠ¤í¬ë¡¤
            self.browser.driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", next_button)
            time.sleep(random.uniform(1, 2))
            
            # í´ë¦­
            self.browser.driver.execute_script("arguments[0].click();", next_button)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            time.sleep(random.uniform(3, 6))
            return True
            
        except Exception as e:
            print(f"ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì˜¤ë¥˜: {e}")
            return False
    
    def crawl_all_pages(self, start_url, max_pages=None, delay_range=(2, 5)):
        """ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§ - ìƒˆë¡œìš´ HTML êµ¬ì¡° ëŒ€ì‘"""
        try:
            print(f"í¬ë¡¤ë§ ì‹œì‘: {start_url}")
            if self.image_downloader:
                print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í™œì„±í™”: {self.image_downloader.image_dir}")
                print("(Gemini ì´ë¯¸ì§€ ë§¤ì¹­ì„ ìœ„í•œ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìˆ˜ì§‘)")
            print("(macOSì—ì„œëŠ” ì•½ê°„ì˜ ì¶”ê°€ ëŒ€ê¸°ì‹œê°„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            print("ğŸ”§ ìƒˆë¡œìš´ HTML êµ¬ì¡° ëŒ€ì‘ ì™„ë£Œ - ê°€ê²©/í• ì¸ìœ¨ ì •ìƒ ì¶”ì¶œ")
            
            # ì²« í˜ì´ì§€ ë¡œë“œ
            self.browser.driver.get(start_url)
            
            if not self.wait_for_page_load():
                print("ì²« í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")
                return []
            
            page_count = 0
            
            while True:
                page_count += 1
                print(f"\n=== í˜ì´ì§€ {page_count} í¬ë¡¤ë§ ì¤‘ ===")
                
                # í˜„ì¬ í˜ì´ì§€ ìƒí’ˆ ì¶”ì¶œ
                page_products = self.extract_products_from_current_page()
                
                if not page_products and page_count == 1:
                    print("âš ï¸ ì²« í˜ì´ì§€ì—ì„œ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print("í˜„ì¬ í˜ì´ì§€ ì œëª©:", self.browser.driver.title)
                    print("ë¸Œë¼ìš°ì €ì—ì„œ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    
                    # 10ì´ˆ ëŒ€ê¸° (ìˆ˜ë™ ì²˜ë¦¬ ì‹œê°„)
                    time.sleep(10)
                    page_products = self.extract_products_from_current_page()
                
                self.products.extend(page_products)
                
                print(f"í˜ì´ì§€ {page_count}ì—ì„œ {len(page_products)}ê°œ ìƒí’ˆ ì¶”ì¶œ")
                print(f"ì´ ëˆ„ì  ìƒí’ˆ ìˆ˜: {len(self.products)}ê°œ")
                
                # ë°ì´í„° í’ˆì§ˆ í™•ì¸ (ì²˜ìŒ ëª‡ ê°œ ìƒí’ˆ)
                if page_products and len(page_products) > 0:
                    sample_product = page_products[0]
                    print(f"ìƒ˜í”Œ ìƒí’ˆ í’ˆì§ˆ í™•ì¸:")
                    print(f"  - ìƒí’ˆëª…: {sample_product.get('product_name', 'N/A')[:50]}...")
                    print(f"  - ê°€ê²©: {sample_product.get('current_price', 'N/A')}")
                    print(f"  - í• ì¸ìœ¨: {sample_product.get('discount_rate', 'N/A')}")
                    print(f"  - ë¦¬ë·°ìˆ˜: {sample_product.get('review_count', 'N/A')}")
                
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ëˆ„ì  í†µê³„
                if self.image_downloader:
                    stats = self.image_downloader.image_download_stats
                    print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ëˆ„ì  í†µê³„:")
                    print(f"  - ì‹œë„: {stats['total_attempts']}ê°œ")
                    print(f"  - ì„±ê³µ: {stats['successful_downloads']}ê°œ")
                    print(f"  - ì‹¤íŒ¨: {stats['failed_downloads']}ê°œ")
                    print(f"  - ê¸°ì¡´íŒŒì¼: {stats['skipped_existing']}ê°œ")
                
                # ìµœëŒ€ í˜ì´ì§€ í™•ì¸
                if max_pages and page_count >= max_pages:
                    print(f"ìµœëŒ€ í˜ì´ì§€ ìˆ˜({max_pages}) ë„ë‹¬")
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                if not self.has_next_page():
                    print("ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬")
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if not self.go_to_next_page():
                    print("ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨")
                    break
                
                # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                if not self.wait_for_page_load():
                    print("í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨")
                    break
                
                # ëœë¤ ëŒ€ê¸° (macOSì—ì„œëŠ” ì¡°ê¸ˆ ë” ê¸¸ê²Œ)
                wait_time = random.uniform(delay_range[0] + 1, delay_range[1] + 2)
                print(f"{wait_time:.1f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(wait_time)
            
            print(f"\ní¬ë¡¤ë§ ì™„ë£Œ!")
            print(f"ì´ {len(self.products)}ê°œ ìƒí’ˆ ìˆ˜ì§‘")
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ìµœì¢… í†µê³„
            if self.image_downloader:
                self.image_downloader.print_image_download_summary()
            
            return self.products
            
        except KeyboardInterrupt:
            print("\nì‚¬ìš©ìê°€ í¬ë¡¤ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            if self.image_downloader:
                print("í˜„ì¬ê¹Œì§€ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€:")
                self.image_downloader.print_image_download_summary()
            return self.products
            
        except Exception as e:
            print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            if self.image_downloader:
                print("í˜„ì¬ê¹Œì§€ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€:")
                self.image_downloader.print_image_download_summary()
            return self.products