"""
íŒŒì´í”„ë¼ì¸ Orchestrator
DB ìƒíƒœ ê¸°ë°˜ ìë™ ì‹¤í–‰

ë¡œì§:
1. ìƒí’ˆ ì—†ìŒ â†’ NEW (ì²˜ìŒë¶€í„°)
2. ì •ìƒ ë¯¸ì™„ë£Œ(crawled/translated) ìˆìŒ â†’ RESUME (ë‚¨ì€ ê²ƒë§Œ)
3. ì™„ë£Œë¨ â†’ UPDATE (í¬ë¡¤ë§ë¶€í„°)

Failed ì²˜ë¦¬:
- UPDATE ì‹œ failed â†’ crawledë¡œ ë¦¬ì…‹ (ìƒˆ ì‚¬ì´í´ ì‹œë„)
- ë¬´í•œ RESUME ë°©ì§€
"""

import sys
import os
import argparse
from datetime import datetime
from typing import Tuple, Dict, Any

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from db.database import Database

# Coupang ëª¨ë“ˆ
from coupang.crawler import CoupangCrawlerDB
from coupang.translator import TranslatorDB

# IHerb ëª¨ë“ˆ
from iherbscraper.main import IHerbScraperDB


class PipelineOrchestrator:
    """íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰ ê´€ë¦¬"""
    
    def __init__(self, db_path='products.db', headless=False, max_iherb_products=5):
        self.db = Database(db_path)
        self.headless = headless
        self.max_iherb_products = max_iherb_products
        
    def analyze_state(self, brand_name: str) -> Tuple[str, Dict[str, int]]:
        """
        ë¸Œëœë“œ ìƒíƒœ ë¶„ì„ ë° ì‹¤í–‰ ëª¨ë“œ ê²°ì •
        
        Returns:
            (mode, stats)
            - mode: 'NEW' | 'RESUME' | 'UPDATE'
            - stats: {'total', 'crawled', 'translated', 'matched', 'failed'}
        """
        stats = {
            'total': 0,
            'crawled': 0,
            'translated': 0,
            'matched': 0,
            'failed': 0
        }
        
        # ê° ë‹¨ê³„ë³„ ìƒí’ˆ ìˆ˜ ì¡°íšŒ
        with self.db.get_connection() as conn:
            # ì „ì²´ ìƒí’ˆ ìˆ˜
            result = conn.execute("""
                SELECT COUNT(*) as cnt FROM products WHERE brand_name = ?
            """, (brand_name,)).fetchone()
            stats['total'] = result['cnt']
            
            # ë‹¨ê³„ë³„ ì¹´ìš´íŠ¸
            for stage in ['crawled', 'translated', 'matched', 'failed']:
                result = conn.execute("""
                    SELECT COUNT(*) as cnt FROM products 
                    WHERE brand_name = ? AND pipeline_stage = ?
                """, (brand_name, stage)).fetchone()
                stats[stage] = result['cnt']
        
        # íŒë‹¨ ë¡œì§
        if stats['total'] == 0:
            mode = 'NEW'
        elif stats['crawled'] + stats['translated'] > 0:
            # ì •ìƒ ë¯¸ì™„ë£Œ ì‘ì—… ìˆìŒ (failed ì œì™¸)
            mode = 'RESUME'
        else:
            # ëª¨ë‘ ì™„ë£Œ (matchedë§Œ ìˆê±°ë‚˜ failedë§Œ ìˆìŒ)
            mode = 'UPDATE'
        
        return mode, stats
    
    def run(self, brand_name: str) -> Dict[str, Any]:
        """
        ë¸Œëœë“œ íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰
        
        Returns:
            ì‹¤í–‰ ê²°ê³¼ í†µê³„
        """
        print(f"\n{'='*80}")
        print(f"ğŸ” ë¸Œëœë“œ ìƒíƒœ ë¶„ì„: {brand_name}")
        print(f"{'='*80}")
        
        # 1. ìƒíƒœ ë¶„ì„
        mode, stats = self.analyze_state(brand_name)
        
        print(f"\nğŸ“Š í˜„ì¬ ìƒíƒœ:")
        print(f"   ì „ì²´ ìƒí’ˆ: {stats['total']}ê°œ")
        if stats['total'] > 0:
            print(f"   - crawled: {stats['crawled']}ê°œ")
            print(f"   - translated: {stats['translated']}ê°œ")
            print(f"   - matched: {stats['matched']}ê°œ")
            print(f"   - failed: {stats['failed']}ê°œ")
        
        print(f"\nğŸ¯ ê²°ì •ëœ ì‹¤í–‰ ëª¨ë“œ: {mode}")
        
        if mode == 'NEW':
            print(f"   ì´ìœ : ìƒí’ˆ ë°ì´í„° ì—†ìŒ")
            return self._run_new(brand_name)
        elif mode == 'RESUME':
            print(f"   ì´ìœ : ë¯¸ì™„ë£Œ ì‘ì—… {stats['crawled'] + stats['translated']}ê°œ ë°œê²¬")
            return self._run_resume(brand_name, stats)
        else:  # UPDATE
            print(f"   ì´ìœ : ì „ì²´ {stats['matched'] + stats['failed']}ê°œ ì™„ë£Œë¨, ì—…ë°ì´íŠ¸ í•„ìš”")
            return self._run_update(brand_name)
    
    def _run_new(self, brand_name: str) -> Dict[str, Any]:
        """NEW ëª¨ë“œ: ì²˜ìŒë¶€í„° ì „ì²´ ì‹¤í–‰"""
        print(f"\n{'='*80}")
        print(f"ğŸ†• NEW ëª¨ë“œ: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        print(f"{'='*80}")
        
        result = {
            'mode': 'NEW',
            'crawled': 0,
            'translated': 0,
            'matched': 0,
            'failed': 0
        }
        
        # ë¸Œëœë“œ ì •ë³´ í™•ì¸
        brand_info = self.db.get_brand(brand_name)
        if not brand_info or not brand_info['coupang_search_url']:
            raise ValueError(f"ë¸Œëœë“œ '{brand_name}'ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ê±°ë‚˜ URLì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # 1. í¬ë¡¤ë§
        print(f"\n[1/3] í¬ë¡¤ë§ ì‹œì‘...")
        crawler = CoupangCrawlerDB(
            db=self.db,
            brand_name=brand_name,
            headless=self.headless
        )
        crawler.start_driver()
        crawler_stats = crawler.crawl_and_save(brand_info['coupang_search_url'])
        crawler.close()
        result['crawled'] = crawler_stats.get('crawled_count', 0)
        print(f"âœ“ {result['crawled']}ê°œ í¬ë¡¤ë§ ì™„ë£Œ")
        
        # 2. ë²ˆì—­
        print(f"\n[2/3] ë²ˆì—­ ì‹œì‘...")
        translator = TranslatorDB(db=self.db)
        trans_stats = translator.translate_brand(brand_name)
        result['translated'] = trans_stats.get('translated', 0)
        print(f"âœ“ {result['translated']}ê°œ ë²ˆì—­ ì™„ë£Œ")
        
        # 3. ë§¤ì¹­
        print(f"\n[3/3] ë§¤ì¹­ ì‹œì‘...")
        scraper = IHerbScraperDB(
            db=self.db,
            brand_name=brand_name,
            headless=self.headless,
            max_products=self.max_iherb_products
        )
        match_result = scraper.match_all_products()
        scraper.close()
        result['matched'] = match_result.get('matched', 0)
        result['failed'] = match_result.get('error', 0)
        print(f"âœ“ {result['matched']}ê°œ ë§¤ì¹­ ì„±ê³µ, {result['failed']}ê°œ ì‹¤íŒ¨")
        
        return result
    
    def _run_resume(self, brand_name: str, stats: Dict[str, int]) -> Dict[str, Any]:
        """RESUME ëª¨ë“œ: ì¤‘ë‹¨ëœ ì‘ì—… ì´ì–´í•˜ê¸°"""
        print(f"\n{'='*80}")
        print(f"â–¶ï¸ RESUME ëª¨ë“œ: ë¯¸ì™„ë£Œ ì‘ì—… ì¬ê°œ")
        print(f"{'='*80}")
        
        result = {
            'mode': 'RESUME',
            'crawled': 0,
            'translated': 0,
            'matched': 0,
            'failed': 0
        }
        
        # 1. í¬ë¡¤ë§ (crawled ìƒí’ˆì´ ìˆìœ¼ë©´)
        if stats['crawled'] > 0:
            print(f"\nâš ï¸ crawled ë‹¨ê³„ ìƒí’ˆ {stats['crawled']}ê°œ ë°œê²¬")
            print(f"   â†’ í¬ë¡¤ë§ ì¤‘ë‹¨ìœ¼ë¡œ íŒë‹¨, í¬ë¡¤ë§ë¶€í„° ì¬ì‹œì‘")
            
            brand_info = self.db.get_brand(brand_name)
            if not brand_info or not brand_info['coupang_search_url']:
                raise ValueError(f"ë¸Œëœë“œ '{brand_name}'ì˜ URL ì •ë³´ ì—†ìŒ")
            
            crawler = CoupangCrawlerDB(
                db=self.db,
                brand_name=brand_name,
                headless=self.headless
            )
            crawler.start_driver()
            crawler_stats = crawler.crawl_and_save(brand_info['coupang_search_url'])
            crawler.close()
            result['crawled'] = crawler_stats.get('crawled_count', 0)
            print(f"âœ“ {result['crawled']}ê°œ í¬ë¡¤ë§ ì™„ë£Œ")
        else:
            print(f"\n[í¬ë¡¤ë§] ê±´ë„ˆëœ€ (crawled ë‹¨ê³„ ì—†ìŒ)")
        
        # 2. ë²ˆì—­ (crawled ëŒ€ê¸° ì¤‘ì¸ ìƒí’ˆë§Œ)
        to_translate = len(self.db.get_products_by_stage(brand_name, 'crawled'))
        if to_translate > 0:
            print(f"\n[ë²ˆì—­] {to_translate}ê°œ ì‹œì‘...")
            translator = TranslatorDB(db=self.db)
            trans_stats = translator.translate_brand(brand_name)
            result['translated'] = trans_stats.get('translated', 0)
            print(f"âœ“ {result['translated']}ê°œ ë²ˆì—­ ì™„ë£Œ")
        else:
            print(f"\n[ë²ˆì—­] ê±´ë„ˆëœ€ (crawled ë‹¨ê³„ ì—†ìŒ)")
        
        # 3. ë§¤ì¹­ (translated ëŒ€ê¸° ì¤‘ì¸ ìƒí’ˆë§Œ)
        to_match = len(self.db.get_products_by_stage(brand_name, 'translated'))
        if to_match > 0:
            print(f"\n[ë§¤ì¹­] {to_match}ê°œ ì‹œì‘...")
            scraper = IHerbScraperDB(
                db=self.db,
                brand_name=brand_name,
                headless=self.headless,
                max_products=self.max_iherb_products
            )
            match_result = scraper.match_all_products()
            scraper.close()
            result['matched'] = match_result.get('matched', 0)
            result['failed'] = match_result.get('error', 0)
            print(f"âœ“ {result['matched']}ê°œ ë§¤ì¹­ ì„±ê³µ, {result['failed']}ê°œ ì‹¤íŒ¨")
        else:
            print(f"\n[ë§¤ì¹­] ê±´ë„ˆëœ€ (translated ë‹¨ê³„ ì—†ìŒ)")
        
        return result
    
    def _run_update(self, brand_name: str) -> Dict[str, Any]:
        """UPDATE ëª¨ë“œ: ìƒˆ í¬ë¡¤ë§ í›„ ì‹ ê·œ ìƒí’ˆë§Œ ì²˜ë¦¬"""
        print(f"\n{'='*80}")
        print(f"ğŸ”„ UPDATE ëª¨ë“œ: ìƒˆ í¬ë¡¤ë§ ì‹œì‘")
        print(f"{'='*80}")
        
        result = {
            'mode': 'UPDATE',
            'crawled': 0,
            'translated': 0,
            'matched': 0,
            'failed': 0
        }
        
        # 1. í¬ë¡¤ë§ (ì „ì²´)
        print(f"\n[í¬ë¡¤ë§] ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        brand_info = self.db.get_brand(brand_name)
        if not brand_info or not brand_info['coupang_search_url']:
            raise ValueError(f"ë¸Œëœë“œ '{brand_name}'ì˜ URL ì •ë³´ ì—†ìŒ")
        
        crawler = CoupangCrawlerDB(
            db=self.db,
            brand_name=brand_name,
            headless=self.headless
        )
        crawler.start_driver()
        crawler_stats = crawler.crawl_and_save(brand_info['coupang_search_url'])
        crawler.close()
        result['crawled'] = crawler_stats.get('crawled_count', 0)
        print(f"âœ“ {result['crawled']}ê°œ í¬ë¡¤ë§ ì™„ë£Œ")
        
        # í¬ë¡¤ë§ í›„ ìƒíƒœ ì¬í™•ì¸
        print(f"\n[ìƒíƒœ í™•ì¸] í¬ë¡¤ë§ í›„ ë¶„ë¥˜...")
        with self.db.get_connection() as conn:
            # failedì˜€ë˜ ìƒí’ˆì´ crawledë¡œ ë¦¬ì…‹ë˜ì—ˆëŠ”ì§€ í™•ì¸
            new_crawled = conn.execute("""
                SELECT COUNT(*) as cnt FROM products
                WHERE brand_name = ? AND pipeline_stage = 'crawled'
            """, (brand_name,)).fetchone()['cnt']
            
            matched_count = conn.execute("""
                SELECT COUNT(*) as cnt FROM products
                WHERE brand_name = ? AND pipeline_stage = 'matched'
            """, (brand_name,)).fetchone()['cnt']
        
        print(f"   - ì‹ ê·œ/ë¦¬ì…‹ ìƒí’ˆ: {new_crawled}ê°œ (crawled)")
        print(f"   - ê¸°ì¡´ ì™„ë£Œ ìƒí’ˆ: {matched_count}ê°œ (matched)")
        
        # ì‹ ê·œ ìƒí’ˆì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ RESUME
        if new_crawled > 0:
            print(f"\nğŸ”„ ìë™ ì „í™˜: RESUME ëª¨ë“œ (ì‹ ê·œ {new_crawled}ê°œ ì²˜ë¦¬)")
            
            # 2. ë²ˆì—­
            print(f"\n[ë²ˆì—­] {new_crawled}ê°œ ì‹œì‘...")
            translator = TranslatorDB(db=self.db)
            trans_stats = translator.translate_brand(brand_name)
            result['translated'] = trans_stats.get('translated', 0)
            print(f"âœ“ {result['translated']}ê°œ ë²ˆì—­ ì™„ë£Œ")
            
            # 3. ë§¤ì¹­
            to_match = len(self.db.get_products_by_stage(brand_name, 'translated'))
            print(f"\n[ë§¤ì¹­] {to_match}ê°œ ì‹œì‘...")
            scraper = IHerbScraperDB(
                db=self.db,
                brand_name=brand_name,
                headless=self.headless,
                max_products=self.max_iherb_products
            )
            match_result = scraper.match_all_products()
            scraper.close()
            result['matched'] = match_result.get('matched', 0)
            result['failed'] = match_result.get('error', 0)
            print(f"âœ“ {result['matched']}ê°œ ë§¤ì¹­ ì„±ê³µ, {result['failed']}ê°œ ì‹¤íŒ¨")
        else:
            print(f"\nâœ“ ì‹ ê·œ ìƒí’ˆ ì—†ìŒ, ê°€ê²© ì—…ë°ì´íŠ¸ë§Œ ì™„ë£Œ")
        
        return result
    
    def register_brand(self, brand_name: str, coupang_url: str) -> None:
        """ë¸Œëœë“œ ë“±ë¡"""
        self.db.upsert_brand(brand_name, coupang_url)
        print(f"âœ“ ë¸Œëœë“œ '{brand_name}' ë“±ë¡ ì™„ë£Œ")
    
    def list_brands(self) -> None:
        """ë“±ë¡ëœ ë¸Œëœë“œ ëª©ë¡ ì¶œë ¥"""
        with self.db.get_connection() as conn:
            brands = conn.execute("""
                SELECT 
                    b.brand_name,
                    b.coupang_search_url,
                    b.last_crawled_at,
                    b.last_matched_at,
                    COUNT(p.id) as product_count,
                    SUM(CASE WHEN p.pipeline_stage = 'matched' THEN 1 ELSE 0 END) as matched_count
                FROM brands b
                LEFT JOIN products p ON b.brand_name = p.brand_name
                GROUP BY b.brand_name
                ORDER BY b.brand_name
            """).fetchall()
            
            if not brands:
                print("ë“±ë¡ëœ ë¸Œëœë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"\n{'='*80}")
            print(f"ë“±ë¡ëœ ë¸Œëœë“œ ëª©ë¡")
            print(f"{'='*80}")
            
            for brand in brands:
                print(f"\në¸Œëœë“œ: {brand['brand_name']}")
                print(f"  URL: {brand['coupang_search_url']}")
                print(f"  ìƒí’ˆ ìˆ˜: {brand['product_count']}ê°œ")
                print(f"  ë§¤ì¹­ ì™„ë£Œ: {brand['matched_count']}ê°œ")
                print(f"  ë§ˆì§€ë§‰ í¬ë¡¤ë§: {brand['last_crawled_at'] or 'ì—†ìŒ'}")
                print(f"  ë§ˆì§€ë§‰ ë§¤ì¹­: {brand['last_matched_at'] or 'ì—†ìŒ'}")


def main():
    parser = argparse.ArgumentParser(
        description='ì¿ íŒ¡-ì•„ì´í—ˆë¸Œ ê°€ê²© ë¹„êµ íŒŒì´í”„ë¼ì¸',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë¸Œëœë“œ ë“±ë¡
  python orchestrator.py --register --brand thorne --url "https://coupang.com/..."
  
  # ì‹¤í–‰ (ìë™ ëª¨ë“œ íŒë‹¨)
  python orchestrator.py --brand thorne
  
  # ë¸Œëœë“œ ëª©ë¡
  python orchestrator.py --list
        """
    )
    
    # ëª…ë ¹ì–´ ê·¸ë£¹
    parser.add_argument('--brand', type=str, help='ì²˜ë¦¬í•  ë¸Œëœë“œëª…')
    parser.add_argument('--register', action='store_true', help='ìƒˆ ë¸Œëœë“œ ë“±ë¡')
    parser.add_argument('--list', action='store_true', help='ë¸Œëœë“œ ëª©ë¡ ì¶œë ¥')
    
    # ë“±ë¡ ì‹œ í•„ìš”
    parser.add_argument('--url', type=str, help='ì¿ íŒ¡ ê²€ìƒ‰ URL (ë“±ë¡ ì‹œ)')
    
    # ì˜µì…˜
    parser.add_argument('--db', type=str, default='products.db', help='DB íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--headless', action='store_true', help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ê¸°ë³¸: ë¸Œë¼ìš°ì € í‘œì‹œ)')
    parser.add_argument('--max-products', type=int, default=5, 
                       help='ì•„ì´í—ˆë¸Œ ë¹„êµ ìƒí’ˆ ìˆ˜ (ê¸°ë³¸: 5)')
    
    args = parser.parse_args()
    
    # Orchestrator ìƒì„±
    orchestrator = PipelineOrchestrator(
        db_path=args.db,
        headless=args.headless,
        max_iherb_products=args.max_products
    )
    
    try:
        # ëª…ë ¹ ì‹¤í–‰
        if args.list:
            orchestrator.list_brands()
        
        elif args.register:
            if not args.brand or not args.url:
                parser.error("--registerëŠ” --brandì™€ --urlì´ í•„ìš”í•©ë‹ˆë‹¤")
            orchestrator.register_brand(args.brand, args.url)
        
        elif args.brand:
            # ìë™ ì‹¤í–‰
            result = orchestrator.run(args.brand)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\n{'='*80}")
            print(f"âœ… ì‹¤í–‰ ì™„ë£Œ")
            print(f"{'='*80}")
            print(f"ëª¨ë“œ: {result['mode']}")
            print(f"í¬ë¡¤ë§: {result['crawled']}ê°œ")
            print(f"ë²ˆì—­: {result['translated']}ê°œ")
            print(f"ë§¤ì¹­ ì„±ê³µ: {result['matched']}ê°œ")
            print(f"ë§¤ì¹­ ì‹¤íŒ¨: {result['failed']}ê°œ")
        
        else:
            parser.print_help()
    
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()