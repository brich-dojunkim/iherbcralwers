
import sys
import os
import time
import random
import csv
import re
import shutil
from datetime import datetime

# ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸ - ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
sys.path.insert(0, os.path.join(current_dir, 'coupang'))
sys.path.insert(0, os.path.join(current_dir, 'iherbscraper'))

from coupang.coupang_manager import BrowserManager as CoupangBrowser
from iherbscraper.iherb_manager import BrowserManager as IHerbBrowser
from iherbscraper.iherb_client import IHerbClient
from iherbscraper.product_matcher import ProductMatcher

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


class InfiniteScrollCrawler:
    """ë¬´í•œ ìŠ¤í¬ë¡¤ í¬ë¡¤ëŸ¬ - ì‹ ê·œ ìƒí’ˆë§Œ ìˆ˜ì§‘"""
    
    def __init__(self, browser, existing_ids, global_new_ids):
        self.browser = browser
        self.existing_ids = existing_ids  # ê¸°ì¡´ 774ê°œ ë¸”ë™ë¦¬ìŠ¤íŠ¸
        self.global_new_ids = global_new_ids  # ì „ì²´ ì‹ ê·œ ìˆ˜ì§‘ ID
        self.products = []
    
    def infinite_scroll_crawl(self, url, target_count=300):
        """ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ì‹ ê·œ ìƒí’ˆë§Œ ìˆ˜ì§‘"""
        try:
            print(f"\n{'='*80}")
            print(f"ğŸ¯ ì‹ ê·œ ìƒí’ˆ í¬ë¡¤ë§ ì‹œì‘: {target_count}ê°œ ëª©í‘œ")
            print(f"   ê¸°ì¡´ {len(self.existing_ids)}ê°œ ì œì™¸")
            print(f"{'='*80}\n")
            
            # í˜ì´ì§€ ë¡œë“œ
            self.browser.driver.get(url)
            time.sleep(random.uniform(3, 5))
            
            # íŒë§¤ëŸ‰ìˆœ í•„í„° í´ë¦­
            self._click_sales_filter()
            
            no_new_products_count = 0
            max_no_new_attempts = 8  # 8ë²ˆ ì—°ì† ìƒˆ ìƒí’ˆ ì—†ìœ¼ë©´ ì¢…ë£Œ
            category_seen_ids = set()  # ì´ ì¹´í…Œê³ ë¦¬ì—ì„œ ìˆ˜ì§‘í•œ ID
            scroll_count = 0
            max_scrolls = 100  # ìµœëŒ€ 100ë²ˆ ìŠ¤í¬ë¡¤
            
            # ëˆ„ì  í†µê³„
            total_stats = {
                'total_found': 0,
                'skipped_existing': 0,
                'skipped_already_collected': 0,
                'skipped_duplicate_in_page': 0,
                'collected': 0
            }
            
            while len(self.products) < target_count and scroll_count < max_scrolls:
                scroll_count += 1
                
                # í˜„ì¬ í˜ì´ì§€ ìƒí’ˆ ì¶”ì¶œ (í†µê³„ í¬í•¨)
                stats = self._extract_new_products(category_seen_ids)
                
                # ëˆ„ì  í†µê³„ ì—…ë°ì´íŠ¸
                for key in total_stats:
                    total_stats[key] += stats[key]
                
                # ìƒì„¸ ì¶œë ¥
                print(f"\n{'â”€'*60}")
                print(f"[ìŠ¤í¬ë¡¤ {scroll_count}íšŒ]")
                print(f"{'â”€'*60}")
                print(f"í˜ì´ì§€ ì „ì²´: {stats['total_found']}ê°œ (DOMì— ë¡œë“œëœ ì´ ìƒí’ˆ)")
                
                if stats['skipped_existing'] > 0 or stats['skipped_already_collected'] > 0 or stats['skipped_duplicate_in_page'] > 0 or stats['collected'] > 0:
                    print(f"ì´ë²ˆ ë¼ìš´ë“œ ì²˜ë¦¬:")
                
                if stats['skipped_existing'] > 0:
                    print(f"  â”œâ”€ ê¸°ì¡´ 776ê°œ ì¤‘ë³µ: {stats['skipped_existing']}ê°œ âŒ")
                if stats['skipped_already_collected'] > 0:
                    print(f"  â”œâ”€ ì´ë¯¸ ìˆ˜ì§‘í•œ ìƒí’ˆ: {stats['skipped_already_collected']}ê°œ âŒ")
                if stats['skipped_duplicate_in_page'] > 0:
                    print(f"  â”œâ”€ í˜ì´ì§€ ë‚´ ì¤‘ë³µ: {stats['skipped_duplicate_in_page']}ê°œ âŒ")
                
                if stats['collected'] > 0:
                    print(f"  â””â”€ ğŸ¯ ì‹ ê·œ ìˆ˜ì§‘: {stats['collected']}ê°œ âœ…")
                    no_new_products_count = 0
                else:
                    print(f"  â””â”€ ğŸ¯ ì‹ ê·œ ìˆ˜ì§‘: 0ê°œ âš ï¸")
                    no_new_products_count += 1
                
                # ì§„í–‰ë¥ 
                progress = (len(self.products) / target_count) * 100
                print(f"\nğŸ“Š ëˆ„ì  ì§„í–‰: {len(self.products)}/{target_count}ê°œ ({progress:.1f}%)")
                print(f"{'â”€'*60}")
                
                # ì¢…ë£Œ ì¡°ê±´ ì²´í¬
                if stats['collected'] == 0:
                    if no_new_products_count >= max_no_new_attempts:
                        print(f"\n{'='*60}")
                        print(f"âš ï¸  ë” ì´ìƒ ìƒˆ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                        print(f"   ({no_new_products_count}ë²ˆ ì—°ì† ì‹ ê·œ ìƒí’ˆ 0ê°œ)")
                        print(f"{'='*60}")
                        break
                
                # ëª©í‘œ ë‹¬ì„± ì²´í¬
                if len(self.products) >= target_count:
                    print(f"\n{'='*60}")
                    print(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±: {len(self.products)}ê°œ ìˆ˜ì§‘!")
                    print(f"{'='*60}")
                    break
                
                # ìŠ¤í¬ë¡¤ (ìƒˆ ì½˜í…ì¸  ë¡œë“œ í™•ì¸)
                has_new_content = self._scroll_to_bottom()
                
                # í˜ì´ì§€ ëì— ë„ë‹¬í–ˆëŠ”ë° ëª©í‘œ ë¯¸ë‹¬ì„±
                if not has_new_content:
                    print(f"\n{'='*60}")
                    print(f"âš ï¸  í˜ì´ì§€ ë ë„ë‹¬")
                    print(f"   ìµœì¢… ìˆ˜ì§‘: {len(self.products)}ê°œ (ëª©í‘œ: {target_count}ê°œ)")
                    print(f"{'='*60}")
                    break
                
                # ì¶”ê°€ ëŒ€ê¸° (ë¬´í•œ ìŠ¤í¬ë¡¤ ì•ˆì •í™”)
                time.sleep(random.uniform(1, 2))
            
            # ìµœì¢… í†µê³„
            print(f"\n{'='*80}")
            print(f"ğŸ“Š í¬ë¡¤ë§ ì™„ë£Œ - ëˆ„ì  í†µê³„")
            print(f"{'='*80}")
            print(f"ì´ ìŠ¤í¬ë¡¤: {scroll_count}íšŒ")
            print(f"ë°œê²¬í•œ ìƒí’ˆ: {total_stats['total_found']}ê°œ")
            print(f"")
            print(f"í•„í„°ë§ ë‚´ì—­:")
            print(f"  â”œâ”€ ê¸°ì¡´ 776ê°œ ì¤‘ë³µ: {total_stats['skipped_existing']}ê°œ")
            print(f"  â”œâ”€ ì´ë¯¸ ìˆ˜ì§‘í•œ ìƒí’ˆ: {total_stats['skipped_already_collected']}ê°œ")
            print(f"  â””â”€ í˜ì´ì§€ ë‚´ ì¤‘ë³µ: {total_stats['skipped_duplicate_in_page']}ê°œ")
            print(f"")
            print(f"âœ… ì‹ ê·œ ìˆ˜ì§‘: {total_stats['collected']}ê°œ")
            print(f"{'='*80}\n")
            
            if scroll_count >= max_scrolls:
                print(f"âš ï¸ ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜({max_scrolls}íšŒ) ë„ë‹¬")
            
            return self.products
            
        except Exception as e:
            print(f"\nâŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return self.products
    
    def _click_sales_filter(self):
        """íŒë§¤ëŸ‰ìˆœ í•„í„° í´ë¦­"""
        try:
            print("ğŸ” íŒë§¤ëŸ‰ìˆœ í•„í„° ì°¾ëŠ” ì¤‘...")
            time.sleep(2)
            
            # íŒë§¤ëŸ‰ìˆœ ë²„íŠ¼ ì°¾ê¸°
            filter_button = WebDriverWait(self.browser.driver, 10).until(
                EC.presence_of_element_located((
                    By.XPATH, 
                    "//button[contains(text(), 'íŒë§¤ëŸ‰ìˆœ') or contains(@class, 'sales')]"
                ))
            )
            
            filter_button.click()
            print("âœ… íŒë§¤ëŸ‰ìˆœ í•„í„° í´ë¦­")
            time.sleep(3)
            
        except Exception as e:
            print(f"âš ï¸ íŒë§¤ëŸ‰ìˆœ í•„í„° ì°¾ê¸° ì‹¤íŒ¨: {e}")
    
    def _extract_new_products(self, category_seen_ids):
        """í˜„ì¬ í™”ë©´ì—ì„œ ì‹ ê·œ ìƒí’ˆë§Œ ì¶”ì¶œ - ìƒì„¸ í†µê³„ í¬í•¨"""
        try:
            # í†µê³„ ë³€ìˆ˜
            stats = {
                'total_found': 0,                # í™”ë©´ì—ì„œ ë°œê²¬í•œ ì´ ìƒí’ˆ ìˆ˜
                'skipped_existing': 0,            # ê¸°ì¡´ 776ê°œ ì¤‘ë³µ
                'skipped_already_collected': 0,   # ì´ë²ˆ í¬ë¡¤ë§ì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í•œ ìƒí’ˆ (ìˆ˜ì •!)
                'skipped_duplicate_in_page': 0,   # ê°™ì€ í˜ì´ì§€ ë‚´ ì¤‘ë³µ
                'collected': 0                    # ì‹ ê·œ ìˆ˜ì§‘
            }
            
            # ìƒí’ˆ ìš”ì†Œ ì°¾ê¸°
            product_elements = self.browser.driver.find_elements(
                By.CSS_SELECTOR,
                'li.product-wrap'
            )
            
            stats['total_found'] = len(product_elements)
            seen_this_round = set()  # ì´ë²ˆ ì¶”ì¶œì—ì„œ ë³¸ IDë“¤
            
            for element in product_elements:
                try:
                    # ìƒí’ˆ ë§í¬
                    link_element = element.find_element(By.CSS_SELECTOR, 'a.product-wrapper')
                    product_url = link_element.get_attribute('href')
                    
                    # Product ID ì¶”ì¶œ
                    match = re.search(r'itemId=(\d+)', product_url)
                    if not match:
                        continue
                    
                    product_id = match.group(1)
                    
                    # ì´ë²ˆ ë¼ìš´ë“œì—ì„œ ì´ë¯¸ ì²˜ë¦¬í–ˆëŠ”ê°€? (ê°™ì€ í˜ì´ì§€ ë‚´ ì¤‘ë³µ)
                    if product_id in seen_this_round:
                        stats['skipped_duplicate_in_page'] += 1
                        continue
                    seen_this_round.add(product_id)
                    
                    # ğŸ”¥ í•„í„°ë§ ë¡œì§ (í†µê³„ ìˆ˜ì§‘)
                    
                    # 1. ê¸°ì¡´ 776ê°œì— ìˆëŠ”ê°€?
                    if product_id in self.existing_ids:
                        stats['skipped_existing'] += 1
                        continue
                    
                    # 2. ì´ë²ˆ í¬ë¡¤ë§ì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í–ˆëŠ”ê°€? (ì „ì²´ ì¹´í…Œê³ ë¦¬ í¬í•¨)
                    if product_id in self.global_new_ids:
                        stats['skipped_already_collected'] += 1
                        continue
                    
                    # 3. ì´ ì¹´í…Œê³ ë¦¬ì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í–ˆëŠ”ê°€? (ì¤‘ë³µ ì²´í¬, ìœ„ì—ì„œ ê±¸ëŸ¬ì ¸ì•¼ í•¨)
                    if product_id in category_seen_ids:
                        stats['skipped_already_collected'] += 1
                        continue
                    
                    # âœ… ì™„ì „íˆ ìƒˆë¡œìš´ ìƒí’ˆ!
                    
                    # ìƒí’ˆëª…
                    try:
                        name_element = element.find_element(By.CSS_SELECTOR, 'div[data-v-1acd0e2a].name')
                        product_name = name_element.text.strip()
                    except:
                        try:
                            name_element = element.find_element(By.CSS_SELECTOR, 'div.name')
                            product_name = name_element.text.strip()
                        except:
                            continue
                    
                    # ê°€ê²©
                    try:
                        price_element = element.find_element(By.CSS_SELECTOR, 'strong.price-value')
                        price = price_element.text.strip()
                    except:
                        price = ""
                    
                    if not product_name:
                        continue
                    
                    # ì‹ ê·œ ìƒí’ˆ ì¶”ê°€
                    product = {
                        'product_id': product_id,
                        'product_name': product_name,
                        'product_url': product_url,
                        'current_price': price
                    }
                    
                    self.products.append(product)
                    category_seen_ids.add(product_id)
                    self.global_new_ids.add(product_id)
                    stats['collected'] += 1
                    
                except Exception as e:
                    continue
            
            return stats
            
        except Exception as e:
            print(f"  âš ï¸ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {
                'total_found': 0,
                'skipped_existing': 0,
                'skipped_already_collected': 0,
                'skipped_duplicate_in_page': 0,
                'collected': 0
            }
    
    def _scroll_to_bottom(self):
        """í˜ì´ì§€ ëê¹Œì§€ ì²œì²œíˆ ìŠ¤í¬ë¡¤ (ë¬´í•œ ìŠ¤í¬ë¡¤ ëŒ€ì‘)"""
        try:
            # í˜„ì¬ í˜ì´ì§€ ë†’ì´
            last_height = self.browser.driver.execute_script("return document.body.scrollHeight")
            
            # ë‹¨ê³„ì ìœ¼ë¡œ ìŠ¤í¬ë¡¤ (3-5ë‹¨ê³„)
            scroll_steps = random.randint(3, 5)
            scroll_pause = 0.5  # ê° ë‹¨ê³„ë§ˆë‹¤ 0.5ì´ˆ ëŒ€ê¸°
            
            for i in range(scroll_steps):
                # ì¼ë¶€ë§Œ ìŠ¤í¬ë¡¤
                scroll_amount = (last_height / scroll_steps) * (i + 1)
                self.browser.driver.execute_script(f"window.scrollTo(0, {scroll_amount});")
                time.sleep(scroll_pause)
            
            # ë§ˆì§€ë§‰ìœ¼ë¡œ ì™„ì „íˆ ëê¹Œì§€
            self.browser.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # ìƒˆ ì½˜í…ì¸  ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
            wait_time = 0
            max_wait = 5
            
            while wait_time < max_wait:
                time.sleep(1)
                wait_time += 1
                
                # ìƒˆ ë†’ì´ í™•ì¸
                new_height = self.browser.driver.execute_script("return document.body.scrollHeight")
                
                # ë†’ì´ê°€ ì¦ê°€í–ˆìœ¼ë©´ (ìƒˆ ì½˜í…ì¸  ë¡œë“œë¨)
                if new_height > last_height:
                    print(f"  ğŸ“¥ ìƒˆ ì½˜í…ì¸  ë¡œë“œë¨ ({last_height} â†’ {new_height})")
                    return True
            
            # ë†’ì´ ë³€í™” ì—†ìŒ (ë” ì´ìƒ ë¡œë“œí•  ì½˜í…ì¸  ì—†ìŒ)
            print(f"  âš ï¸ í˜ì´ì§€ ë ë„ë‹¬ (ë†’ì´ ë³€í™” ì—†ìŒ)")
            return False
            
        except Exception as e:
            print(f"  âš ï¸ ìŠ¤í¬ë¡¤ ì˜¤ë¥˜: {e}")
            return False


class CoupangIHerbAdd900Crawler:
    """ì¿ íŒ¡ -> ì•„ì´í—ˆë¸Œ í¬ë¡¤ëŸ¬: ì‹ ê·œ 900ê°œ ì¶”ê°€"""
    
    def __init__(self, 
                 output_file="coupang_iherb_products.csv",
                 cache_file="coupang_products_cache.csv"):
        self.output_file = output_file
        self.cache_file = cache_file
        
        self.csv_file = None
        self.csv_writer = None
        
        # ê¸°ì¡´ ë°ì´í„°
        self.existing_product_ids = set()  # ê¸°ì¡´ 774ê°œ ID
        self.matched_product_ids = set()   # ì´ë¯¸ ë§¤ì¹­ ì™„ë£Œëœ ID
        
        # ì‹ ê·œ ë°ì´í„°
        self.new_products = []  # ì‹ ê·œ ìˆ˜ì§‘í•  900ê°œ
        self.global_new_ids = set()  # ì „ì²´ ì‹ ê·œ ID (ì¹´í…Œê³ ë¦¬ ê°„ ì¤‘ë³µ ë°©ì§€)
        
        # ì „ì²´ ìƒí’ˆ (ê¸°ì¡´ + ì‹ ê·œ)
        self.all_products = []
        
        # ë¸Œë¼ìš°ì €
        self.coupang_browser = None
        self.iherb_browser = None
        self.iherb_client = None
        self.product_matcher = None
        
        self._load_existing_data()
        self._init_csv()
    
    def _load_existing_data(self):
        """ê¸°ì¡´ ë°ì´í„° ë¡œë“œ"""
        # 1. ê¸°ì¡´ ìºì‹œì—ì„œ ìƒí’ˆ ID ë¡œë“œ (ë¸”ë™ë¦¬ìŠ¤íŠ¸)
        if os.path.exists(self.cache_file):
            print(f"ğŸ“‚ ê¸°ì¡´ ìºì‹œ ë¡œë“œ: {self.cache_file}")
            try:
                with open(self.cache_file, 'r', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        product_id = row.get('ìƒí’ˆID', '')
                        if product_id:
                            self.existing_product_ids.add(product_id)
                        self.all_products.append(row)
                
                print(f"  âœ… ê¸°ì¡´ ìƒí’ˆ: {len(self.existing_product_ids)}ê°œ")
            except Exception as e:
                print(f"  âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 2. CSVì—ì„œ ì´ë¯¸ ë§¤ì¹­ ì™„ë£Œëœ ID ë¡œë“œ
        if os.path.exists(self.output_file):
            print(f"ğŸ“‚ ë§¤ì¹­ ê²°ê³¼ ë¡œë“œ: {self.output_file}")
            try:
                with open(self.output_file, 'r', encoding='utf-8-sig') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        url = row.get('ì¿ íŒ¡_ìƒí’ˆURL', '')
                        match = re.search(r'itemId=(\d+)', url)
                        if match:
                            self.matched_product_ids.add(match.group(1))
                
                print(f"  âœ… ë§¤ì¹­ ì™„ë£Œ: {len(self.matched_product_ids)}ê°œ\n")
            except Exception as e:
                print(f"  âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨: {e}\n")
    
    def _init_csv(self):
        """CSV íŒŒì¼ ì´ˆê¸°í™”"""
        file_exists = os.path.exists(self.output_file)
        
        if file_exists:
            # Append ëª¨ë“œ
            self.csv_file = open(self.output_file, 'a', newline='', encoding='utf-8-sig')
            self.csv_writer = csv.DictWriter(self.csv_file, fieldnames=[
                'ìˆ˜ì§‘ìˆœì„œ', 'ì¹´í…Œê³ ë¦¬', 'ì¿ íŒ¡_ìƒí’ˆURL', 'ì¿ íŒ¡_ì œí’ˆëª…',
                'ì¿ íŒ¡_ë¹„íšŒì›ê°€ê²©', 'ì•„ì´í—ˆë¸Œ_UPC', 'ì•„ì´í—ˆë¸Œ_íŒŒíŠ¸ë„˜ë²„', 'ìˆ˜ì§‘ì‹œê°„'
            ])
            print(f"ğŸ“ CSV íŒŒì¼ ì—´ê¸° (Append): {self.output_file}\n")
        else:
            # ìƒˆë¡œ ìƒì„±
            self.csv_file = open(self.output_file, 'w', newline='', encoding='utf-8-sig')
            self.csv_writer = csv.DictWriter(self.csv_file, fieldnames=[
                'ìˆ˜ì§‘ìˆœì„œ', 'ì¹´í…Œê³ ë¦¬', 'ì¿ íŒ¡_ìƒí’ˆURL', 'ì¿ íŒ¡_ì œí’ˆëª…',
                'ì¿ íŒ¡_ë¹„íšŒì›ê°€ê²©', 'ì•„ì´í—ˆë¸Œ_UPC', 'ì•„ì´í—ˆë¸Œ_íŒŒíŠ¸ë„˜ë²„', 'ìˆ˜ì§‘ì‹œê°„'
            ])
            self.csv_writer.writeheader()
            print(f"âœ… CSV íŒŒì¼ ìƒì„±: {self.output_file}\n")
        
        self.csv_file.flush()
    
    def crawl_new_coupang_products(self, categories):
        """ì‹ ê·œ ì¿ íŒ¡ ìƒí’ˆ 900ê°œ í¬ë¡¤ë§"""
        
        # âœ… ì´ë¯¸ ì¶©ë¶„í•œ ì‹ ê·œ ìƒí’ˆì´ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        expected_total = len(self.existing_product_ids) + 900
        current_total = len(self.all_products)
        
        if current_total >= expected_total:
            print("\n" + "="*80)
            print("âœ… ì¿ íŒ¡ í¬ë¡¤ë§ ì´ë¯¸ ì™„ë£Œë¨")
            print(f"   ìºì‹œ ìƒí’ˆ: {current_total}ê°œ")
            print(f"   ê¸°ì¡´: {len(self.existing_product_ids)}ê°œ")
            print(f"   ì‹ ê·œ: {current_total - len(self.existing_product_ids)}ê°œ")
            print("="*80)
            print("\nâ¡ï¸  ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ë‹¨ê³„ë¡œ ì´ë™...\n")
            return
        
        print("\n" + "="*80)
        print("ğŸ“¦ 1ë‹¨ê³„: ì‹ ê·œ ì¿ íŒ¡ ìƒí’ˆ ìˆ˜ì§‘")
        print(f"   ê¸°ì¡´ {len(self.existing_product_ids)}ê°œ ì œì™¸")
        print("="*80)
        
        # ì¿ íŒ¡ ë¸Œë¼ìš°ì € ì‹œì‘
        print("\nğŸš€ ì¿ íŒ¡ ë¸Œë¼ìš°ì € ì‹œì‘")
        self.coupang_browser = CoupangBrowser(headless=False)
        if not self.coupang_browser.start_driver():
            raise Exception("ì¿ íŒ¡ ë¸Œë¼ìš°ì € ì‹œì‘ ì‹¤íŒ¨")
        
        scroll_crawler = InfiniteScrollCrawler(
            self.coupang_browser,
            self.existing_product_ids,
            self.global_new_ids
        )
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ í¬ë¡¤ë§
        for category in categories:
            print("\n" + "="*80)
            print(f"ğŸ“¦ ì¹´í…Œê³ ë¦¬: {category['name']}")
            print(f"ğŸ¯ ëª©í‘œ: ì‹ ê·œ {category['count']}ê°œ")
            print("="*80)
            
            scroll_crawler.products = []  # ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ ì´ˆê¸°í™”
            
            products = scroll_crawler.infinite_scroll_crawl(
                category['url'],
                category['count']
            )
            
            if products:
                # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€
                for product in products:
                    product['category'] = category['name']
                
                self.new_products.extend(products)
                print(f"âœ… {category['name']}: {len(products)}ê°œ ì‹ ê·œ ìˆ˜ì§‘")
            else:
                print(f"âš ï¸ {category['name']}: ìˆ˜ì§‘ ì‹¤íŒ¨")
        
        # ì¿ íŒ¡ ë¸Œë¼ìš°ì € ì¢…ë£Œ
        self.coupang_browser.close()
        print(f"\n{'='*80}")
        print(f"âœ… ì‹ ê·œ í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(self.new_products)}ê°œ")
        print(f"{'='*80}\n")
        
        # ìºì‹œ ì—…ë°ì´íŠ¸
        self._update_cache()
    
    def _update_cache(self):
        """ìºì‹œ íŒŒì¼ ì—…ë°ì´íŠ¸ (ê¸°ì¡´ + ì‹ ê·œ = 1,674ê°œ)"""
        if not self.new_products:
            return
        
        # ë°±ì—… ìƒì„±
        if os.path.exists(self.cache_file):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = f"coupang_products_cache_{timestamp}.backup"
            shutil.copy(self.cache_file, backup_file)
            print(f"ğŸ’¾ ë°±ì—… ìƒì„±: {backup_file}")
        
        # ì‹ ê·œ ìƒí’ˆì„ all_productsì— ì¶”ê°€
        for product in self.new_products:
            self.all_products.append({
                'ì¹´í…Œê³ ë¦¬': product['category'],
                'ìƒí’ˆID': product['product_id'],
                'ìƒí’ˆëª…': product['product_name'],
                'ìƒí’ˆURL': product['product_url'],
                'ê°€ê²©': product['current_price']
            })
        
        # ìºì‹œ íŒŒì¼ ë®ì–´ì“°ê¸°
        try:
            with open(self.cache_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'ì¹´í…Œê³ ë¦¬', 'ìƒí’ˆID', 'ìƒí’ˆëª…', 'ìƒí’ˆURL', 'ê°€ê²©'
                ])
                writer.writeheader()
                writer.writerows(self.all_products)
            
            print(f"ğŸ’¾ ìºì‹œ ì—…ë°ì´íŠ¸: {len(self.all_products)}ê°œ ì €ì¥\n")
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}\n")
    
    def match_iherb_products(self):
        """ì•„ì´í—ˆë¸Œ ë§¤ì¹­ (ì‹ ê·œ 900ê°œë§Œ)"""
        print("\n" + "="*80)
        print(f"ğŸ“¦ 2ë‹¨ê³„: ì•„ì´í—ˆë¸Œ ë§¤ì¹­")
        print(f"   ì „ì²´ {len(self.all_products)}ê°œ ì¤‘")
        print(f"   ì‹ ê·œ {len(self.new_products)}ê°œë§Œ ë§¤ì¹­")
        print("="*80 + "\n")
        
        # ì•„ì´í—ˆë¸Œ ë¸Œë¼ìš°ì € ì‹œì‘
        print("ğŸš€ ì•„ì´í—ˆë¸Œ ë¸Œë¼ìš°ì € ì‹œì‘")
        self.iherb_browser = IHerbBrowser(headless=False)
        self.iherb_client = IHerbClient(self.iherb_browser)
        self.product_matcher = ProductMatcher(self.iherb_client)
        print("âœ… ì•„ì´í—ˆë¸Œ ë¸Œë¼ìš°ì € ì¤€ë¹„ ì™„ë£Œ (í•œê¸€ ê²€ìƒ‰)\n")
        
        # ë§¤ì¹­ ì‹œì‘
        start_time = time.time()
        completed = 0
        restart_counter = 0  # ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì¹´ìš´í„°
        
        for idx, product_data in enumerate(self.all_products, 1):
            product_id = product_data.get('ìƒí’ˆID', '')
            
            # ì´ë¯¸ ë§¤ì¹­ ì™„ë£Œëœ ìƒí’ˆ ìŠ¤í‚µ
            if product_id in self.matched_product_ids:
                print(f"[{idx}/{len(self.all_products)}] â­ï¸ ìŠ¤í‚µ (ì´ë¯¸ ë§¤ì¹­ ì™„ë£Œ)")
                continue
            
            # ì‹ ê·œ ìƒí’ˆì´ ì•„ë‹ˆë©´ ìŠ¤í‚µ (ì•ˆì „ì¥ì¹˜)
            if product_id in self.existing_product_ids and product_id not in self.global_new_ids:
                continue
            
            # ì˜ˆìƒ ì”ì—¬ ì‹œê°„ ê³„ì‚°
            if completed > 0:
                elapsed = time.time() - start_time
                avg_time = elapsed / completed
                remaining = (len(self.new_products) - completed) * avg_time
                hours = int(remaining // 3600)
                minutes = int((remaining % 3600) // 60)
                
                if hours > 0:
                    time_str = f"{hours}ì‹œê°„ {minutes}ë¶„"
                else:
                    time_str = f"{minutes}ë¶„"
                
                print(f"\nâ±ï¸  ì˜ˆìƒ ì”ì—¬ ì‹œê°„: {time_str} | ì¬ì‹œì‘ê¹Œì§€: {10 - restart_counter}ê°œ")
            
            # ë§¤ì¹­ ì‹¤í–‰
            try:
                success = self._match_and_save(
                    idx,
                    product_data.get('ì¹´í…Œê³ ë¦¬', ''),
                    product_data.get('ìƒí’ˆURL', ''),
                    product_data.get('ìƒí’ˆëª…', ''),
                    product_data.get('ê°€ê²©', ''),
                    product_id
                )
                
                if success:
                    completed += 1
                    restart_counter += 1
                
                # ğŸ”„ 10ê°œë§ˆë‹¤ ë¸Œë¼ìš°ì € ì¬ì‹œì‘
                if restart_counter >= 10:
                    print("\n" + "="*80)
                    print("ğŸ”„ ë¸Œë¼ìš°ì € ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ê´€ë¦¬ & ì°¨ë‹¨ ë°©ì§€)")
                    print("="*80)
                    
                    # ê¸°ì¡´ ë¸Œë¼ìš°ì € ì¢…ë£Œ
                    try:
                        self.iherb_browser.close()
                        print("  âœ… ê¸°ì¡´ ë¸Œë¼ìš°ì € ì¢…ë£Œ")
                    except:
                        pass
                    
                    # ëŒ€ê¸°
                    print("  â³ 3ì´ˆ ëŒ€ê¸° ì¤‘...")
                    time.sleep(3)
                    
                    # ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘
                    print("  ğŸš€ ìƒˆ ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")
                    self.iherb_browser = IHerbBrowser(headless=False)
                    self.iherb_client = IHerbClient(self.iherb_browser)
                    self.product_matcher = ProductMatcher(self.iherb_client)
                    print("  âœ… ë¸Œë¼ìš°ì € ì¬ì‹œì‘ ì™„ë£Œ\n")
                    
                    restart_counter = 0
                    
            except KeyboardInterrupt:
                elapsed_total = time.time() - start_time
                hours = int(elapsed_total // 3600)
                minutes = int((elapsed_total % 3600) // 60)
                
                print(f"\n{'='*80}")
                print(f"âš ï¸  ì‘ì—… ì¤‘ë‹¨!")
                print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ: {completed}ê°œ / {len(self.new_products)}ê°œ")
                print(f"â±ï¸  ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„")
                print(f"ğŸ’¾ ì§„í–‰ì‚¬í•­ ì €ì¥ë¨: {self.output_file}")
                print(f"ğŸ”„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤.")
                print(f"{'='*80}")
                raise
        
        # ì™„ë£Œ
        self.iherb_browser.close()
        
        elapsed = time.time() - start_time
        hours = int(elapsed // 3600)
        minutes = int((elapsed % 3600) // 60)
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ë§¤ì¹­ ì™„ë£Œ!")
        print(f"ğŸ“Š ì‹ ê·œ ë§¤ì¹­: {completed}ê°œ")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„")
        print(f"{'='*80}")
    
    def _match_and_save(self, idx, category, product_url, product_name, price, product_id):
        """ì•„ì´í—ˆë¸Œ ë§¤ì¹­ ë° ì €ì¥"""
        print(f"\n[{idx}/{len(self.all_products)}] ğŸ” {product_name[:50]}...")
        
        upc = ""
        part_number = ""
        
        try:
            # ì•„ì´í—ˆë¸Œ ê²€ìƒ‰ ë° ë§¤ì¹­
            result = self.product_matcher.search_product_enhanced(product_name)
            
            if result and result.get('matched_url'):
                matched_url = result['matched_url']
                print(f"  âœ… ë§¤ì¹­ ì„±ê³µ: {matched_url}")
                
                # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
                info = self.iherb_client.extract_product_info_with_price(matched_url)
                if info:
                    part_number = info.get('product_id', '')
                    upc = self._extract_upc_from_page()
                    print(f"  ğŸ“¦ íŒŒíŠ¸ë„˜ë²„: {part_number}")
                    if upc:
                        print(f"  ğŸ”¢ UPC: {upc}")
            else:
                print(f"  âŒ ë§¤ì¹­ ì‹¤íŒ¨")
        
        except Exception as e:
            error_msg = str(e)
            
            # API ì¿¼í„° ì´ˆê³¼ ê°ì§€
            if "quota" in error_msg.lower() or "limit" in error_msg.lower():
                print(f"\n{'='*80}")
                print("âš ï¸  Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼!")
                print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ: {idx - len(self.existing_product_ids)}ê°œ / {len(self.new_products)}ê°œ")
                print(f"ğŸ’¾ ì§„í–‰ì‚¬í•­ ì €ì¥ë¨: {self.output_file}")
                print(f"ğŸ”„ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ì´ì–´ì„œ ì§„í–‰ë©ë‹ˆë‹¤.")
                print(f"{'='*80}")
                raise KeyboardInterrupt("API í• ë‹¹ëŸ‰ ì´ˆê³¼")
            
            print(f"  âŒ ì˜¤ë¥˜: {error_msg[:100]}")
        
        # CSVì— ì €ì¥
        row = {
            'ìˆ˜ì§‘ìˆœì„œ': idx,
            'ì¹´í…Œê³ ë¦¬': category,
            'ì¿ íŒ¡_ìƒí’ˆURL': product_url,
            'ì¿ íŒ¡_ì œí’ˆëª…': product_name,
            'ì¿ íŒ¡_ë¹„íšŒì›ê°€ê²©': price,
            'ì•„ì´í—ˆë¸Œ_UPC': upc,
            'ì•„ì´í—ˆë¸Œ_íŒŒíŠ¸ë„˜ë²„': part_number,
            'ìˆ˜ì§‘ì‹œê°„': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        self.csv_writer.writerow(row)
        self.csv_file.flush()
        
        # ì²˜ë¦¬ ì™„ë£Œ IDì— ì¶”ê°€
        self.matched_product_ids.add(product_id)
        
        # ë”œë ˆì´
        time.sleep(random.uniform(1, 2))
        
        return True
    
    def _extract_upc_from_page(self):
        """í˜„ì¬ ì•„ì´í—ˆë¸Œ í˜ì´ì§€ì—ì„œ UPC ì¶”ì¶œ"""
        try:
            # XPathë¡œ ì •í™•íˆ ì°¾ê¸°
            upc_elements = self.iherb_browser.driver.find_elements(
                By.XPATH, 
                "//ul[@id='product-specs-list']//li[contains(text(), 'UPC')]"
            )
            
            for element in upc_elements:
                text = element.text
                # "UPC ì½”ë“œ: 898220021055" í˜•ì‹
                match = re.search(r'UPC[^:]*:\s*([0-9]{12,13})', text, re.IGNORECASE)
                if match:
                    upc = match.group(1)
                    if len(upc) in [12, 13]:
                        return upc
                
                # span íƒœê·¸ ì•ˆì— ìˆì„ ìˆ˜ë„
                try:
                    span = element.find_element(By.TAG_NAME, 'span')
                    upc = span.text.strip()
                    if upc.isdigit() and len(upc) in [12, 13]:
                        return upc
                except:
                    pass
            
            return ""
            
        except Exception as e:
            return ""
    
    def run(self):
        """ì „ì²´ ì‹¤í–‰"""
        categories = [
            {
                'name': 'í—¬ìŠ¤/ê±´ê°•ì‹í’ˆ',
                'url': 'https://shop.coupang.com/coupangus/74511?category=305433&platform=p&brandId=0',
                'count': 300
            },
            {
                'name': 'ì¶œì‚°ìœ ì•„ë™',
                'url': 'https://shop.coupang.com/coupangus/74511?category=219079&platform=p&brandId=0',
                'count': 300
            },
            {
                'name': 'ìŠ¤í¬ì¸ ë ˆì €',
                'url': 'https://shop.coupang.com/coupangus/74511?category=317675&platform=p&brandId=0',
                'count': 300
            }
        ]
        
        try:
            # 1ë‹¨ê³„: ì‹ ê·œ ì¿ íŒ¡ í¬ë¡¤ë§ (900ê°œ)
            self.crawl_new_coupang_products(categories)
            
            # 2ë‹¨ê³„: ì‹ ê·œ ìƒí’ˆë§Œ ì•„ì´í—ˆë¸Œ ë§¤ì¹­
            self.match_iherb_products()
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ì‚¬ìš©ì ì¤‘ë‹¨ ë˜ëŠ” API ì œí•œ")
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\nğŸ§¹ ì •ë¦¬ ì¤‘...")
        
        if self.csv_file:
            self.csv_file.close()
            print("  âœ… CSV íŒŒì¼ ë‹«ê¸° ì™„ë£Œ")
        
        if self.coupang_browser:
            try:
                self.coupang_browser.close()
                print("  âœ… ì¿ íŒ¡ ë¸Œë¼ìš°ì € ì¢…ë£Œ")
            except:
                pass
        
        if self.iherb_browser:
            try:
                self.iherb_browser.close()
                print("  âœ… ì•„ì´í—ˆë¸Œ ë¸Œë¼ìš°ì € ì¢…ë£Œ")
            except:
                pass


if __name__ == "__main__":
    crawler = CoupangIHerbAdd900Crawler(
        output_file="coupang_iherb_products.csv",
        cache_file="coupang_products_cache.csv"
    )
    crawler.run()