#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ê²°ê³¼ ì‹¤ì‹œê°„ ìˆ˜ì§‘ (í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì›)
â†’ í˜ì´ì§€ë¥¼ ì‹¤ì œë¡œ ì—´ê³  ìŠ¤í¬ë¡¤í•˜ë©´ì„œ 'í˜„ì¬ DOM/HTML'ì„ **ì ê·¹ íŒŒì‹±**í•˜ì—¬
   ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë² ì´ìŠ¤ URL(https://smartstore.naver.com/<store>)ì„ ìµœëŒ€í•œ ë§ì´ ìˆ˜ì§‘.

ê°•í™” í¬ì¸íŠ¸
- ìŠ¤í¬ë¡¤ë¡œ ì§€ì—°ë¡œë”©ëœ ê²°ê³¼ê¹Œì§€ ëª¨ë‘ ë…¸ì¶œ (ê°€ë³€ ë†’ì´ ëŒ€ì‘)
- DOM ìˆ˜ì§‘: a[href], [data-href], [data-url], [onclick] ë“± ê´‘ë²”ìœ„ ì¶”ì¶œ
- HTML ì •ê·œì‹ íŒŒì‹±: outlink(url=...) ë° ì§ì ‘ smartstore ë§í¬ë¥¼ page_sourceì—ì„œ ì¶”ê°€ ì¶”ì¶œ
- outlinkì˜ url íŒŒë¼ë¯¸í„°ë¥¼ ë””ì½”ë“œí•´ ì‹¤ì œ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ë¡œ ë³µì›
- ë¡œê·¸ì¸ í›„ warm-up ìˆœíšŒ ì œê±° (ìš”ì²­ì‚¬í•­ ë°˜ì˜)

ì‚¬ìš©:
  pip install undetected-chromedriver

ì˜ˆ:
  python3 smartstore_collect.py \
    --start-url "https://search.shopping.naver.com/search/all?adQuery=%ED%97%8C%ED%84%B0&agency=true&origQuery=%ED%97%8C%ED%84%B0&pagingIndex=1&pagingSize=40&productSet=total&query=%ED%97%8C%ED%84%B0&sort=rel&timestamp=&viewType=list" \
    --pages 10 \
    --out stores_hunter.txt
"""

import os, re, time, html, argparse, json
from typing import List, Set, Optional, Iterable
from urllib.parse import urlparse, parse_qs, unquote, urlencode, urlunparse, quote

import undetected_chromedriver as uc
from selenium.webdriver.common.by   import By
from selenium.webdriver.support.ui  import WebDriverWait
from selenium.webdriver.support     import expected_conditions as EC
from selenium.common.exceptions     import TimeoutException, UnexpectedAlertPresentException, JavascriptException

# ===== ì„¤ì • =====
PAGE_WAIT = 12
CAPTCHA_WAIT = 120
SCROLL_MAX_STEPS = 30          # ìŠ¤í¬ë¡¤ ë‹¨ê³„ ìˆ˜(í˜ì´ì§€ ê¸¸ì´ì— ë”°ë¼ ì¶©ë¶„íˆ í¬ê²Œ)
SCROLL_PAUSE = 0.35            # ìŠ¤í¬ë¡¤ ì‚¬ì´ ëŒ€ê¸°
SCROLL_SETTLE_PAUSE = 0.6      # ë§ˆì§€ë§‰ ì•ˆì •í™” ëŒ€ê¸°
USER_DATA_DIR = os.path.expanduser("~/.cache/ossomall_chrome")  # ì˜êµ¬ í”„ë¡œí•„
os.makedirs(USER_DATA_DIR, exist_ok=True)

NID_LOGIN_URL_TMPL = "https://nid.naver.com/nidlogin.login?mode=form&url={return_url}"
GLOBAL_CAPTCHA_HOST_SUBSTRING = "ncpt.naver.com"

SMARTSTORE_BASE_RE = re.compile(r"https?://smartstore\.naver\.com/([A-Za-z0-9._-]+)", re.I)
OUTLINK_RE = re.compile(
    r"https?://smartstore\.naver\.com/inflow/outlink/url\?[^\"'>]*\burl=([^\"'&]+)",
    re.I
)

def make_driver(headless=False):
    opt = uc.ChromeOptions()
    opt.add_argument("--disable-popup-blocking")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-blink-features=AutomationControlled")
    # ì˜êµ¬ í”„ë¡œí•„ + SameSite ì™„í™”
    opt.add_argument(f"--user-data-dir={USER_DATA_DIR}")
    opt.add_argument("--profile-directory=Default")
    opt.add_argument("--disable-features=SameSiteByDefaultCookies,CookiesWithoutSameSiteMustBeSecure")
    if headless:
        opt.add_argument("--headless=new")
    d = uc.Chrome(options=opt)
    d.set_page_load_timeout(45)
    return d

def normalize_url(u: Optional[str]) -> Optional[str]:
    if not u: return None
    u = u.strip()
    if not u: return None
    if not u.startswith(("http://", "https://")):
        u = "https://" + u.lstrip("/")
    return u

def with_paging_index(url: str, index: int) -> str:
    pr = urlparse(url)
    qs = parse_qs(pr.query, keep_blank_values=True)
    qs["pagingIndex"] = [str(index)]
    new_q = urlencode(qs, doseq=True)
    return urlunparse((pr.scheme, pr.netloc, pr.path, pr.params, new_q, pr.fragment))

def to_store_base(url: str) -> Optional[str]:
    m = SMARTSTORE_BASE_RE.search(url.strip())
    if not m: return None
    return f"https://smartstore.naver.com/{m.group(1)}"

def extract_from_outlink(url: str) -> Optional[str]:
    m = OUTLINK_RE.search(url)
    if not m:
        return None
    raw = m.group(1)
    decoded = html.unescape(unquote(raw))
    return to_store_base(decoded)

def is_global_captcha_page(driver) -> bool:
    try:
        return GLOBAL_CAPTCHA_HOST_SUBSTRING in (driver.current_url or "").lower()
    except UnexpectedAlertPresentException:
        try: driver.switch_to.alert.accept()
        except Exception: pass
        return False

def maybe_handle_global_captcha(driver, expected_url=None, where=""):
    if not is_global_captcha_page(driver): return
    print(f"ğŸ”’ ì „ì—­ ë³´ì•ˆ ìº¡ì°¨({where}). ìº¡ì°¨ í•´ê²° í›„ Enterâ€¦")
    try: input()
    except EOFError: time.sleep(CAPTCHA_WAIT)
    if expected_url and is_global_captcha_page(driver):
        driver.get(expected_url)
    time.sleep(0.7)

def check_captcha_or_block(driver) -> bool:
    try:
        cur = (driver.current_url or "").lower()
        htmlsrc = (driver.page_source or "").lower()
        if GLOBAL_CAPTCHA_HOST_SUBSTRING in cur: return True
        indicators = ['ì ‘ì†ì´ ì¼ì‹œì ìœ¼ë¡œ ì œí•œ','ë¹„ì •ìƒì ì¸ ì ‘ê·¼','ìë™ì…ë ¥ ë°©ì§€','ë³´ì•ˆë¬¸ì','captcha','blocked','ë¡œê·¸ì¸','nidlogin']
        if any(s in cur for s in ['captcha','blocked','nidlogin']) or any(s in htmlsrc for s in indicators):
            return True
        return False
    except Exception:
        return False

def prelogin_once(driver, target_url: str):
    """ë¡œê·¸ì¸ í•„ìš” ì‹œ NIDë¡œ 1íšŒë§Œ â†’ í†µê³¼ í›„ ê³§ë°”ë¡œ target_url ë³µê·€ (warm-up ì—†ìŒ)."""
    target_url = normalize_url(target_url) or target_url
    print(f"ğŸ”— ì´ˆê¸° ì§„ì…: {target_url}")
    driver.get("https://www.naver.com")
    try: WebDriverWait(driver, PAGE_WAIT).until(lambda d: d.execute_script("return document.readyState")=="complete")
    except Exception: pass
    driver.get(target_url)
    try: WebDriverWait(driver, PAGE_WAIT).until(lambda d: d.execute_script("return document.readyState")=="complete")
    except Exception: pass
    maybe_handle_global_captcha(driver, expected_url=target_url, where="ì´ˆê¸° ì§„ì…")
    if check_captcha_or_block(driver):
        login_url = NID_LOGIN_URL_TMPL.format(return_url=quote(target_url, safe=''))
        print("ğŸŸ¡ ë¡œê·¸ì¸/ì°¨ë‹¨ ê°ì§€ â†’ NID ë¡œê·¸ì¸ ì´ë™")
        driver.get(login_url)
        print("ğŸŸ¢ ë¡œê·¸ì¸/ë³´ì•ˆë¬¸ì í•´ê²° í›„ Enterâ€¦")
        try: input()
        except EOFError: time.sleep(CAPTCHA_WAIT)
        print("â†©ï¸  ì›ë˜ URLë¡œ ë³µê·€")
        driver.get(target_url)
        try: WebDriverWait(driver, PAGE_WAIT).until(lambda d: d.execute_script("return document.readyState")=="complete")
        except Exception: pass
        maybe_handle_global_captcha(driver, expected_url=target_url, where="ë³µê·€")

# ---------- ì‹¤ì‹œê°„(ë¼ì´ë¸Œ) íŒŒì‹± í•µì‹¬ ----------
def scroll_full_page(driver, max_steps=SCROLL_MAX_STEPS, pause=SCROLL_PAUSE):
    last_h = -1
    same_count = 0
    for _ in range(max_steps):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(pause)
        h = driver.execute_script("return document.body.scrollHeight;")
        if h == last_h:
            same_count += 1
            if same_count >= 2:  # ë‘ ë²ˆ ì—°ì† ë†’ì´ ê·¸ëŒ€ë¡œë©´ ì¢…ë£Œ
                break
        else:
            same_count = 0
        last_h = h
    time.sleep(SCROLL_SETTLE_PAUSE)

def js_collect_candidates(driver) -> List[str]:
    """
    í˜„ì¬ DOMì—ì„œ ë§í¬ í›„ë³´ë¥¼ ê´‘ë²”ìœ„ë¡œ ìˆ˜ì§‘:
    - a[href]
    - [data-href], [data-url]
    - [onclick]ì— í¬í•¨ëœ URL
    - role="link"ì¸ ìš”ì†Œì˜ href-like ì†ì„±
    """
    script = r"""
    const urls = new Set();

    // 1) a[href]
    document.querySelectorAll('a[href]').forEach(a => {
      let u = a.getAttribute('href') || '';
      if (u) urls.add(u);
    });

    // 2) data-href, data-url, data-link, data-mall-url ë“± ì¼ë°˜ì ì¸ data ì†ì„±ë“¤
    const ATTRS = ['data-href','data-url','data-link','data-mall-url','data-nclick','data-nv-mall-url','data-nv-url'];
    ATTRS.forEach(attr => {
      document.querySelectorAll(`[${attr}]`).forEach(el => {
        let v = el.getAttribute(attr);
        if (v) urls.add(v);
      });
    });

    // 3) onclick ë‚´ë¶€ì˜ URL
    document.querySelectorAll('[onclick]').forEach(el => {
      let v = el.getAttribute('onclick') || '';
      // crude extraction
      const m = v.match(/https?:\/\/[^\s"'<>]+/g);
      if (m) m.forEach(x => urls.add(x));
    });

    // 4) role="link"ì¸ ìš”ì†Œê°€ href-like ì†ì„±ì„ ê°€ì§„ ê²½ìš°
    document.querySelectorAll('[role="link"]').forEach(el => {
      let v = el.getAttribute('href') || el.getAttribute('data-href') || el.getAttribute('data-url');
      if (v) urls.add(v);
    });

    return Array.from(urls);
    """
    try:
        return driver.execute_script(script)
    except JavascriptException:
        return []

def extract_smartstores_from_sources(sources: Iterable[str]) -> Set[str]:
    stores: Set[str] = set()
    for href in sources:
        if not href: continue
        href = html.unescape(href)
        lo = href.lower()

        # ê´‘ê³ (adcr)ëŠ” ë„¤ë¹„ê²Œì´ì…˜ ì—†ì´ëŠ” í•´ì„ ë¶ˆê°€ â†’ ìŠ¤í‚µ
        if "/adcr" in lo:
            continue

        # 1) outlinkì—ì„œ ì¶”ì¶œ
        base = extract_from_outlink(href)
        if not base:
            # 2) ì§ì ‘ smartstore ë§í¬
            if "smartstore.naver.com" in lo:
                base = to_store_base(href)

        if base:
            stores.add(base)
    return stores

def collect_from_current_page(driver) -> List[str]:
    """
    1) ìŠ¤í¬ë¡¤ë¡œ ì§€ì—° ë¡œë”© ìš”ì†Œ ë…¸ì¶œ
    2) JSë¡œ DOM ê¸°ë°˜ í›„ë³´ ìˆ˜ì§‘
    3) page_source ì •ê·œì‹ìœ¼ë¡œ ë³´ê°•
    """
    scroll_full_page(driver)

    # DOM ê¸°ë°˜
    dom_candidates = js_collect_candidates(driver)
    dom_stores = extract_smartstores_from_sources(dom_candidates)

    # HTML ì •ê·œì‹ ê¸°ë°˜ (page_source ì „ì²´ ìŠ¤ìº”)
    src = driver.page_source or ""
    src_candidates = []

    # outlink url= íŒŒë¼ë¯¸í„°
    for m in OUTLINK_RE.finditer(src):
        src_candidates.append(f"https://smartstore.naver.com/inflow/outlink/url?url={m.group(1)}")

    # ì§ì ‘ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë§í¬
    for m in SMARTSTORE_BASE_RE.finditer(src):
        src_candidates.append(m.group(0))

    src_stores = extract_smartstores_from_sources(src_candidates)

    all_stores = sorted((dom_stores | src_stores))
    print(f"  - DOMí›„ë³´: {len(dom_candidates)} / DOMìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´: {len(dom_stores)} / HTMLìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´: {len(src_stores)}")
    return all_stores

# ===== ë©”ì¸ =====
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--start-url", required=True, help="ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ê²°ê³¼ URL(1í˜ì´ì§€ ê¸°ì¤€)")
    ap.add_argument("--pages", type=int, default=1, help="ê°€ì ¸ì˜¬ í˜ì´ì§€ ìˆ˜(ê¸°ë³¸=1)")
    ap.add_argument("--out", default="stores.txt", help="ì €ì¥ íŒŒì¼(.txt, í•œ ì¤„ë‹¹ 1ê°œ)")
    ap.add_argument("--headless", action="store_true")
    args = ap.parse_args()

    base_url = normalize_url(args.start_url) or args.start_url
    driver = make_driver(headless=args.headless)
    all_stores: Set[str] = set()

    try:
        # ë¡œê·¸ì¸ 1íšŒ (warm-up ì—†ìŒ)
        prelogin_once(driver, base_url)

        # í˜ì´ì§€ë„¤ì´ì…˜ ìˆœíšŒ (ê²€ìƒ‰ê²°ê³¼ í˜ì´ì§€ë§Œ ë°©ë¬¸)
        for idx in range(1, args.pages + 1):
            page_url = with_paging_index(base_url, idx)
            print(f"\nğŸ“„ í˜ì´ì§€ {idx}/{args.pages}: {page_url}")
            driver.get(page_url)
            try:
                WebDriverWait(driver, PAGE_WAIT).until(
                    lambda d: d.execute_script("return document.readyState") == "complete"
                )
            except Exception:
                pass
            maybe_handle_global_captcha(driver, expected_url=page_url, where=f"{idx}í˜ì´ì§€ ë¡œë“œ")

            stores = collect_from_current_page(driver)
            print(f"  â†’ ìˆ˜ì§‘: {len(stores)}ê°œ")
            all_stores.update(stores)

        if not all_stores:
            print("âš ï¸ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        with open(args.out, "w", encoding="utf-8") as f:
            for u in sorted(all_stores):
                f.write(u + "\n")
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ: {args.out} (ì´ {len(all_stores)}ê°œ ê³ ìœ  ìŠ¤í† ì–´)")

    finally:
        try: driver.quit()
        except Exception: pass

if __name__ == "__main__":
    main()
